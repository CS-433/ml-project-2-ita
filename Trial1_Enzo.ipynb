{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install vtk\n",
        "!pip install meshio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Invi4SwWUGt0",
        "outputId": "f7bee298-e840-41eb-cca6-85faf55c363b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vtk\n",
            "  Downloading vtk-9.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from vtk) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk) (1.16.0)\n",
            "Downloading vtk-9.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vtk\n",
            "Successfully installed vtk-9.3.1\n",
            "Collecting meshio\n",
            "  Downloading meshio-5.3.5-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from meshio) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from meshio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->meshio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->meshio) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->meshio) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->meshio) (0.1.2)\n",
            "Downloading meshio-5.3.5-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.2/166.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: meshio\n",
            "Successfully installed meshio-5.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xcjMZnnRwpCN"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import os\n",
        "import vtkmodules.all as vtk\n",
        "from vtkmodules.util.numpy_support import vtk_to_numpy, numpy_to_vtk\n",
        "import meshio\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ3-Jiio0MMr",
        "outputId": "0e8f5f35-1970-4350-c862-68a376d79abd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fields = {'velocity', 'pressure'}\n",
        "\n",
        "basis_space, sv_space, Nh_space, nmodes_space = dict(), dict(), dict(), dict()\n",
        "basis_time, sv_time, Nh_time, nmodes_time = dict(), dict(), dict(), dict()\n",
        "nmodes = dict()\n",
        "'/content/drive/MyDrive/dati/input_data.npy'\n",
        "for field in fields:\n",
        "    basis_space[field] = np.load(os.path.join('/content/drive/MyDrive/data_ML4Science', 'basis', field, 'space_basis.npy'))  # spatial basis\n",
        "    sv_space[field] = np.load(os.path.join('/content/drive/MyDrive/data_ML4Science', 'basis', field, 'space_sv.npy'))  # singular values in space\n",
        "    Nh_space[field], nmodes_space[field] = basis_space[field].shape  # number of FOM and ROM unknowns in space\n",
        "    basis_time[field] = np.load(os.path.join('/content/drive/MyDrive/data_ML4Science', 'basis', field, 'time_basis.npy'))  # temporal basis\n",
        "    sv_time[field] = np.load(os.path.join('/content/drive/MyDrive/data_ML4Science', 'basis', field, 'time_sv.npy'))  # singular values in time\n",
        "    Nh_time[field], nmodes_time[field] = basis_time[field].shape  # number of FOM and ROM unknowns in time\n",
        "    nmodes[field] = nmodes_space[field] * nmodes_time[field]  # total dimension of the reduced basis\n",
        "\n",
        "# UPDATE VELOCITY BASES TO ACCOUNT FOR SUPREMIZERS AND STABILIZERS\n",
        "N_supr_space = basis_space['pressure'].shape[1] + 66  # number of extra bases in space for the velocity\n",
        "N_supr_time = 5  # number of extra bases in time for the velocity\n",
        "\n",
        "# STORE ORIGINAL NUMBER OF VELOCITY MODES IN THE DICTIONARY\n",
        "nmodes_space['velocity_full'] = nmodes_space['velocity']\n",
        "nmodes_time['velocity_full'] = nmodes_time['velocity']\n",
        "nmodes['velocity_full'] = nmodes['velocity']\n",
        "\n",
        "# UPDATE THE NUMBER OF VELOCITY MODES TO ACCOUNT FOR SUPREMIZERS AND STABILIZERS\n",
        "nmodes_space['velocity'] -= N_supr_space\n",
        "nmodes_time['velocity'] -= N_supr_time\n",
        "nmodes['velocity'] = nmodes_space['velocity'] * nmodes_time['velocity']\n",
        "\n",
        "# UPDATE VELOCITY BASES TO ACCOUNT FOR SUPREMIZERS AND STABILIZERS\n",
        "basis_space['velocity'] = basis_space['velocity'][:, :nmodes_space['velocity']]\n",
        "basis_time['velocity'] = basis_time['velocity'][:, :nmodes_time['velocity']]\n",
        "\n",
        "# LOAD NORMED BASIS MATRICES IN SPACE (needed for projections)\n",
        "basis_space_normed = dict()\n",
        "#norm = dict()\n",
        "for field in fields:\n",
        "    #norm[field] = load_npz(os.path.join('dataset', 'norms', f'norm_{field}.npz'))\n",
        "    #basis_space_normed[field] = norm[field].dot(basis_space[field])\n",
        "    #np.save(os.path.join('dataset', 'basis', field, 'basis_space_normed.npy'), basis_space_normed[field])\n",
        "    basis_space_normed[field] = np.load(os.path.join('/content/drive/MyDrive/data_ML4Science', 'basis', field, 'basis_space_normed.npy'))\n",
        "\n",
        "# n_snaps = None  # change to a number if you want to load only a subset of snapshots\n",
        "# _sol = np.load(os.path.join('dataset', 'RB_data', 'solutions.npy'))[:n_snaps]\n",
        "_sol = np.load(os.path.join('/content/drive/MyDrive/data_ML4Science', 'RB_data', 'solutions.npy'))\n",
        "\n",
        "solutions = dict()\n",
        "\n",
        "# velocity reduced solutions (with and without supremizers and stabilizers)\n",
        "solutions['velocity_full'] = np.reshape(_sol[:, :nmodes['velocity_full']],\n",
        "                                        (-1, nmodes_space['velocity_full'], nmodes_time['velocity_full']))\n",
        "solutions['velocity'] = solutions['velocity_full'][:, :nmodes_space['velocity'], :nmodes_time['velocity']]\n",
        "\n",
        "# pressure reduced solutions\n",
        "solutions['pressure'] = np.reshape(_sol[:, :nmodes['pressure']],\n",
        "                                   (-1, nmodes_space['pressure'], nmodes_time['pressure']))\n",
        "\n",
        "##################################################################\n",
        "def project(sol, normed_basis_space, basis_time):\n",
        "    \"\"\" Project a full-order solution in space-time.\"\"\"\n",
        "    return (normed_basis_space.T.dot(sol)).dot(basis_time) # !! REMARK: here we need the normed basis in space !!\n",
        "\n",
        "def expand(sol, basis_space, basis_time):\n",
        "    \"\"\" Expand a reduced-order solution in space-time.\"\"\"\n",
        "    return (basis_space.dot(sol)).dot(basis_time.T)\n",
        "\n",
        "##################################################################\n",
        "\n",
        "params = np.load(os.path.join('/content/drive/MyDrive/data_ML4Science', 'RB_data', 'parameters.npy'))\n",
        "params = np.delete(params, 2, axis=1)  # one column is useless and we delete it\n",
        "\n",
        "Q = lambda t, mu, T=1: 1 - np.cos(2*np.pi*t/T) + mu[1] * np.sin(mu[0]*2*np.pi*t/T)\n",
        "\n",
        "times = np.linspace(0,1,1000)\n",
        "plt.plot(times, Q(times, [4.0, 0.1]), 'b-', label=r\"$\\mu = [4.0, 0.1]$\")\n",
        "plt.plot(times, Q(times, [4.0, 0.3]), 'b--', label=r\"$\\mu = [4.0, 0.3]$\")\n",
        "plt.plot(times, Q(times, [8.0, 0.1]), 'r-', label=r\"$\\mu = [8.0, 0.1]$\")\n",
        "plt.plot(times, Q(times, [8.0, 0.3]), 'r--', label=r\"$\\mu = [8.0, 0.3]$\")\n",
        "\n",
        "plt.grid()\n",
        "plt.xlim([0,1])\n",
        "plt.legend()\n",
        "plt.title(\"Parametric flow rate\", fontweight='bold', fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "_Bqc_7Kl3RmC",
        "outputId": "5678ebe7-5ed5-43e2-970d-c9702dc723a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(solutions['velocity'].shape)\n",
        "print(solutions['pressure'].shape)\n",
        "print(params.shape)\n",
        "\n",
        "params = params.astype(np.float32)\n",
        "solutions['velocity'] = solutions['velocity'].astype(np.float32)\n",
        "solutions['pressure'] = solutions['pressure'].astype(np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qmiswGP51Cj",
        "outputId": "e2e94daa-dbbb-471e-82be-d8efc6f3d544"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1950, 39, 16)\n",
            "(1950, 9, 19)\n",
            "(1950, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "class Fluid_Dataset(Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "    def __getitem__(self, idx):\n",
        "        input_data = self.inputs[idx]\n",
        "        target_data = self.targets[idx]\n",
        "        return input_data, target_data\n",
        "\n",
        "class Fluid_Dataset_auto(Dataset):\n",
        "    def __init__(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.targets = inputs\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "    def __getitem__(self, idx):\n",
        "        input_data = self.inputs[idx]\n",
        "        target_data = self.targets[idx]\n",
        "        return input_data, target_data\n",
        "\n",
        "N_data=params.shape[0]\n",
        "indices = torch.randperm(N_data)\n",
        "ratio_data=0.8\n",
        "train_size = int(ratio_data * N_data)\n",
        "train_indices = indices[:train_size]\n",
        "test_indices=indices[train_size:]\n",
        "\n",
        "mean_params=np.mean(params,axis=0)\n",
        "min_params=np.min(params,axis=0)\n",
        "max_params=np.max(params,axis=0)\n",
        "std_params=np.std(params,axis=0)\n",
        "params_norm=(params-mean_params)/std_params\n",
        "# params_norm=(params-min_params)/(max_params-min_params)\n",
        "#FARE IN -1,1??\n",
        "\n",
        "train_params=params_norm[train_indices]\n",
        "test_params=params_norm[test_indices]\n",
        "\n",
        "vel=solutions['velocity']\n",
        "# max_vel=np.max(vel,axis=0)\n",
        "# min_vel=np.min(vel,axis=0)\n",
        "# # print(min_vel.shape)\n",
        "# vel=(vel-min_vel)/(max_vel-min_vel)\n",
        "# mean_vel=np.mean(vel,axis=0)\n",
        "# std_vel=np.std(vel,axis=0)\n",
        "# vel=(vel-mean_vel)/std_vel\n",
        "\n",
        "train_vel=vel[train_indices]\n",
        "test_vel=vel[test_indices]\n",
        "\n",
        "train_press=solutions['pressure'][train_indices]\n",
        "test_press=solutions['pressure'][test_indices]\n",
        "# dataset = Fluid_Dataset(params_norm, solutions['velocity'])\n",
        "\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "print(test_vel.shape,train_vel.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoN6CMUf93jj",
        "outputId": "697bbfda-7d95-4569-ec26-9440c3c82c44"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(390, 39, 16) (1560, 39, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K=256\n",
        "class MLP_vel_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gelu = torch.nn.GELU()\n",
        "        self.ln = torch.nn.LayerNorm(K)\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(3,K),\n",
        "            torch.nn.LayerNorm(K),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(K,K),\n",
        "            torch.nn.LayerNorm(K),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(K,K),\n",
        "            torch.nn.LayerNorm(K),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(K,K),\n",
        "            torch.nn.LayerNorm(K),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(K,K),\n",
        "            torch.nn.LayerNorm(K),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(K,39*16)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, Z):\n",
        "        Z = torch.flatten(Z, 1)\n",
        "        Z = self.mlp(Z)\n",
        "        Z = Z.view(-1, 39, 16)\n",
        "        return Z\n",
        "\n",
        "class Autoencoder(torch.nn.Module):\n",
        "    def __init__(self): #VARIARE NUMERO LAYER E NH es (Nh=32)\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(39 * 16, 512),  # Livello completamente connesso\n",
        "            torch.nn.LayerNorm(512),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.LayerNorm(512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 39 * 16),  # Ricostruisce la dimensione piatta\n",
        "            torch.nn.Unflatten(1, (39, 16))\n",
        "        )\n",
        "                                     # Normalizza l'output [0,1])\n",
        "    def forward(self, x):\n",
        "        Z = torch.flatten(x, 1)\n",
        "        Z1=self.encoder(Z)\n",
        "        Z2=self.decoder(Z1)\n",
        "        return Z2\n",
        "\n",
        "class Autoencoder2(torch.nn.Module):\n",
        "    def __init__(self): #VARIARE NUMERO LAYER E NH es (Nh=32)\n",
        "        super(Autoencoder2, self).__init__()\n",
        "\n",
        "\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=1),  # (1, 39, 16) -> (64, 19, 7)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # (64, 19, 7) -> (128, 10, 4)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Flatten(),                                          # (32, 10, 4) -> (32*10*4)\n",
        "            torch.nn.Linear(128*10*4, 256)                               # Bottleneck\n",
        "            # torch.nn.ReLU(),\n",
        "            # torch.nn.Linear(128, 32)                                     # Latent space\n",
        "        )\n",
        "\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            # torch.nn.Linear(32, 128),\n",
        "            # torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128*10*4),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Unflatten(1, (128, 10, 4)),                         # (32*10*4) -> (32, 10, 4)\n",
        "            torch.nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=(0, 0)), #(64,19,7)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.ConvTranspose2d(64, 1, kernel_size=5, stride=2, padding=1, output_padding=(0, 1)),   # -> (1, 39, 16)\n",
        "            # torch.nn.Sigmoid()                                          # Normalizza l'output [0,1]\n",
        "        )\n",
        "                                     # Normalizza l'output [0,1])\n",
        "    def forward(self, x):\n",
        "        x=x.unsqueeze(1)\n",
        "        Z1=self.encoder(x)\n",
        "        Z2=self.decoder(Z1)\n",
        "        Z2=Z2.squeeze(1)\n",
        "        return Z2\n",
        "\n",
        "class MLP_vel_ConvAutoencoder(torch.nn.Module):\n",
        "    def __init__(self): #VARIARE NUMERO LAYER E NH es (Nh=32)\n",
        "        super(MLP_vel_ConvAutoencoder, self).__init__()\n",
        "\n",
        "        self.gelu = torch.nn.GELU()\n",
        "        self.ln = torch.nn.LayerNorm(256)\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(3,256),\n",
        "            torch.nn.LayerNorm(256),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(256,256),\n",
        "            torch.nn.LayerNorm(256),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(256,256),\n",
        "            torch.nn.LayerNorm(256),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(256,256),\n",
        "            torch.nn.LayerNorm(256),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(256,256),\n",
        "            torch.nn.LayerNorm(256),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(256,128)\n",
        "        )\n",
        "\n",
        "        # self.encoder = torch.nn.Sequential(\n",
        "        #     torch.nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),  # (1, 39, 16) -> (16, 20, 8)\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # (16, 20, 8) -> (32, 10, 4)\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Flatten(),                                          # (32, 10, 4) -> (32*10*4)\n",
        "        #     torch.nn.Linear(32*10*4, 128),                               # Bottleneck\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Linear(128, 64)                                     # Latent space\n",
        "        # )\n",
        "\n",
        "        # self.encoder = torch.nn.Sequential(\n",
        "        #     torch.nn.Flatten(),\n",
        "        #     torch.nn.Linear(39 * 16, 512),  # Livello completamente connesso\n",
        "        #     torch.nn.LayerNorm(512),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.Linear(512, 256),\n",
        "        #     torch.nn.LayerNorm(256),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.Linear(256, 256)\n",
        "        # )\n",
        "\n",
        "        # self.decoder = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(256, 256),\n",
        "        #     torch.nn.LayerNorm(256),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.Linear(256, 512),\n",
        "        #     torch.nn.LayerNorm(512),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.Linear(512, 39 * 16),  # Ricostruisce la dimensione piatta\n",
        "        #     torch.nn.Unflatten(1, (39, 16))\n",
        "        # )\n",
        "\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=1),  # (1, 39, 16) -> (64, 19, 7)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # (64, 19, 7) -> (128, 10, 4)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Flatten(),                                          # (32, 10, 4) -> (32*10*4)\n",
        "            torch.nn.Linear(128*10*4, 256),                               # Bottleneck\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128)                                     # Latent space\n",
        "        )\n",
        "\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(128, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128*10*4),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Unflatten(1, (128, 10, 4)),                         # (32*10*4) -> (32, 10, 4)\n",
        "            torch.nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=(0, 0)), #(64,19,7)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.ConvTranspose2d(64, 1, kernel_size=5, stride=2, padding=1, output_padding=(0, 1)),   # -> (1, 39, 16)\n",
        "            # torch.nn.Sigmoid()                                          # Normalizza l'output [0,1]\n",
        "        )\n",
        "\n",
        "        # # Decoder\n",
        "        # self.decoder = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(64, 128),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Linear(128, 32*10*4),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Unflatten(1, (32, 10, 4)),                         # (32*10*4) -> (32, 10, 4)\n",
        "        #     torch.nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)), #(16,20,8)\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=(0, 1)))   # -> (1, 39, 16)\n",
        "        #    # torch.nn.Sigmoid()  )                                        # Normalizza l'output [0,1])\n",
        "    def forward(self, x, y):\n",
        "        # Z = torch.flatten(x, 1)\n",
        "        Z=x\n",
        "        Z1 = self.mlp(Z)\n",
        "\n",
        "        y = y.unsqueeze(1)\n",
        "        Z2=self.encoder(y)\n",
        "        Z3=self.decoder(Z2)\n",
        "        Z3=Z3.squeeze(1)\n",
        "        return Z1, Z2, Z3\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Z = torch.flatten(x, 1)\n",
        "        Z=x\n",
        "        Z1 = self.mlp(Z)\n",
        "\n",
        "        Z2=self.decoder(Z1)\n",
        "        Z2=Z2.squeeze(1)\n",
        "        return Z2\n",
        "\n"
      ],
      "metadata": {
        "id": "deK6tggV7Oos"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, device, train_loader, optimizer, scheduler, epoch, criterion):\n",
        "    model.train()  # Important set model to train mode (affects dropout, batch norm etc)\n",
        "\n",
        "    loss_history = []\n",
        "    accuracy_history = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data=data.to(device)\n",
        "        target=target.to(device)\n",
        "        output = model.forward(data)  # TODO\n",
        "        loss =  criterion(output, target)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        loss.backward()        # Backpropagation\n",
        "        optimizer.step()       # Update the weights\n",
        "        scheduler.step()\n",
        "\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "        if batch_idx % (len(train_loader.dataset) // len(data) // 4) == 0:\n",
        "            print(\n",
        "                f\"Train Epoch: {epoch}-{batch_idx} batch_loss={loss.item()/len(data):0.2e}\"\n",
        "            )\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "def train_epoch_conv(model, device, train_loader, optimizer, epoch, criterion,scheduler):\n",
        "  model.train()  # Important set model to train mode (affects dropout, batch norm etc)\n",
        "\n",
        "  loss_history = []\n",
        "  accuracy_history = []\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "      data=data.to(device)\n",
        "      target=target.to(device)\n",
        "      Z1,Z2,Z3 = model.forward(data,target)\n",
        "      # print(Z1.shape,Z2.shape,Z3.shape)\n",
        "      loss =  0.5* criterion(Z1, Z2)+ 0.5* criterion(target, Z3)\n",
        "\n",
        "      optimizer.zero_grad()  # Zero the gradients\n",
        "      loss.backward()        # Backpropagation\n",
        "      optimizer.step()       # Update the weights\n",
        "\n",
        "      scheduler.step()\n",
        "\n",
        "      loss_history.append(loss.item())\n",
        "\n",
        "      if batch_idx % (len(train_loader.dataset) // len(data) // 4) == 0:\n",
        "          print(\n",
        "              f\"Train Epoch: {epoch}-{batch_idx} batch_loss={loss.item()/len(data):0.2e}\"\n",
        "          )\n",
        "\n",
        "  return loss_history\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, device, val_loader, criterion):\n",
        "    model.eval()  # Important set model to eval mode (affects dropout, batch norm etc)\n",
        "    test_loss = 0\n",
        "    test_rel_loss = 0\n",
        "    for data, target in val_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        test_loss += criterion(output, target).item() * len(data)\n",
        "        # test_rel_loss += criterion(output, target).item()/torch.norm(target).item() * len(data)\n",
        "        test_rel_loss += ((torch.norm((output-target).view(output.shape[0], -1), dim=1)/torch.norm((target).view(output.shape[0],-1), dim=1)).sum()).item()\n",
        "\n",
        "    test_loss /= len(val_loader.dataset)\n",
        "    test_rel_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(\n",
        "        \"Test set: Average loss: {:.4f} Average relative error: {:.4f}\".format(\n",
        "            test_loss, test_rel_loss\n",
        "        )\n",
        "    )\n",
        "    return test_loss,test_rel_loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_conv(model, device, val_loader, criterion):\n",
        "    model.eval()  # Important set model to eval mode (affects dropout, batch norm etc)\n",
        "    test_loss = 0\n",
        "    test_rel_loss = 0\n",
        "    for data, target in val_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model.predict(data)\n",
        "        Z1,Z2,Z3 = model.forward(data,target)\n",
        "        test_loss +=  (0.5* criterion(Z1, Z2).item()+ 0.5* criterion(target, Z3).item()) * len(data)\n",
        "        test_rel_loss += ((torch.norm((output-target).view(output.shape[0], -1), dim=1)/torch.norm((target).view(output.shape[0],-1), dim=1)).sum()).item()\n",
        "\n",
        "    test_loss /= len(val_loader.dataset)\n",
        "    test_rel_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(\n",
        "        \"Test set: Average loss: {:.4f} Average relative error: {:.4f}\".format(\n",
        "            test_loss, test_rel_loss\n",
        "        )\n",
        "    )\n",
        "    return test_loss,test_rel_loss\n",
        "\n",
        "\n",
        "# def run_vel_training(num_epochs, lr, batch_size, device=\"cuda\"):\n",
        "\n",
        "#     train_set = Fluid_Dataset(train_params, train_vel)\n",
        "\n",
        "#     val_set = Fluid_Dataset(test_params, test_vel)\n",
        "\n",
        "#     train_loader = torch.utils.data.DataLoader(\n",
        "#         train_set,\n",
        "#         batch_size=batch_size,\n",
        "#         shuffle=True,  # Can be important for training\n",
        "#         pin_memory=torch.cuda.is_available(),\n",
        "#         drop_last=True,\n",
        "#         num_workers=2,\n",
        "#     )\n",
        "#     val_loader = torch.utils.data.DataLoader(\n",
        "#         val_set,\n",
        "#         batch_size=batch_size,\n",
        "#     )\n",
        "\n",
        "#     # ===== Model, Optimizer and Criterion =====\n",
        "#     model = MLP_vel_model()\n",
        "#     model = model.to(device=device)\n",
        "#     optimizer = torch.optim.SGD(\n",
        "#         model.parameters(),\n",
        "#         lr=lr,\n",
        "#         weight_decay=1e-4\n",
        "#     )\n",
        "#     criterion = torch.nn.functional.mse_loss\n",
        "\n",
        "#     # ===== Train Model =====\n",
        "#     train_loss_history = []\n",
        "#     val_loss_history = []\n",
        "#     val_rel_loss_history = []\n",
        "\n",
        "#     for epoch in range(1, num_epochs + 1):\n",
        "#         train_loss = train_epoch(\n",
        "#             model, device, train_loader, optimizer, epoch, criterion\n",
        "#         )\n",
        "#         train_loss_history.extend(train_loss)\n",
        "\n",
        "#         val_loss,val_rel_loss= validate(model, device, val_loader, criterion)\n",
        "#         val_loss_history.append(val_loss)\n",
        "#         val_rel_loss_history.append(val_rel_loss)\n",
        "\n",
        "#     # ===== Plot training curves =====\n",
        "#     n_train = len(train_loss_history)\n",
        "#     t_train = num_epochs * np.arange(n_train) / n_train\n",
        "#     t_val = np.arange(1, num_epochs + 1)\n",
        "\n",
        "#     plt.figure()\n",
        "#     plt.plot(t_train, train_loss_history, label=\"Train\")\n",
        "#     plt.plot(t_val, val_loss_history, label=\"Val\")\n",
        "#     plt.legend()\n",
        "#     plt.xlabel(\"Epoch\")\n",
        "#     plt.ylabel(\"Loss\")\n",
        "\n",
        "#     plt.figure()\n",
        "#     plt.plot(t_val, val_rel_loss_history, label=\"Val rel err\")\n",
        "#     plt.legend()\n",
        "#     plt.xlabel(\"Epoch\")\n",
        "#     plt.ylabel(\"rel err\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def run_training(model,train_output,test_output,num_epochs, lr, batch_size, device=\"cuda\"):\n",
        "\n",
        "  train_set = Fluid_Dataset(train_params, train_output)\n",
        "\n",
        "  val_set = Fluid_Dataset(test_params, test_output)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_set,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,  # Can be important for training\n",
        "      pin_memory=torch.cuda.is_available(),\n",
        "      drop_last=True,\n",
        "      num_workers=2,\n",
        "  )\n",
        "  val_loader = torch.utils.data.DataLoader(\n",
        "      val_set,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "  # ===== Model, Optimizer and Criterion =====\n",
        "  model = model.to(device=device)\n",
        "  optimizer = torch.optim.Adam(\n",
        "      model.parameters(),\n",
        "      lr=lr,\n",
        "  )\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.99)\n",
        "\n",
        "  criterion = torch.nn.functional.mse_loss\n",
        "\n",
        "  # ===== Train Model =====\n",
        "  train_loss_history = []\n",
        "  val_loss_history = []\n",
        "  val_rel_loss_history = []\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "      train_loss = train_epoch(\n",
        "          model, device, train_loader, optimizer, scheduler, epoch, criterion\n",
        "      )\n",
        "      train_loss_history.extend(train_loss)\n",
        "\n",
        "      val_loss,val_rel_loss= validate(model, device, val_loader, criterion)\n",
        "      val_loss_history.append(val_loss)\n",
        "      val_rel_loss_history.append(val_rel_loss)\n",
        "\n",
        "  # ===== Plot training curves =====\n",
        "  n_train = len(train_loss_history)\n",
        "  t_train = num_epochs * np.arange(n_train) / n_train\n",
        "  t_val = np.arange(1, num_epochs + 1)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(t_train, train_loss_history, label=\"Train\")\n",
        "  plt.plot(t_val, val_loss_history, label=\"Val\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(t_val, val_rel_loss_history, label=\"Val rel err\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"rel err\")\n",
        "\n",
        "  return model\n",
        "\n",
        "def run_training_auto(model,train_output,test_output,num_epochs, lr, batch_size, device=\"cuda\"):\n",
        "\n",
        "  train_set = Fluid_Dataset_auto(train_output)\n",
        "\n",
        "  val_set = Fluid_Dataset_auto(test_output)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_set,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,  # Can be important for training\n",
        "      pin_memory=torch.cuda.is_available(),\n",
        "      drop_last=True,\n",
        "      num_workers=2,\n",
        "  )\n",
        "  val_loader = torch.utils.data.DataLoader(\n",
        "      val_set,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "  # ===== Model, Optimizer and Criterion =====\n",
        "  model = model.to(device=device)\n",
        "  optimizer = torch.optim.Adam(\n",
        "      model.parameters(),\n",
        "      lr=lr,\n",
        "  )\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.99)\n",
        "\n",
        "  criterion = torch.nn.functional.mse_loss\n",
        "\n",
        "  # ===== Train Model =====\n",
        "  train_loss_history = []\n",
        "  val_loss_history = []\n",
        "  val_rel_loss_history = []\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "      train_loss = train_epoch(\n",
        "          model, device, train_loader, optimizer, scheduler, epoch, criterion\n",
        "      )\n",
        "      train_loss_history.extend(train_loss)\n",
        "\n",
        "      val_loss,val_rel_loss= validate(model, device, val_loader, criterion)\n",
        "      val_loss_history.append(val_loss)\n",
        "      val_rel_loss_history.append(val_rel_loss)\n",
        "\n",
        "  # ===== Plot training curves =====\n",
        "  n_train = len(train_loss_history)\n",
        "  t_train = num_epochs * np.arange(n_train) / n_train\n",
        "  t_val = np.arange(1, num_epochs + 1)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(t_train, train_loss_history, label=\"Train\")\n",
        "  plt.plot(t_val, val_loss_history, label=\"Val\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(t_val, val_rel_loss_history, label=\"Val rel err\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"rel err\")\n",
        "\n",
        "  return model\n",
        "\n",
        "def run_training_conv(model,train_output,test_output,num_epochs, lr, batch_size, wd, device=\"cuda\"):\n",
        "\n",
        "  train_set = Fluid_Dataset(train_params, train_output)\n",
        "\n",
        "  val_set = Fluid_Dataset(test_params, test_output)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_set,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,  # Can be important for training\n",
        "      pin_memory=torch.cuda.is_available(),\n",
        "      drop_last=True,\n",
        "      num_workers=2,\n",
        "  )\n",
        "  val_loader = torch.utils.data.DataLoader(\n",
        "      val_set,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "  # ===== Model, Optimizer and Criterion =====\n",
        "  model = model.to(device=device)\n",
        "  optimizer = torch.optim.Adam(\n",
        "      model.parameters(),\n",
        "      lr=lr,\n",
        "      weight_decay=wd\n",
        "  )\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.99)\n",
        "\n",
        "  criterion = torch.nn.functional.mse_loss\n",
        "\n",
        "  # ===== Train Model =====\n",
        "  train_loss_history = []\n",
        "  val_loss_history = []\n",
        "  val_rel_loss_history = []\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "      train_loss = train_epoch_conv(\n",
        "          model, device, train_loader, optimizer, epoch, criterion,scheduler\n",
        "      )\n",
        "      train_loss_history.extend(train_loss)\n",
        "\n",
        "      val_loss, val_rel_loss= validate_conv(model, device, val_loader, criterion)\n",
        "      val_loss_history.append(val_loss)\n",
        "      val_rel_loss_history.append(val_loss)\n",
        "\n",
        "  # ===== Plot training curves =====\n",
        "  n_train = len(train_loss_history)\n",
        "  t_train = num_epochs * np.arange(n_train) / n_train\n",
        "  t_val = np.arange(1, num_epochs + 1)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(t_train, train_loss_history, label=\"Train\")\n",
        "  plt.plot(t_val, val_loss_history, label=\"Val\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(t_val, val_rel_loss_history, label=\"Val rel err\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"rel err\")\n",
        "\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "UTpEF7Nbyifb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = 0.01\n",
        "# batch_size = 32\n",
        "# num_epochs = 500\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# model_vel_trained=run_training(MLP_vel_model(), train_vel, test_vel, num_epochs, lr, batch_size, device)\n",
        "\n",
        "\n",
        "lr = 0.0001\n",
        "batch_size = 32\n",
        "num_epochs = 400\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "wd=1e-3\n",
        "\n",
        "model_vel_trained_autoencoder=run_training_conv(MLP_vel_ConvAutoencoder(), train_vel, test_vel, num_epochs, lr, batch_size, wd, device)\n",
        "\n",
        "# lr = 0.0005\n",
        "# batch_size = 32\n",
        "# num_epochs = 200\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# wd=1e-3\n",
        "\n",
        "# model_vel_trained_autoencoder=run_training_auto(Autoencoder(), train_vel, test_vel, num_epochs, lr, batch_size, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tR7Fp6yKFBkA",
        "outputId": "f8efa392-09dc-4bb8-db1c-1cf72fb47bba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1-0 batch_loss=8.37e-01\n",
            "Train Epoch: 1-12 batch_loss=8.31e-01\n",
            "Train Epoch: 1-24 batch_loss=8.22e-01\n",
            "Train Epoch: 1-36 batch_loss=8.24e-01\n",
            "Test set: Average loss: 25.0029 Average relative error: 0.9810\n",
            "Train Epoch: 2-0 batch_loss=7.78e-01\n",
            "Train Epoch: 2-12 batch_loss=7.35e-01\n",
            "Train Epoch: 2-24 batch_loss=6.49e-01\n",
            "Train Epoch: 2-36 batch_loss=5.67e-01\n",
            "Test set: Average loss: 15.1844 Average relative error: 0.8177\n",
            "Train Epoch: 3-0 batch_loss=4.61e-01\n",
            "Train Epoch: 3-12 batch_loss=3.92e-01\n",
            "Train Epoch: 3-24 batch_loss=2.89e-01\n",
            "Train Epoch: 3-36 batch_loss=2.06e-01\n",
            "Test set: Average loss: 3.9520 Average relative error: 0.4903\n",
            "Train Epoch: 4-0 batch_loss=1.34e-01\n",
            "Train Epoch: 4-12 batch_loss=1.08e-01\n",
            "Train Epoch: 4-24 batch_loss=8.62e-02\n",
            "Train Epoch: 4-36 batch_loss=8.40e-02\n",
            "Test set: Average loss: 2.2157 Average relative error: 0.2748\n",
            "Train Epoch: 5-0 batch_loss=6.57e-02\n",
            "Train Epoch: 5-12 batch_loss=6.86e-02\n",
            "Train Epoch: 5-24 batch_loss=6.64e-02\n",
            "Train Epoch: 5-36 batch_loss=7.42e-02\n",
            "Test set: Average loss: 2.2047 Average relative error: 0.2715\n",
            "Train Epoch: 6-0 batch_loss=7.21e-02\n",
            "Train Epoch: 6-12 batch_loss=6.85e-02\n",
            "Train Epoch: 6-24 batch_loss=7.57e-02\n",
            "Train Epoch: 6-36 batch_loss=7.60e-02\n",
            "Test set: Average loss: 2.2116 Average relative error: 0.2721\n",
            "Train Epoch: 7-0 batch_loss=7.47e-02\n",
            "Train Epoch: 7-12 batch_loss=7.59e-02\n",
            "Train Epoch: 7-24 batch_loss=7.38e-02\n",
            "Train Epoch: 7-36 batch_loss=7.31e-02\n",
            "Test set: Average loss: 2.2000 Average relative error: 0.2713\n",
            "Train Epoch: 8-0 batch_loss=6.19e-02\n",
            "Train Epoch: 8-12 batch_loss=7.21e-02\n",
            "Train Epoch: 8-24 batch_loss=7.39e-02\n",
            "Train Epoch: 8-36 batch_loss=6.49e-02\n",
            "Test set: Average loss: 2.1964 Average relative error: 0.2712\n",
            "Train Epoch: 9-0 batch_loss=7.15e-02\n",
            "Train Epoch: 9-12 batch_loss=7.42e-02\n",
            "Train Epoch: 9-24 batch_loss=6.74e-02\n",
            "Train Epoch: 9-36 batch_loss=8.04e-02\n",
            "Test set: Average loss: 2.1813 Average relative error: 0.2708\n",
            "Train Epoch: 10-0 batch_loss=6.81e-02\n",
            "Train Epoch: 10-12 batch_loss=8.35e-02\n",
            "Train Epoch: 10-24 batch_loss=6.85e-02\n",
            "Train Epoch: 10-36 batch_loss=6.49e-02\n",
            "Test set: Average loss: 2.1252 Average relative error: 0.2695\n",
            "Train Epoch: 11-0 batch_loss=7.31e-02\n",
            "Train Epoch: 11-12 batch_loss=6.81e-02\n",
            "Train Epoch: 11-24 batch_loss=6.18e-02\n",
            "Train Epoch: 11-36 batch_loss=6.37e-02\n",
            "Test set: Average loss: 1.9188 Average relative error: 0.2604\n",
            "Train Epoch: 12-0 batch_loss=5.09e-02\n",
            "Train Epoch: 12-12 batch_loss=5.52e-02\n",
            "Train Epoch: 12-24 batch_loss=5.86e-02\n",
            "Train Epoch: 12-36 batch_loss=5.61e-02\n",
            "Test set: Average loss: 1.5062 Average relative error: 0.2375\n",
            "Train Epoch: 13-0 batch_loss=4.02e-02\n",
            "Train Epoch: 13-12 batch_loss=4.88e-02\n",
            "Train Epoch: 13-24 batch_loss=4.34e-02\n",
            "Train Epoch: 13-36 batch_loss=3.79e-02\n",
            "Test set: Average loss: 1.0631 Average relative error: 0.2056\n",
            "Train Epoch: 14-0 batch_loss=3.59e-02\n",
            "Train Epoch: 14-12 batch_loss=3.56e-02\n",
            "Train Epoch: 14-24 batch_loss=2.92e-02\n",
            "Train Epoch: 14-36 batch_loss=3.23e-02\n",
            "Test set: Average loss: 0.8368 Average relative error: 0.1794\n",
            "Train Epoch: 15-0 batch_loss=3.07e-02\n",
            "Train Epoch: 15-12 batch_loss=2.93e-02\n",
            "Train Epoch: 15-24 batch_loss=2.31e-02\n",
            "Train Epoch: 15-36 batch_loss=2.83e-02\n",
            "Test set: Average loss: 0.7912 Average relative error: 0.1699\n",
            "Train Epoch: 16-0 batch_loss=2.89e-02\n",
            "Train Epoch: 16-12 batch_loss=2.39e-02\n",
            "Train Epoch: 16-24 batch_loss=2.66e-02\n",
            "Train Epoch: 16-36 batch_loss=2.46e-02\n",
            "Test set: Average loss: 0.7920 Average relative error: 0.1682\n",
            "Train Epoch: 17-0 batch_loss=2.61e-02\n",
            "Train Epoch: 17-12 batch_loss=2.72e-02\n",
            "Train Epoch: 17-24 batch_loss=2.89e-02\n",
            "Train Epoch: 17-36 batch_loss=2.57e-02\n",
            "Test set: Average loss: 0.7808 Average relative error: 0.1663\n",
            "Train Epoch: 18-0 batch_loss=2.57e-02\n",
            "Train Epoch: 18-12 batch_loss=2.75e-02\n",
            "Train Epoch: 18-24 batch_loss=2.61e-02\n",
            "Train Epoch: 18-36 batch_loss=2.50e-02\n",
            "Test set: Average loss: 0.7791 Average relative error: 0.1657\n",
            "Train Epoch: 19-0 batch_loss=2.56e-02\n",
            "Train Epoch: 19-12 batch_loss=3.26e-02\n",
            "Train Epoch: 19-24 batch_loss=2.90e-02\n",
            "Train Epoch: 19-36 batch_loss=2.89e-02\n",
            "Test set: Average loss: 0.7760 Average relative error: 0.1653\n",
            "Train Epoch: 20-0 batch_loss=2.41e-02\n",
            "Train Epoch: 20-12 batch_loss=2.34e-02\n",
            "Train Epoch: 20-24 batch_loss=2.45e-02\n",
            "Train Epoch: 20-36 batch_loss=2.57e-02\n",
            "Test set: Average loss: 0.7757 Average relative error: 0.1652\n",
            "Train Epoch: 21-0 batch_loss=2.46e-02\n",
            "Train Epoch: 21-12 batch_loss=2.46e-02\n",
            "Train Epoch: 21-24 batch_loss=2.71e-02\n",
            "Train Epoch: 21-36 batch_loss=2.79e-02\n",
            "Test set: Average loss: 0.7792 Average relative error: 0.1654\n",
            "Train Epoch: 22-0 batch_loss=2.42e-02\n",
            "Train Epoch: 22-12 batch_loss=2.71e-02\n",
            "Train Epoch: 22-24 batch_loss=2.75e-02\n",
            "Train Epoch: 22-36 batch_loss=3.08e-02\n",
            "Test set: Average loss: 0.7769 Average relative error: 0.1652\n",
            "Train Epoch: 23-0 batch_loss=2.39e-02\n",
            "Train Epoch: 23-12 batch_loss=2.71e-02\n",
            "Train Epoch: 23-24 batch_loss=2.57e-02\n",
            "Train Epoch: 23-36 batch_loss=2.53e-02\n",
            "Test set: Average loss: 0.7790 Average relative error: 0.1653\n",
            "Train Epoch: 24-0 batch_loss=2.86e-02\n",
            "Train Epoch: 24-12 batch_loss=2.52e-02\n",
            "Train Epoch: 24-24 batch_loss=2.66e-02\n",
            "Train Epoch: 24-36 batch_loss=2.42e-02\n",
            "Test set: Average loss: 0.7766 Average relative error: 0.1651\n",
            "Train Epoch: 25-0 batch_loss=2.82e-02\n",
            "Train Epoch: 25-12 batch_loss=2.61e-02\n",
            "Train Epoch: 25-24 batch_loss=2.28e-02\n",
            "Train Epoch: 25-36 batch_loss=2.48e-02\n",
            "Test set: Average loss: 0.7744 Average relative error: 0.1648\n",
            "Train Epoch: 26-0 batch_loss=2.65e-02\n",
            "Train Epoch: 26-12 batch_loss=2.92e-02\n",
            "Train Epoch: 26-24 batch_loss=2.41e-02\n",
            "Train Epoch: 26-36 batch_loss=2.80e-02\n",
            "Test set: Average loss: 0.7749 Average relative error: 0.1648\n",
            "Train Epoch: 27-0 batch_loss=2.68e-02\n",
            "Train Epoch: 27-12 batch_loss=2.81e-02\n",
            "Train Epoch: 27-24 batch_loss=2.37e-02\n",
            "Train Epoch: 27-36 batch_loss=2.97e-02\n",
            "Test set: Average loss: 0.7739 Average relative error: 0.1647\n",
            "Train Epoch: 28-0 batch_loss=2.42e-02\n",
            "Train Epoch: 28-12 batch_loss=2.52e-02\n",
            "Train Epoch: 28-24 batch_loss=2.54e-02\n",
            "Train Epoch: 28-36 batch_loss=2.98e-02\n",
            "Test set: Average loss: 0.7714 Average relative error: 0.1644\n",
            "Train Epoch: 29-0 batch_loss=2.63e-02\n",
            "Train Epoch: 29-12 batch_loss=2.32e-02\n",
            "Train Epoch: 29-24 batch_loss=2.67e-02\n",
            "Train Epoch: 29-36 batch_loss=2.30e-02\n",
            "Test set: Average loss: 0.7743 Average relative error: 0.1648\n",
            "Train Epoch: 30-0 batch_loss=2.62e-02\n",
            "Train Epoch: 30-12 batch_loss=2.88e-02\n",
            "Train Epoch: 30-24 batch_loss=2.56e-02\n",
            "Train Epoch: 30-36 batch_loss=2.80e-02\n",
            "Test set: Average loss: 0.7765 Average relative error: 0.1651\n",
            "Train Epoch: 31-0 batch_loss=2.50e-02\n",
            "Train Epoch: 31-12 batch_loss=2.73e-02\n",
            "Train Epoch: 31-24 batch_loss=2.84e-02\n",
            "Train Epoch: 31-36 batch_loss=2.59e-02\n",
            "Test set: Average loss: 0.7787 Average relative error: 0.1651\n",
            "Train Epoch: 32-0 batch_loss=2.52e-02\n",
            "Train Epoch: 32-12 batch_loss=2.56e-02\n",
            "Train Epoch: 32-24 batch_loss=2.82e-02\n",
            "Train Epoch: 32-36 batch_loss=2.40e-02\n",
            "Test set: Average loss: 0.7747 Average relative error: 0.1647\n",
            "Train Epoch: 33-0 batch_loss=2.82e-02\n",
            "Train Epoch: 33-12 batch_loss=2.93e-02\n",
            "Train Epoch: 33-24 batch_loss=2.69e-02\n",
            "Train Epoch: 33-36 batch_loss=2.24e-02\n",
            "Test set: Average loss: 0.7732 Average relative error: 0.1646\n",
            "Train Epoch: 34-0 batch_loss=2.67e-02\n",
            "Train Epoch: 34-12 batch_loss=2.85e-02\n",
            "Train Epoch: 34-24 batch_loss=2.89e-02\n",
            "Train Epoch: 34-36 batch_loss=2.61e-02\n",
            "Test set: Average loss: 0.7750 Average relative error: 0.1648\n",
            "Train Epoch: 35-0 batch_loss=2.82e-02\n",
            "Train Epoch: 35-12 batch_loss=2.46e-02\n",
            "Train Epoch: 35-24 batch_loss=2.59e-02\n",
            "Train Epoch: 35-36 batch_loss=3.13e-02\n",
            "Test set: Average loss: 0.7722 Average relative error: 0.1645\n",
            "Train Epoch: 36-0 batch_loss=2.83e-02\n",
            "Train Epoch: 36-12 batch_loss=2.64e-02\n",
            "Train Epoch: 36-24 batch_loss=2.62e-02\n",
            "Train Epoch: 36-36 batch_loss=2.83e-02\n",
            "Test set: Average loss: 0.7712 Average relative error: 0.1644\n",
            "Train Epoch: 37-0 batch_loss=2.65e-02\n",
            "Train Epoch: 37-12 batch_loss=2.71e-02\n",
            "Train Epoch: 37-24 batch_loss=2.71e-02\n",
            "Train Epoch: 37-36 batch_loss=2.68e-02\n",
            "Test set: Average loss: 0.7729 Average relative error: 0.1646\n",
            "Train Epoch: 38-0 batch_loss=2.10e-02\n",
            "Train Epoch: 38-12 batch_loss=2.96e-02\n",
            "Train Epoch: 38-24 batch_loss=2.41e-02\n",
            "Train Epoch: 38-36 batch_loss=3.13e-02\n",
            "Test set: Average loss: 0.7743 Average relative error: 0.1648\n",
            "Train Epoch: 39-0 batch_loss=2.75e-02\n",
            "Train Epoch: 39-12 batch_loss=2.77e-02\n",
            "Train Epoch: 39-24 batch_loss=2.65e-02\n",
            "Train Epoch: 39-36 batch_loss=2.75e-02\n",
            "Test set: Average loss: 0.7770 Average relative error: 0.1650\n",
            "Train Epoch: 40-0 batch_loss=2.96e-02\n",
            "Train Epoch: 40-12 batch_loss=2.67e-02\n",
            "Train Epoch: 40-24 batch_loss=2.78e-02\n",
            "Train Epoch: 40-36 batch_loss=2.58e-02\n",
            "Test set: Average loss: 0.7715 Average relative error: 0.1644\n",
            "Train Epoch: 41-0 batch_loss=2.24e-02\n",
            "Train Epoch: 41-12 batch_loss=2.68e-02\n",
            "Train Epoch: 41-24 batch_loss=2.76e-02\n",
            "Train Epoch: 41-36 batch_loss=2.65e-02\n",
            "Test set: Average loss: 0.7718 Average relative error: 0.1644\n",
            "Train Epoch: 42-0 batch_loss=2.75e-02\n",
            "Train Epoch: 42-12 batch_loss=2.93e-02\n",
            "Train Epoch: 42-24 batch_loss=2.66e-02\n",
            "Train Epoch: 42-36 batch_loss=2.83e-02\n",
            "Test set: Average loss: 0.7711 Average relative error: 0.1644\n",
            "Train Epoch: 43-0 batch_loss=2.50e-02\n",
            "Train Epoch: 43-12 batch_loss=2.40e-02\n",
            "Train Epoch: 43-24 batch_loss=2.31e-02\n",
            "Train Epoch: 43-36 batch_loss=2.72e-02\n",
            "Test set: Average loss: 0.7718 Average relative error: 0.1644\n",
            "Train Epoch: 44-0 batch_loss=2.14e-02\n",
            "Train Epoch: 44-12 batch_loss=2.74e-02\n",
            "Train Epoch: 44-24 batch_loss=2.46e-02\n",
            "Train Epoch: 44-36 batch_loss=2.56e-02\n",
            "Test set: Average loss: 0.7758 Average relative error: 0.1649\n",
            "Train Epoch: 45-0 batch_loss=3.00e-02\n",
            "Train Epoch: 45-12 batch_loss=2.81e-02\n",
            "Train Epoch: 45-24 batch_loss=2.37e-02\n",
            "Train Epoch: 45-36 batch_loss=2.92e-02\n",
            "Test set: Average loss: 0.7732 Average relative error: 0.1645\n",
            "Train Epoch: 46-0 batch_loss=2.68e-02\n",
            "Train Epoch: 46-12 batch_loss=2.73e-02\n",
            "Train Epoch: 46-24 batch_loss=2.38e-02\n",
            "Train Epoch: 46-36 batch_loss=2.73e-02\n",
            "Test set: Average loss: 0.7784 Average relative error: 0.1653\n",
            "Train Epoch: 47-0 batch_loss=2.74e-02\n",
            "Train Epoch: 47-12 batch_loss=2.68e-02\n",
            "Train Epoch: 47-24 batch_loss=2.58e-02\n",
            "Train Epoch: 47-36 batch_loss=2.68e-02\n",
            "Test set: Average loss: 0.7712 Average relative error: 0.1644\n",
            "Train Epoch: 48-0 batch_loss=2.54e-02\n",
            "Train Epoch: 48-12 batch_loss=2.64e-02\n",
            "Train Epoch: 48-24 batch_loss=2.78e-02\n",
            "Train Epoch: 48-36 batch_loss=2.70e-02\n",
            "Test set: Average loss: 0.7687 Average relative error: 0.1641\n",
            "Train Epoch: 49-0 batch_loss=3.42e-02\n",
            "Train Epoch: 49-12 batch_loss=2.48e-02\n",
            "Train Epoch: 49-24 batch_loss=2.27e-02\n",
            "Train Epoch: 49-36 batch_loss=2.60e-02\n",
            "Test set: Average loss: 0.7707 Average relative error: 0.1644\n",
            "Train Epoch: 50-0 batch_loss=2.69e-02\n",
            "Train Epoch: 50-12 batch_loss=2.58e-02\n",
            "Train Epoch: 50-24 batch_loss=2.58e-02\n",
            "Train Epoch: 50-36 batch_loss=2.66e-02\n",
            "Test set: Average loss: 0.7689 Average relative error: 0.1642\n",
            "Train Epoch: 51-0 batch_loss=2.36e-02\n",
            "Train Epoch: 51-12 batch_loss=2.95e-02\n",
            "Train Epoch: 51-24 batch_loss=2.32e-02\n",
            "Train Epoch: 51-36 batch_loss=2.79e-02\n",
            "Test set: Average loss: 0.7667 Average relative error: 0.1640\n",
            "Train Epoch: 52-0 batch_loss=2.72e-02\n",
            "Train Epoch: 52-12 batch_loss=2.03e-02\n",
            "Train Epoch: 52-24 batch_loss=2.64e-02\n",
            "Train Epoch: 52-36 batch_loss=2.83e-02\n",
            "Test set: Average loss: 0.7630 Average relative error: 0.1636\n",
            "Train Epoch: 53-0 batch_loss=2.40e-02\n",
            "Train Epoch: 53-12 batch_loss=2.84e-02\n",
            "Train Epoch: 53-24 batch_loss=2.98e-02\n",
            "Train Epoch: 53-36 batch_loss=2.44e-02\n",
            "Test set: Average loss: 0.7621 Average relative error: 0.1636\n",
            "Train Epoch: 54-0 batch_loss=2.47e-02\n",
            "Train Epoch: 54-12 batch_loss=2.57e-02\n",
            "Train Epoch: 54-24 batch_loss=2.26e-02\n",
            "Train Epoch: 54-36 batch_loss=2.77e-02\n",
            "Test set: Average loss: 0.7496 Average relative error: 0.1624\n",
            "Train Epoch: 55-0 batch_loss=2.70e-02\n",
            "Train Epoch: 55-12 batch_loss=2.24e-02\n",
            "Train Epoch: 55-24 batch_loss=2.61e-02\n",
            "Train Epoch: 55-36 batch_loss=2.38e-02\n",
            "Test set: Average loss: 0.7356 Average relative error: 0.1611\n",
            "Train Epoch: 56-0 batch_loss=2.66e-02\n",
            "Train Epoch: 56-12 batch_loss=2.54e-02\n",
            "Train Epoch: 56-24 batch_loss=2.34e-02\n",
            "Train Epoch: 56-36 batch_loss=2.97e-02\n",
            "Test set: Average loss: 0.7166 Average relative error: 0.1590\n",
            "Train Epoch: 57-0 batch_loss=2.27e-02\n",
            "Train Epoch: 57-12 batch_loss=2.40e-02\n",
            "Train Epoch: 57-24 batch_loss=2.17e-02\n",
            "Train Epoch: 57-36 batch_loss=2.29e-02\n",
            "Test set: Average loss: 0.6973 Average relative error: 0.1565\n",
            "Train Epoch: 58-0 batch_loss=1.97e-02\n",
            "Train Epoch: 58-12 batch_loss=2.36e-02\n",
            "Train Epoch: 58-24 batch_loss=2.41e-02\n",
            "Train Epoch: 58-36 batch_loss=2.44e-02\n",
            "Test set: Average loss: 0.6886 Average relative error: 0.1555\n",
            "Train Epoch: 59-0 batch_loss=2.30e-02\n",
            "Train Epoch: 59-12 batch_loss=2.50e-02\n",
            "Train Epoch: 59-24 batch_loss=2.31e-02\n",
            "Train Epoch: 59-36 batch_loss=2.70e-02\n",
            "Test set: Average loss: 0.6820 Average relative error: 0.1545\n",
            "Train Epoch: 60-0 batch_loss=2.31e-02\n",
            "Train Epoch: 60-12 batch_loss=2.32e-02\n",
            "Train Epoch: 60-24 batch_loss=1.99e-02\n",
            "Train Epoch: 60-36 batch_loss=2.12e-02\n",
            "Test set: Average loss: 0.6742 Average relative error: 0.1539\n",
            "Train Epoch: 61-0 batch_loss=2.09e-02\n",
            "Train Epoch: 61-12 batch_loss=2.32e-02\n",
            "Train Epoch: 61-24 batch_loss=2.33e-02\n",
            "Train Epoch: 61-36 batch_loss=2.11e-02\n",
            "Test set: Average loss: 0.6679 Average relative error: 0.1530\n",
            "Train Epoch: 62-0 batch_loss=2.14e-02\n",
            "Train Epoch: 62-12 batch_loss=2.48e-02\n",
            "Train Epoch: 62-24 batch_loss=2.58e-02\n",
            "Train Epoch: 62-36 batch_loss=2.80e-02\n",
            "Test set: Average loss: 0.6657 Average relative error: 0.1527\n",
            "Train Epoch: 63-0 batch_loss=2.23e-02\n",
            "Train Epoch: 63-12 batch_loss=2.08e-02\n",
            "Train Epoch: 63-24 batch_loss=2.40e-02\n",
            "Train Epoch: 63-36 batch_loss=2.08e-02\n",
            "Test set: Average loss: 0.6581 Average relative error: 0.1520\n",
            "Train Epoch: 64-0 batch_loss=2.05e-02\n",
            "Train Epoch: 64-12 batch_loss=2.33e-02\n",
            "Train Epoch: 64-24 batch_loss=2.10e-02\n",
            "Train Epoch: 64-36 batch_loss=1.94e-02\n",
            "Test set: Average loss: 0.6530 Average relative error: 0.1512\n",
            "Train Epoch: 65-0 batch_loss=1.95e-02\n",
            "Train Epoch: 65-12 batch_loss=2.06e-02\n",
            "Train Epoch: 65-24 batch_loss=1.76e-02\n",
            "Train Epoch: 65-36 batch_loss=2.43e-02\n",
            "Test set: Average loss: 0.6495 Average relative error: 0.1505\n",
            "Train Epoch: 66-0 batch_loss=2.24e-02\n",
            "Train Epoch: 66-12 batch_loss=2.34e-02\n",
            "Train Epoch: 66-24 batch_loss=2.10e-02\n",
            "Train Epoch: 66-36 batch_loss=2.08e-02\n",
            "Test set: Average loss: 0.6412 Average relative error: 0.1495\n",
            "Train Epoch: 67-0 batch_loss=1.72e-02\n",
            "Train Epoch: 67-12 batch_loss=2.35e-02\n",
            "Train Epoch: 67-24 batch_loss=2.05e-02\n",
            "Train Epoch: 67-36 batch_loss=2.36e-02\n",
            "Test set: Average loss: 0.6311 Average relative error: 0.1482\n",
            "Train Epoch: 68-0 batch_loss=1.93e-02\n",
            "Train Epoch: 68-12 batch_loss=1.67e-02\n",
            "Train Epoch: 68-24 batch_loss=1.96e-02\n",
            "Train Epoch: 68-36 batch_loss=1.87e-02\n",
            "Test set: Average loss: 0.6220 Average relative error: 0.1468\n",
            "Train Epoch: 69-0 batch_loss=1.84e-02\n",
            "Train Epoch: 69-12 batch_loss=2.19e-02\n",
            "Train Epoch: 69-24 batch_loss=2.03e-02\n",
            "Train Epoch: 69-36 batch_loss=2.18e-02\n",
            "Test set: Average loss: 0.6109 Average relative error: 0.1455\n",
            "Train Epoch: 70-0 batch_loss=2.33e-02\n",
            "Train Epoch: 70-12 batch_loss=2.17e-02\n",
            "Train Epoch: 70-24 batch_loss=2.01e-02\n",
            "Train Epoch: 70-36 batch_loss=1.95e-02\n",
            "Test set: Average loss: 0.5968 Average relative error: 0.1438\n",
            "Train Epoch: 71-0 batch_loss=2.17e-02\n",
            "Train Epoch: 71-12 batch_loss=1.77e-02\n",
            "Train Epoch: 71-24 batch_loss=1.77e-02\n",
            "Train Epoch: 71-36 batch_loss=1.70e-02\n",
            "Test set: Average loss: 0.5800 Average relative error: 0.1417\n",
            "Train Epoch: 72-0 batch_loss=1.65e-02\n",
            "Train Epoch: 72-12 batch_loss=1.80e-02\n",
            "Train Epoch: 72-24 batch_loss=2.08e-02\n",
            "Train Epoch: 72-36 batch_loss=1.49e-02\n",
            "Test set: Average loss: 0.5543 Average relative error: 0.1384\n",
            "Train Epoch: 73-0 batch_loss=1.76e-02\n",
            "Train Epoch: 73-12 batch_loss=1.92e-02\n",
            "Train Epoch: 73-24 batch_loss=1.76e-02\n",
            "Train Epoch: 73-36 batch_loss=1.39e-02\n",
            "Test set: Average loss: 0.5295 Average relative error: 0.1352\n",
            "Train Epoch: 74-0 batch_loss=1.73e-02\n",
            "Train Epoch: 74-12 batch_loss=1.55e-02\n",
            "Train Epoch: 74-24 batch_loss=1.64e-02\n",
            "Train Epoch: 74-36 batch_loss=1.72e-02\n",
            "Test set: Average loss: 0.5135 Average relative error: 0.1330\n",
            "Train Epoch: 75-0 batch_loss=1.84e-02\n",
            "Train Epoch: 75-12 batch_loss=1.72e-02\n",
            "Train Epoch: 75-24 batch_loss=1.69e-02\n",
            "Train Epoch: 75-36 batch_loss=1.77e-02\n",
            "Test set: Average loss: 0.4973 Average relative error: 0.1308\n",
            "Train Epoch: 76-0 batch_loss=1.75e-02\n",
            "Train Epoch: 76-12 batch_loss=1.96e-02\n",
            "Train Epoch: 76-24 batch_loss=1.77e-02\n",
            "Train Epoch: 76-36 batch_loss=1.50e-02\n",
            "Test set: Average loss: 0.4854 Average relative error: 0.1288\n",
            "Train Epoch: 77-0 batch_loss=1.73e-02\n",
            "Train Epoch: 77-12 batch_loss=1.74e-02\n",
            "Train Epoch: 77-24 batch_loss=1.71e-02\n",
            "Train Epoch: 77-36 batch_loss=1.50e-02\n",
            "Test set: Average loss: 0.4718 Average relative error: 0.1274\n",
            "Train Epoch: 78-0 batch_loss=1.27e-02\n",
            "Train Epoch: 78-12 batch_loss=1.58e-02\n",
            "Train Epoch: 78-24 batch_loss=1.30e-02\n",
            "Train Epoch: 78-36 batch_loss=1.42e-02\n",
            "Test set: Average loss: 0.4608 Average relative error: 0.1256\n",
            "Train Epoch: 79-0 batch_loss=1.12e-02\n",
            "Train Epoch: 79-12 batch_loss=1.50e-02\n",
            "Train Epoch: 79-24 batch_loss=1.59e-02\n",
            "Train Epoch: 79-36 batch_loss=1.51e-02\n",
            "Test set: Average loss: 0.4508 Average relative error: 0.1241\n",
            "Train Epoch: 80-0 batch_loss=1.64e-02\n",
            "Train Epoch: 80-12 batch_loss=1.46e-02\n",
            "Train Epoch: 80-24 batch_loss=1.55e-02\n",
            "Train Epoch: 80-36 batch_loss=1.50e-02\n",
            "Test set: Average loss: 0.4404 Average relative error: 0.1229\n",
            "Train Epoch: 81-0 batch_loss=1.45e-02\n",
            "Train Epoch: 81-12 batch_loss=1.41e-02\n",
            "Train Epoch: 81-24 batch_loss=1.50e-02\n",
            "Train Epoch: 81-36 batch_loss=1.47e-02\n",
            "Test set: Average loss: 0.4247 Average relative error: 0.1207\n",
            "Train Epoch: 82-0 batch_loss=1.48e-02\n",
            "Train Epoch: 82-12 batch_loss=1.29e-02\n",
            "Train Epoch: 82-24 batch_loss=1.19e-02\n",
            "Train Epoch: 82-36 batch_loss=1.45e-02\n",
            "Test set: Average loss: 0.4125 Average relative error: 0.1188\n",
            "Train Epoch: 83-0 batch_loss=1.09e-02\n",
            "Train Epoch: 83-12 batch_loss=1.23e-02\n",
            "Train Epoch: 83-24 batch_loss=1.15e-02\n",
            "Train Epoch: 83-36 batch_loss=1.33e-02\n",
            "Test set: Average loss: 0.3991 Average relative error: 0.1169\n",
            "Train Epoch: 84-0 batch_loss=1.07e-02\n",
            "Train Epoch: 84-12 batch_loss=9.56e-03\n",
            "Train Epoch: 84-24 batch_loss=1.21e-02\n",
            "Train Epoch: 84-36 batch_loss=1.02e-02\n",
            "Test set: Average loss: 0.3843 Average relative error: 0.1146\n",
            "Train Epoch: 85-0 batch_loss=1.39e-02\n",
            "Train Epoch: 85-12 batch_loss=1.05e-02\n",
            "Train Epoch: 85-24 batch_loss=1.22e-02\n",
            "Train Epoch: 85-36 batch_loss=1.31e-02\n",
            "Test set: Average loss: 0.3685 Average relative error: 0.1123\n",
            "Train Epoch: 86-0 batch_loss=1.23e-02\n",
            "Train Epoch: 86-12 batch_loss=1.19e-02\n",
            "Train Epoch: 86-24 batch_loss=1.15e-02\n",
            "Train Epoch: 86-36 batch_loss=1.08e-02\n",
            "Test set: Average loss: 0.3597 Average relative error: 0.1104\n",
            "Train Epoch: 87-0 batch_loss=1.05e-02\n",
            "Train Epoch: 87-12 batch_loss=1.23e-02\n",
            "Train Epoch: 87-24 batch_loss=1.01e-02\n",
            "Train Epoch: 87-36 batch_loss=1.14e-02\n",
            "Test set: Average loss: 0.3440 Average relative error: 0.1079\n",
            "Train Epoch: 88-0 batch_loss=1.32e-02\n",
            "Train Epoch: 88-12 batch_loss=1.25e-02\n",
            "Train Epoch: 88-24 batch_loss=9.73e-03\n",
            "Train Epoch: 88-36 batch_loss=1.03e-02\n",
            "Test set: Average loss: 0.3335 Average relative error: 0.1065\n",
            "Train Epoch: 89-0 batch_loss=1.10e-02\n",
            "Train Epoch: 89-12 batch_loss=9.99e-03\n",
            "Train Epoch: 89-24 batch_loss=9.20e-03\n",
            "Train Epoch: 89-36 batch_loss=9.15e-03\n",
            "Test set: Average loss: 0.3227 Average relative error: 0.1040\n",
            "Train Epoch: 90-0 batch_loss=7.89e-03\n",
            "Train Epoch: 90-12 batch_loss=8.37e-03\n",
            "Train Epoch: 90-24 batch_loss=9.47e-03\n",
            "Train Epoch: 90-36 batch_loss=1.12e-02\n",
            "Test set: Average loss: 0.3059 Average relative error: 0.1015\n",
            "Train Epoch: 91-0 batch_loss=7.97e-03\n",
            "Train Epoch: 91-12 batch_loss=1.16e-02\n",
            "Train Epoch: 91-24 batch_loss=8.36e-03\n",
            "Train Epoch: 91-36 batch_loss=8.48e-03\n",
            "Test set: Average loss: 0.2977 Average relative error: 0.0993\n",
            "Train Epoch: 92-0 batch_loss=7.31e-03\n",
            "Train Epoch: 92-12 batch_loss=1.13e-02\n",
            "Train Epoch: 92-24 batch_loss=8.82e-03\n",
            "Train Epoch: 92-36 batch_loss=1.13e-02\n",
            "Test set: Average loss: 0.2866 Average relative error: 0.0973\n",
            "Train Epoch: 93-0 batch_loss=6.81e-03\n",
            "Train Epoch: 93-12 batch_loss=7.37e-03\n",
            "Train Epoch: 93-24 batch_loss=8.80e-03\n",
            "Train Epoch: 93-36 batch_loss=1.09e-02\n",
            "Test set: Average loss: 0.2792 Average relative error: 0.0958\n",
            "Train Epoch: 94-0 batch_loss=6.86e-03\n",
            "Train Epoch: 94-12 batch_loss=8.52e-03\n",
            "Train Epoch: 94-24 batch_loss=8.36e-03\n",
            "Train Epoch: 94-36 batch_loss=9.08e-03\n",
            "Test set: Average loss: 0.2695 Average relative error: 0.0940\n",
            "Train Epoch: 95-0 batch_loss=8.14e-03\n",
            "Train Epoch: 95-12 batch_loss=7.72e-03\n",
            "Train Epoch: 95-24 batch_loss=7.97e-03\n",
            "Train Epoch: 95-36 batch_loss=9.72e-03\n",
            "Test set: Average loss: 0.2602 Average relative error: 0.0920\n",
            "Train Epoch: 96-0 batch_loss=6.66e-03\n",
            "Train Epoch: 96-12 batch_loss=7.81e-03\n",
            "Train Epoch: 96-24 batch_loss=7.12e-03\n",
            "Train Epoch: 96-36 batch_loss=8.92e-03\n",
            "Test set: Average loss: 0.2537 Average relative error: 0.0906\n",
            "Train Epoch: 97-0 batch_loss=8.99e-03\n",
            "Train Epoch: 97-12 batch_loss=5.82e-03\n",
            "Train Epoch: 97-24 batch_loss=6.75e-03\n",
            "Train Epoch: 97-36 batch_loss=7.84e-03\n",
            "Test set: Average loss: 0.2487 Average relative error: 0.0897\n",
            "Train Epoch: 98-0 batch_loss=6.95e-03\n",
            "Train Epoch: 98-12 batch_loss=8.03e-03\n",
            "Train Epoch: 98-24 batch_loss=7.07e-03\n",
            "Train Epoch: 98-36 batch_loss=7.91e-03\n",
            "Test set: Average loss: 0.2416 Average relative error: 0.0884\n",
            "Train Epoch: 99-0 batch_loss=6.94e-03\n",
            "Train Epoch: 99-12 batch_loss=8.02e-03\n",
            "Train Epoch: 99-24 batch_loss=9.40e-03\n",
            "Train Epoch: 99-36 batch_loss=6.11e-03\n",
            "Test set: Average loss: 0.2408 Average relative error: 0.0875\n",
            "Train Epoch: 100-0 batch_loss=6.95e-03\n",
            "Train Epoch: 100-12 batch_loss=6.42e-03\n",
            "Train Epoch: 100-24 batch_loss=6.14e-03\n",
            "Train Epoch: 100-36 batch_loss=6.49e-03\n",
            "Test set: Average loss: 0.2316 Average relative error: 0.0863\n",
            "Train Epoch: 101-0 batch_loss=7.12e-03\n",
            "Train Epoch: 101-12 batch_loss=7.45e-03\n",
            "Train Epoch: 101-24 batch_loss=9.35e-03\n",
            "Train Epoch: 101-36 batch_loss=7.07e-03\n",
            "Test set: Average loss: 0.2281 Average relative error: 0.0855\n",
            "Train Epoch: 102-0 batch_loss=6.76e-03\n",
            "Train Epoch: 102-12 batch_loss=9.12e-03\n",
            "Train Epoch: 102-24 batch_loss=5.54e-03\n",
            "Train Epoch: 102-36 batch_loss=6.89e-03\n",
            "Test set: Average loss: 0.2219 Average relative error: 0.0836\n",
            "Train Epoch: 103-0 batch_loss=7.07e-03\n",
            "Train Epoch: 103-12 batch_loss=5.46e-03\n",
            "Train Epoch: 103-24 batch_loss=6.48e-03\n",
            "Train Epoch: 103-36 batch_loss=8.49e-03\n",
            "Test set: Average loss: 0.2179 Average relative error: 0.0831\n",
            "Train Epoch: 104-0 batch_loss=7.28e-03\n",
            "Train Epoch: 104-12 batch_loss=7.11e-03\n",
            "Train Epoch: 104-24 batch_loss=5.64e-03\n",
            "Train Epoch: 104-36 batch_loss=8.42e-03\n",
            "Test set: Average loss: 0.2138 Average relative error: 0.0826\n",
            "Train Epoch: 105-0 batch_loss=5.13e-03\n",
            "Train Epoch: 105-12 batch_loss=5.62e-03\n",
            "Train Epoch: 105-24 batch_loss=6.94e-03\n",
            "Train Epoch: 105-36 batch_loss=7.14e-03\n",
            "Test set: Average loss: 0.2123 Average relative error: 0.0812\n",
            "Train Epoch: 106-0 batch_loss=6.36e-03\n",
            "Train Epoch: 106-12 batch_loss=6.41e-03\n",
            "Train Epoch: 106-24 batch_loss=7.66e-03\n",
            "Train Epoch: 106-36 batch_loss=7.51e-03\n",
            "Test set: Average loss: 0.2087 Average relative error: 0.0804\n",
            "Train Epoch: 107-0 batch_loss=6.89e-03\n",
            "Train Epoch: 107-12 batch_loss=6.41e-03\n",
            "Train Epoch: 107-24 batch_loss=5.05e-03\n",
            "Train Epoch: 107-36 batch_loss=5.67e-03\n",
            "Test set: Average loss: 0.2033 Average relative error: 0.0793\n",
            "Train Epoch: 108-0 batch_loss=6.80e-03\n",
            "Train Epoch: 108-12 batch_loss=6.86e-03\n",
            "Train Epoch: 108-24 batch_loss=6.64e-03\n",
            "Train Epoch: 108-36 batch_loss=7.41e-03\n",
            "Test set: Average loss: 0.2002 Average relative error: 0.0789\n",
            "Train Epoch: 109-0 batch_loss=7.31e-03\n",
            "Train Epoch: 109-12 batch_loss=5.46e-03\n",
            "Train Epoch: 109-24 batch_loss=5.19e-03\n",
            "Train Epoch: 109-36 batch_loss=5.53e-03\n",
            "Test set: Average loss: 0.1953 Average relative error: 0.0778\n",
            "Train Epoch: 110-0 batch_loss=5.24e-03\n",
            "Train Epoch: 110-12 batch_loss=6.09e-03\n",
            "Train Epoch: 110-24 batch_loss=6.91e-03\n",
            "Train Epoch: 110-36 batch_loss=5.16e-03\n",
            "Test set: Average loss: 0.1939 Average relative error: 0.0774\n",
            "Train Epoch: 111-0 batch_loss=5.85e-03\n",
            "Train Epoch: 111-12 batch_loss=5.11e-03\n",
            "Train Epoch: 111-24 batch_loss=6.49e-03\n",
            "Train Epoch: 111-36 batch_loss=6.28e-03\n",
            "Test set: Average loss: 0.1915 Average relative error: 0.0773\n",
            "Train Epoch: 112-0 batch_loss=7.28e-03\n",
            "Train Epoch: 112-12 batch_loss=6.37e-03\n",
            "Train Epoch: 112-24 batch_loss=5.08e-03\n",
            "Train Epoch: 112-36 batch_loss=4.74e-03\n",
            "Test set: Average loss: 0.1888 Average relative error: 0.0758\n",
            "Train Epoch: 113-0 batch_loss=5.33e-03\n",
            "Train Epoch: 113-12 batch_loss=4.83e-03\n",
            "Train Epoch: 113-24 batch_loss=7.30e-03\n",
            "Train Epoch: 113-36 batch_loss=5.96e-03\n",
            "Test set: Average loss: 0.1853 Average relative error: 0.0755\n",
            "Train Epoch: 114-0 batch_loss=5.16e-03\n",
            "Train Epoch: 114-12 batch_loss=4.35e-03\n",
            "Train Epoch: 114-24 batch_loss=6.92e-03\n",
            "Train Epoch: 114-36 batch_loss=6.35e-03\n",
            "Test set: Average loss: 0.1819 Average relative error: 0.0746\n",
            "Train Epoch: 115-0 batch_loss=6.68e-03\n",
            "Train Epoch: 115-12 batch_loss=5.85e-03\n",
            "Train Epoch: 115-24 batch_loss=5.63e-03\n",
            "Train Epoch: 115-36 batch_loss=6.52e-03\n",
            "Test set: Average loss: 0.1833 Average relative error: 0.0745\n",
            "Train Epoch: 116-0 batch_loss=4.72e-03\n",
            "Train Epoch: 116-12 batch_loss=4.32e-03\n",
            "Train Epoch: 116-24 batch_loss=6.53e-03\n",
            "Train Epoch: 116-36 batch_loss=4.73e-03\n",
            "Test set: Average loss: 0.1805 Average relative error: 0.0737\n",
            "Train Epoch: 117-0 batch_loss=4.31e-03\n",
            "Train Epoch: 117-12 batch_loss=8.61e-03\n",
            "Train Epoch: 117-24 batch_loss=4.72e-03\n",
            "Train Epoch: 117-36 batch_loss=4.07e-03\n",
            "Test set: Average loss: 0.1757 Average relative error: 0.0730\n",
            "Train Epoch: 118-0 batch_loss=3.89e-03\n",
            "Train Epoch: 118-12 batch_loss=4.58e-03\n",
            "Train Epoch: 118-24 batch_loss=4.36e-03\n",
            "Train Epoch: 118-36 batch_loss=4.38e-03\n",
            "Test set: Average loss: 0.1751 Average relative error: 0.0728\n",
            "Train Epoch: 119-0 batch_loss=6.38e-03\n",
            "Train Epoch: 119-12 batch_loss=3.97e-03\n",
            "Train Epoch: 119-24 batch_loss=7.12e-03\n",
            "Train Epoch: 119-36 batch_loss=4.68e-03\n",
            "Test set: Average loss: 0.1717 Average relative error: 0.0722\n",
            "Train Epoch: 120-0 batch_loss=5.13e-03\n",
            "Train Epoch: 120-12 batch_loss=4.23e-03\n",
            "Train Epoch: 120-24 batch_loss=6.07e-03\n",
            "Train Epoch: 120-36 batch_loss=4.55e-03\n",
            "Test set: Average loss: 0.1689 Average relative error: 0.0716\n",
            "Train Epoch: 121-0 batch_loss=4.47e-03\n",
            "Train Epoch: 121-12 batch_loss=5.34e-03\n",
            "Train Epoch: 121-24 batch_loss=5.30e-03\n",
            "Train Epoch: 121-36 batch_loss=3.77e-03\n",
            "Test set: Average loss: 0.1700 Average relative error: 0.0714\n",
            "Train Epoch: 122-0 batch_loss=6.85e-03\n",
            "Train Epoch: 122-12 batch_loss=3.45e-03\n",
            "Train Epoch: 122-24 batch_loss=5.67e-03\n",
            "Train Epoch: 122-36 batch_loss=5.40e-03\n",
            "Test set: Average loss: 0.1673 Average relative error: 0.0708\n",
            "Train Epoch: 123-0 batch_loss=5.97e-03\n",
            "Train Epoch: 123-12 batch_loss=4.91e-03\n",
            "Train Epoch: 123-24 batch_loss=5.03e-03\n",
            "Train Epoch: 123-36 batch_loss=4.76e-03\n",
            "Test set: Average loss: 0.1673 Average relative error: 0.0707\n",
            "Train Epoch: 124-0 batch_loss=4.98e-03\n",
            "Train Epoch: 124-12 batch_loss=3.96e-03\n",
            "Train Epoch: 124-24 batch_loss=5.86e-03\n",
            "Train Epoch: 124-36 batch_loss=4.56e-03\n",
            "Test set: Average loss: 0.1618 Average relative error: 0.0700\n",
            "Train Epoch: 125-0 batch_loss=6.83e-03\n",
            "Train Epoch: 125-12 batch_loss=4.21e-03\n",
            "Train Epoch: 125-24 batch_loss=4.81e-03\n",
            "Train Epoch: 125-36 batch_loss=4.16e-03\n",
            "Test set: Average loss: 0.1594 Average relative error: 0.0694\n",
            "Train Epoch: 126-0 batch_loss=4.60e-03\n",
            "Train Epoch: 126-12 batch_loss=4.38e-03\n",
            "Train Epoch: 126-24 batch_loss=4.04e-03\n",
            "Train Epoch: 126-36 batch_loss=4.15e-03\n",
            "Test set: Average loss: 0.1584 Average relative error: 0.0687\n",
            "Train Epoch: 127-0 batch_loss=2.71e-03\n",
            "Train Epoch: 127-12 batch_loss=5.67e-03\n",
            "Train Epoch: 127-24 batch_loss=5.23e-03\n",
            "Train Epoch: 127-36 batch_loss=4.79e-03\n",
            "Test set: Average loss: 0.1550 Average relative error: 0.0684\n",
            "Train Epoch: 128-0 batch_loss=4.90e-03\n",
            "Train Epoch: 128-12 batch_loss=3.39e-03\n",
            "Train Epoch: 128-24 batch_loss=4.15e-03\n",
            "Train Epoch: 128-36 batch_loss=4.26e-03\n",
            "Test set: Average loss: 0.1532 Average relative error: 0.0679\n",
            "Train Epoch: 129-0 batch_loss=4.22e-03\n",
            "Train Epoch: 129-12 batch_loss=5.98e-03\n",
            "Train Epoch: 129-24 batch_loss=4.33e-03\n",
            "Train Epoch: 129-36 batch_loss=5.44e-03\n",
            "Test set: Average loss: 0.1525 Average relative error: 0.0677\n",
            "Train Epoch: 130-0 batch_loss=5.97e-03\n",
            "Train Epoch: 130-12 batch_loss=4.68e-03\n",
            "Train Epoch: 130-24 batch_loss=3.52e-03\n",
            "Train Epoch: 130-36 batch_loss=3.48e-03\n",
            "Test set: Average loss: 0.1536 Average relative error: 0.0676\n",
            "Train Epoch: 131-0 batch_loss=3.97e-03\n",
            "Train Epoch: 131-12 batch_loss=5.54e-03\n",
            "Train Epoch: 131-24 batch_loss=4.80e-03\n",
            "Train Epoch: 131-36 batch_loss=4.96e-03\n",
            "Test set: Average loss: 0.1500 Average relative error: 0.0670\n",
            "Train Epoch: 132-0 batch_loss=3.85e-03\n",
            "Train Epoch: 132-12 batch_loss=4.60e-03\n",
            "Train Epoch: 132-24 batch_loss=4.63e-03\n",
            "Train Epoch: 132-36 batch_loss=3.65e-03\n",
            "Test set: Average loss: 0.1501 Average relative error: 0.0669\n",
            "Train Epoch: 133-0 batch_loss=5.87e-03\n",
            "Train Epoch: 133-12 batch_loss=3.31e-03\n",
            "Train Epoch: 133-24 batch_loss=5.40e-03\n",
            "Train Epoch: 133-36 batch_loss=3.96e-03\n",
            "Test set: Average loss: 0.1465 Average relative error: 0.0665\n",
            "Train Epoch: 134-0 batch_loss=4.52e-03\n",
            "Train Epoch: 134-12 batch_loss=5.38e-03\n",
            "Train Epoch: 134-24 batch_loss=3.80e-03\n",
            "Train Epoch: 134-36 batch_loss=5.57e-03\n",
            "Test set: Average loss: 0.1459 Average relative error: 0.0660\n",
            "Train Epoch: 135-0 batch_loss=4.83e-03\n",
            "Train Epoch: 135-12 batch_loss=2.51e-03\n",
            "Train Epoch: 135-24 batch_loss=4.49e-03\n",
            "Train Epoch: 135-36 batch_loss=3.19e-03\n",
            "Test set: Average loss: 0.1446 Average relative error: 0.0657\n",
            "Train Epoch: 136-0 batch_loss=3.55e-03\n",
            "Train Epoch: 136-12 batch_loss=5.16e-03\n",
            "Train Epoch: 136-24 batch_loss=4.87e-03\n",
            "Train Epoch: 136-36 batch_loss=4.89e-03\n",
            "Test set: Average loss: 0.1407 Average relative error: 0.0653\n",
            "Train Epoch: 137-0 batch_loss=4.70e-03\n",
            "Train Epoch: 137-12 batch_loss=4.28e-03\n",
            "Train Epoch: 137-24 batch_loss=4.61e-03\n",
            "Train Epoch: 137-36 batch_loss=3.15e-03\n",
            "Test set: Average loss: 0.1396 Average relative error: 0.0647\n",
            "Train Epoch: 138-0 batch_loss=4.51e-03\n",
            "Train Epoch: 138-12 batch_loss=3.35e-03\n",
            "Train Epoch: 138-24 batch_loss=4.18e-03\n",
            "Train Epoch: 138-36 batch_loss=5.01e-03\n",
            "Test set: Average loss: 0.1388 Average relative error: 0.0645\n",
            "Train Epoch: 139-0 batch_loss=3.06e-03\n",
            "Train Epoch: 139-12 batch_loss=5.52e-03\n",
            "Train Epoch: 139-24 batch_loss=3.94e-03\n",
            "Train Epoch: 139-36 batch_loss=4.42e-03\n",
            "Test set: Average loss: 0.1362 Average relative error: 0.0641\n",
            "Train Epoch: 140-0 batch_loss=3.77e-03\n",
            "Train Epoch: 140-12 batch_loss=3.12e-03\n",
            "Train Epoch: 140-24 batch_loss=3.63e-03\n",
            "Train Epoch: 140-36 batch_loss=3.63e-03\n",
            "Test set: Average loss: 0.1351 Average relative error: 0.0640\n",
            "Train Epoch: 141-0 batch_loss=4.25e-03\n",
            "Train Epoch: 141-12 batch_loss=5.08e-03\n",
            "Train Epoch: 141-24 batch_loss=4.66e-03\n",
            "Train Epoch: 141-36 batch_loss=3.44e-03\n",
            "Test set: Average loss: 0.1332 Average relative error: 0.0634\n",
            "Train Epoch: 142-0 batch_loss=5.32e-03\n",
            "Train Epoch: 142-12 batch_loss=4.61e-03\n",
            "Train Epoch: 142-24 batch_loss=3.99e-03\n",
            "Train Epoch: 142-36 batch_loss=5.20e-03\n",
            "Test set: Average loss: 0.1310 Average relative error: 0.0629\n",
            "Train Epoch: 143-0 batch_loss=2.91e-03\n",
            "Train Epoch: 143-12 batch_loss=2.86e-03\n",
            "Train Epoch: 143-24 batch_loss=3.02e-03\n",
            "Train Epoch: 143-36 batch_loss=3.45e-03\n",
            "Test set: Average loss: 0.1312 Average relative error: 0.0628\n",
            "Train Epoch: 144-0 batch_loss=2.32e-03\n",
            "Train Epoch: 144-12 batch_loss=3.49e-03\n",
            "Train Epoch: 144-24 batch_loss=3.65e-03\n",
            "Train Epoch: 144-36 batch_loss=3.93e-03\n",
            "Test set: Average loss: 0.1276 Average relative error: 0.0622\n",
            "Train Epoch: 145-0 batch_loss=3.54e-03\n",
            "Train Epoch: 145-12 batch_loss=5.04e-03\n",
            "Train Epoch: 145-24 batch_loss=4.26e-03\n",
            "Train Epoch: 145-36 batch_loss=3.96e-03\n",
            "Test set: Average loss: 0.1258 Average relative error: 0.0618\n",
            "Train Epoch: 146-0 batch_loss=3.38e-03\n",
            "Train Epoch: 146-12 batch_loss=2.83e-03\n",
            "Train Epoch: 146-24 batch_loss=4.55e-03\n",
            "Train Epoch: 146-36 batch_loss=5.01e-03\n",
            "Test set: Average loss: 0.1253 Average relative error: 0.0619\n",
            "Train Epoch: 147-0 batch_loss=3.55e-03\n",
            "Train Epoch: 147-12 batch_loss=2.90e-03\n",
            "Train Epoch: 147-24 batch_loss=3.47e-03\n",
            "Train Epoch: 147-36 batch_loss=3.10e-03\n",
            "Test set: Average loss: 0.1228 Average relative error: 0.0612\n",
            "Train Epoch: 148-0 batch_loss=3.88e-03\n",
            "Train Epoch: 148-12 batch_loss=3.65e-03\n",
            "Train Epoch: 148-24 batch_loss=4.60e-03\n",
            "Train Epoch: 148-36 batch_loss=3.20e-03\n",
            "Test set: Average loss: 0.1224 Average relative error: 0.0612\n",
            "Train Epoch: 149-0 batch_loss=3.91e-03\n",
            "Train Epoch: 149-12 batch_loss=2.86e-03\n",
            "Train Epoch: 149-24 batch_loss=3.77e-03\n",
            "Train Epoch: 149-36 batch_loss=4.84e-03\n",
            "Test set: Average loss: 0.1211 Average relative error: 0.0607\n",
            "Train Epoch: 150-0 batch_loss=3.42e-03\n",
            "Train Epoch: 150-12 batch_loss=3.17e-03\n",
            "Train Epoch: 150-24 batch_loss=3.65e-03\n",
            "Train Epoch: 150-36 batch_loss=4.63e-03\n",
            "Test set: Average loss: 0.1182 Average relative error: 0.0602\n",
            "Train Epoch: 151-0 batch_loss=3.59e-03\n",
            "Train Epoch: 151-12 batch_loss=2.62e-03\n",
            "Train Epoch: 151-24 batch_loss=3.48e-03\n",
            "Train Epoch: 151-36 batch_loss=3.98e-03\n",
            "Test set: Average loss: 0.1167 Average relative error: 0.0599\n",
            "Train Epoch: 152-0 batch_loss=3.53e-03\n",
            "Train Epoch: 152-12 batch_loss=4.03e-03\n",
            "Train Epoch: 152-24 batch_loss=4.69e-03\n",
            "Train Epoch: 152-36 batch_loss=3.32e-03\n",
            "Test set: Average loss: 0.1148 Average relative error: 0.0593\n",
            "Train Epoch: 153-0 batch_loss=3.09e-03\n",
            "Train Epoch: 153-12 batch_loss=3.63e-03\n",
            "Train Epoch: 153-24 batch_loss=3.21e-03\n",
            "Train Epoch: 153-36 batch_loss=3.93e-03\n",
            "Test set: Average loss: 0.1129 Average relative error: 0.0589\n",
            "Train Epoch: 154-0 batch_loss=3.42e-03\n",
            "Train Epoch: 154-12 batch_loss=3.37e-03\n",
            "Train Epoch: 154-24 batch_loss=4.45e-03\n",
            "Train Epoch: 154-36 batch_loss=4.14e-03\n",
            "Test set: Average loss: 0.1109 Average relative error: 0.0588\n",
            "Train Epoch: 155-0 batch_loss=3.41e-03\n",
            "Train Epoch: 155-12 batch_loss=3.50e-03\n",
            "Train Epoch: 155-24 batch_loss=3.07e-03\n",
            "Train Epoch: 155-36 batch_loss=3.00e-03\n",
            "Test set: Average loss: 0.1085 Average relative error: 0.0580\n",
            "Train Epoch: 156-0 batch_loss=2.74e-03\n",
            "Train Epoch: 156-12 batch_loss=3.70e-03\n",
            "Train Epoch: 156-24 batch_loss=3.57e-03\n",
            "Train Epoch: 156-36 batch_loss=3.46e-03\n",
            "Test set: Average loss: 0.1067 Average relative error: 0.0576\n",
            "Train Epoch: 157-0 batch_loss=2.82e-03\n",
            "Train Epoch: 157-12 batch_loss=3.27e-03\n",
            "Train Epoch: 157-24 batch_loss=2.90e-03\n",
            "Train Epoch: 157-36 batch_loss=3.33e-03\n",
            "Test set: Average loss: 0.1052 Average relative error: 0.0576\n",
            "Train Epoch: 158-0 batch_loss=3.33e-03\n",
            "Train Epoch: 158-12 batch_loss=3.12e-03\n",
            "Train Epoch: 158-24 batch_loss=3.79e-03\n",
            "Train Epoch: 158-36 batch_loss=3.37e-03\n",
            "Test set: Average loss: 0.1047 Average relative error: 0.0570\n",
            "Train Epoch: 159-0 batch_loss=4.43e-03\n",
            "Train Epoch: 159-12 batch_loss=2.85e-03\n",
            "Train Epoch: 159-24 batch_loss=4.64e-03\n",
            "Train Epoch: 159-36 batch_loss=3.96e-03\n",
            "Test set: Average loss: 0.1022 Average relative error: 0.0568\n",
            "Train Epoch: 160-0 batch_loss=2.32e-03\n",
            "Train Epoch: 160-12 batch_loss=2.98e-03\n",
            "Train Epoch: 160-24 batch_loss=2.24e-03\n",
            "Train Epoch: 160-36 batch_loss=3.53e-03\n",
            "Test set: Average loss: 0.1010 Average relative error: 0.0563\n",
            "Train Epoch: 161-0 batch_loss=2.85e-03\n",
            "Train Epoch: 161-12 batch_loss=3.06e-03\n",
            "Train Epoch: 161-24 batch_loss=2.89e-03\n",
            "Train Epoch: 161-36 batch_loss=3.64e-03\n",
            "Test set: Average loss: 0.0997 Average relative error: 0.0563\n",
            "Train Epoch: 162-0 batch_loss=2.88e-03\n",
            "Train Epoch: 162-12 batch_loss=2.65e-03\n",
            "Train Epoch: 162-24 batch_loss=3.18e-03\n",
            "Train Epoch: 162-36 batch_loss=2.86e-03\n",
            "Test set: Average loss: 0.0972 Average relative error: 0.0553\n",
            "Train Epoch: 163-0 batch_loss=3.50e-03\n",
            "Train Epoch: 163-12 batch_loss=4.16e-03\n",
            "Train Epoch: 163-24 batch_loss=2.84e-03\n",
            "Train Epoch: 163-36 batch_loss=3.26e-03\n",
            "Test set: Average loss: 0.0957 Average relative error: 0.0549\n",
            "Train Epoch: 164-0 batch_loss=3.24e-03\n",
            "Train Epoch: 164-12 batch_loss=2.86e-03\n",
            "Train Epoch: 164-24 batch_loss=2.50e-03\n",
            "Train Epoch: 164-36 batch_loss=3.34e-03\n",
            "Test set: Average loss: 0.0948 Average relative error: 0.0548\n",
            "Train Epoch: 165-0 batch_loss=3.44e-03\n",
            "Train Epoch: 165-12 batch_loss=2.14e-03\n",
            "Train Epoch: 165-24 batch_loss=3.52e-03\n",
            "Train Epoch: 165-36 batch_loss=3.80e-03\n",
            "Test set: Average loss: 0.0927 Average relative error: 0.0542\n",
            "Train Epoch: 166-0 batch_loss=2.40e-03\n",
            "Train Epoch: 166-12 batch_loss=2.90e-03\n",
            "Train Epoch: 166-24 batch_loss=2.71e-03\n",
            "Train Epoch: 166-36 batch_loss=4.51e-03\n",
            "Test set: Average loss: 0.0917 Average relative error: 0.0539\n",
            "Train Epoch: 167-0 batch_loss=3.57e-03\n",
            "Train Epoch: 167-12 batch_loss=2.47e-03\n",
            "Train Epoch: 167-24 batch_loss=3.38e-03\n",
            "Train Epoch: 167-36 batch_loss=3.11e-03\n",
            "Test set: Average loss: 0.0906 Average relative error: 0.0537\n",
            "Train Epoch: 168-0 batch_loss=2.76e-03\n",
            "Train Epoch: 168-12 batch_loss=2.25e-03\n",
            "Train Epoch: 168-24 batch_loss=2.38e-03\n",
            "Train Epoch: 168-36 batch_loss=2.21e-03\n",
            "Test set: Average loss: 0.0888 Average relative error: 0.0534\n",
            "Train Epoch: 169-0 batch_loss=2.13e-03\n",
            "Train Epoch: 169-12 batch_loss=2.71e-03\n",
            "Train Epoch: 169-24 batch_loss=3.51e-03\n",
            "Train Epoch: 169-36 batch_loss=2.44e-03\n",
            "Test set: Average loss: 0.0883 Average relative error: 0.0531\n",
            "Train Epoch: 170-0 batch_loss=2.43e-03\n",
            "Train Epoch: 170-12 batch_loss=2.95e-03\n",
            "Train Epoch: 170-24 batch_loss=3.13e-03\n",
            "Train Epoch: 170-36 batch_loss=2.49e-03\n",
            "Test set: Average loss: 0.0872 Average relative error: 0.0527\n",
            "Train Epoch: 171-0 batch_loss=2.80e-03\n",
            "Train Epoch: 171-12 batch_loss=3.80e-03\n",
            "Train Epoch: 171-24 batch_loss=3.13e-03\n",
            "Train Epoch: 171-36 batch_loss=2.30e-03\n",
            "Test set: Average loss: 0.0853 Average relative error: 0.0522\n",
            "Train Epoch: 172-0 batch_loss=2.75e-03\n",
            "Train Epoch: 172-12 batch_loss=2.55e-03\n",
            "Train Epoch: 172-24 batch_loss=2.52e-03\n",
            "Train Epoch: 172-36 batch_loss=2.87e-03\n",
            "Test set: Average loss: 0.0844 Average relative error: 0.0522\n",
            "Train Epoch: 173-0 batch_loss=2.06e-03\n",
            "Train Epoch: 173-12 batch_loss=4.28e-03\n",
            "Train Epoch: 173-24 batch_loss=2.35e-03\n",
            "Train Epoch: 173-36 batch_loss=2.01e-03\n",
            "Test set: Average loss: 0.0836 Average relative error: 0.0519\n",
            "Train Epoch: 174-0 batch_loss=2.14e-03\n",
            "Train Epoch: 174-12 batch_loss=2.75e-03\n",
            "Train Epoch: 174-24 batch_loss=2.93e-03\n",
            "Train Epoch: 174-36 batch_loss=2.73e-03\n",
            "Test set: Average loss: 0.0819 Average relative error: 0.0514\n",
            "Train Epoch: 175-0 batch_loss=2.78e-03\n",
            "Train Epoch: 175-12 batch_loss=2.61e-03\n",
            "Train Epoch: 175-24 batch_loss=2.25e-03\n",
            "Train Epoch: 175-36 batch_loss=2.24e-03\n",
            "Test set: Average loss: 0.0805 Average relative error: 0.0509\n",
            "Train Epoch: 176-0 batch_loss=2.22e-03\n",
            "Train Epoch: 176-12 batch_loss=2.49e-03\n",
            "Train Epoch: 176-24 batch_loss=2.49e-03\n",
            "Train Epoch: 176-36 batch_loss=2.96e-03\n",
            "Test set: Average loss: 0.0800 Average relative error: 0.0508\n",
            "Train Epoch: 177-0 batch_loss=2.29e-03\n",
            "Train Epoch: 177-12 batch_loss=2.63e-03\n",
            "Train Epoch: 177-24 batch_loss=2.25e-03\n",
            "Train Epoch: 177-36 batch_loss=2.11e-03\n",
            "Test set: Average loss: 0.0785 Average relative error: 0.0503\n",
            "Train Epoch: 178-0 batch_loss=2.22e-03\n",
            "Train Epoch: 178-12 batch_loss=2.78e-03\n",
            "Train Epoch: 178-24 batch_loss=2.34e-03\n",
            "Train Epoch: 178-36 batch_loss=2.35e-03\n",
            "Test set: Average loss: 0.0781 Average relative error: 0.0502\n",
            "Train Epoch: 179-0 batch_loss=1.95e-03\n",
            "Train Epoch: 179-12 batch_loss=2.76e-03\n",
            "Train Epoch: 179-24 batch_loss=3.51e-03\n",
            "Train Epoch: 179-36 batch_loss=2.87e-03\n",
            "Test set: Average loss: 0.0775 Average relative error: 0.0501\n",
            "Train Epoch: 180-0 batch_loss=2.85e-03\n",
            "Train Epoch: 180-12 batch_loss=2.10e-03\n",
            "Train Epoch: 180-24 batch_loss=2.66e-03\n",
            "Train Epoch: 180-36 batch_loss=2.33e-03\n",
            "Test set: Average loss: 0.0772 Average relative error: 0.0499\n",
            "Train Epoch: 181-0 batch_loss=2.10e-03\n",
            "Train Epoch: 181-12 batch_loss=2.25e-03\n",
            "Train Epoch: 181-24 batch_loss=2.21e-03\n",
            "Train Epoch: 181-36 batch_loss=2.18e-03\n",
            "Test set: Average loss: 0.0753 Average relative error: 0.0495\n",
            "Train Epoch: 182-0 batch_loss=2.25e-03\n",
            "Train Epoch: 182-12 batch_loss=3.78e-03\n",
            "Train Epoch: 182-24 batch_loss=2.23e-03\n",
            "Train Epoch: 182-36 batch_loss=2.06e-03\n",
            "Test set: Average loss: 0.0747 Average relative error: 0.0492\n",
            "Train Epoch: 183-0 batch_loss=2.19e-03\n",
            "Train Epoch: 183-12 batch_loss=2.23e-03\n",
            "Train Epoch: 183-24 batch_loss=3.37e-03\n",
            "Train Epoch: 183-36 batch_loss=1.88e-03\n",
            "Test set: Average loss: 0.0739 Average relative error: 0.0490\n",
            "Train Epoch: 184-0 batch_loss=2.50e-03\n",
            "Train Epoch: 184-12 batch_loss=2.45e-03\n",
            "Train Epoch: 184-24 batch_loss=2.44e-03\n",
            "Train Epoch: 184-36 batch_loss=1.86e-03\n",
            "Test set: Average loss: 0.0729 Average relative error: 0.0488\n",
            "Train Epoch: 185-0 batch_loss=1.85e-03\n",
            "Train Epoch: 185-12 batch_loss=2.30e-03\n",
            "Train Epoch: 185-24 batch_loss=2.71e-03\n",
            "Train Epoch: 185-36 batch_loss=2.85e-03\n",
            "Test set: Average loss: 0.0723 Average relative error: 0.0486\n",
            "Train Epoch: 186-0 batch_loss=2.14e-03\n",
            "Train Epoch: 186-12 batch_loss=2.59e-03\n",
            "Train Epoch: 186-24 batch_loss=3.02e-03\n",
            "Train Epoch: 186-36 batch_loss=2.38e-03\n",
            "Test set: Average loss: 0.0718 Average relative error: 0.0483\n",
            "Train Epoch: 187-0 batch_loss=2.68e-03\n",
            "Train Epoch: 187-12 batch_loss=2.13e-03\n",
            "Train Epoch: 187-24 batch_loss=2.48e-03\n",
            "Train Epoch: 187-36 batch_loss=2.07e-03\n",
            "Test set: Average loss: 0.0713 Average relative error: 0.0481\n",
            "Train Epoch: 188-0 batch_loss=2.19e-03\n",
            "Train Epoch: 188-12 batch_loss=2.23e-03\n",
            "Train Epoch: 188-24 batch_loss=1.89e-03\n",
            "Train Epoch: 188-36 batch_loss=2.08e-03\n",
            "Test set: Average loss: 0.0698 Average relative error: 0.0479\n",
            "Train Epoch: 189-0 batch_loss=1.88e-03\n",
            "Train Epoch: 189-12 batch_loss=1.98e-03\n",
            "Train Epoch: 189-24 batch_loss=2.19e-03\n",
            "Train Epoch: 189-36 batch_loss=1.95e-03\n",
            "Test set: Average loss: 0.0700 Average relative error: 0.0478\n",
            "Train Epoch: 190-0 batch_loss=2.59e-03\n",
            "Train Epoch: 190-12 batch_loss=2.65e-03\n",
            "Train Epoch: 190-24 batch_loss=2.08e-03\n",
            "Train Epoch: 190-36 batch_loss=1.87e-03\n",
            "Test set: Average loss: 0.0690 Average relative error: 0.0475\n",
            "Train Epoch: 191-0 batch_loss=2.44e-03\n",
            "Train Epoch: 191-12 batch_loss=2.07e-03\n",
            "Train Epoch: 191-24 batch_loss=1.86e-03\n",
            "Train Epoch: 191-36 batch_loss=2.33e-03\n",
            "Test set: Average loss: 0.0684 Average relative error: 0.0473\n",
            "Train Epoch: 192-0 batch_loss=1.69e-03\n",
            "Train Epoch: 192-12 batch_loss=1.70e-03\n",
            "Train Epoch: 192-24 batch_loss=2.55e-03\n",
            "Train Epoch: 192-36 batch_loss=1.99e-03\n",
            "Test set: Average loss: 0.0681 Average relative error: 0.0472\n",
            "Train Epoch: 193-0 batch_loss=2.31e-03\n",
            "Train Epoch: 193-12 batch_loss=2.52e-03\n",
            "Train Epoch: 193-24 batch_loss=1.87e-03\n",
            "Train Epoch: 193-36 batch_loss=1.75e-03\n",
            "Test set: Average loss: 0.0675 Average relative error: 0.0470\n",
            "Train Epoch: 194-0 batch_loss=2.09e-03\n",
            "Train Epoch: 194-12 batch_loss=1.76e-03\n",
            "Train Epoch: 194-24 batch_loss=1.82e-03\n",
            "Train Epoch: 194-36 batch_loss=2.35e-03\n",
            "Test set: Average loss: 0.0668 Average relative error: 0.0468\n",
            "Train Epoch: 195-0 batch_loss=1.94e-03\n",
            "Train Epoch: 195-12 batch_loss=2.19e-03\n",
            "Train Epoch: 195-24 batch_loss=2.11e-03\n",
            "Train Epoch: 195-36 batch_loss=1.58e-03\n",
            "Test set: Average loss: 0.0659 Average relative error: 0.0464\n",
            "Train Epoch: 196-0 batch_loss=1.88e-03\n",
            "Train Epoch: 196-12 batch_loss=1.63e-03\n",
            "Train Epoch: 196-24 batch_loss=1.55e-03\n",
            "Train Epoch: 196-36 batch_loss=1.91e-03\n",
            "Test set: Average loss: 0.0658 Average relative error: 0.0463\n",
            "Train Epoch: 197-0 batch_loss=2.33e-03\n",
            "Train Epoch: 197-12 batch_loss=1.79e-03\n",
            "Train Epoch: 197-24 batch_loss=2.52e-03\n",
            "Train Epoch: 197-36 batch_loss=2.13e-03\n",
            "Test set: Average loss: 0.0650 Average relative error: 0.0462\n",
            "Train Epoch: 198-0 batch_loss=2.14e-03\n",
            "Train Epoch: 198-12 batch_loss=2.26e-03\n",
            "Train Epoch: 198-24 batch_loss=2.05e-03\n",
            "Train Epoch: 198-36 batch_loss=1.41e-03\n",
            "Test set: Average loss: 0.0650 Average relative error: 0.0462\n",
            "Train Epoch: 199-0 batch_loss=1.87e-03\n",
            "Train Epoch: 199-12 batch_loss=2.31e-03\n",
            "Train Epoch: 199-24 batch_loss=1.82e-03\n",
            "Train Epoch: 199-36 batch_loss=2.22e-03\n",
            "Test set: Average loss: 0.0643 Average relative error: 0.0458\n",
            "Train Epoch: 200-0 batch_loss=1.64e-03\n",
            "Train Epoch: 200-12 batch_loss=1.72e-03\n",
            "Train Epoch: 200-24 batch_loss=2.27e-03\n",
            "Train Epoch: 200-36 batch_loss=1.90e-03\n",
            "Test set: Average loss: 0.0637 Average relative error: 0.0457\n",
            "Train Epoch: 201-0 batch_loss=1.64e-03\n",
            "Train Epoch: 201-12 batch_loss=1.97e-03\n",
            "Train Epoch: 201-24 batch_loss=1.81e-03\n",
            "Train Epoch: 201-36 batch_loss=1.67e-03\n",
            "Test set: Average loss: 0.0634 Average relative error: 0.0456\n",
            "Train Epoch: 202-0 batch_loss=1.36e-03\n",
            "Train Epoch: 202-12 batch_loss=1.50e-03\n",
            "Train Epoch: 202-24 batch_loss=1.89e-03\n",
            "Train Epoch: 202-36 batch_loss=1.59e-03\n",
            "Test set: Average loss: 0.0633 Average relative error: 0.0456\n",
            "Train Epoch: 203-0 batch_loss=1.95e-03\n",
            "Train Epoch: 203-12 batch_loss=2.57e-03\n",
            "Train Epoch: 203-24 batch_loss=1.79e-03\n",
            "Train Epoch: 203-36 batch_loss=1.79e-03\n",
            "Test set: Average loss: 0.0627 Average relative error: 0.0453\n",
            "Train Epoch: 204-0 batch_loss=2.39e-03\n",
            "Train Epoch: 204-12 batch_loss=1.72e-03\n",
            "Train Epoch: 204-24 batch_loss=1.39e-03\n",
            "Train Epoch: 204-36 batch_loss=1.94e-03\n",
            "Test set: Average loss: 0.0627 Average relative error: 0.0453\n",
            "Train Epoch: 205-0 batch_loss=1.94e-03\n",
            "Train Epoch: 205-12 batch_loss=2.21e-03\n",
            "Train Epoch: 205-24 batch_loss=1.91e-03\n",
            "Train Epoch: 205-36 batch_loss=2.19e-03\n",
            "Test set: Average loss: 0.0622 Average relative error: 0.0452\n",
            "Train Epoch: 206-0 batch_loss=2.01e-03\n",
            "Train Epoch: 206-12 batch_loss=2.15e-03\n",
            "Train Epoch: 206-24 batch_loss=2.06e-03\n",
            "Train Epoch: 206-36 batch_loss=1.35e-03\n",
            "Test set: Average loss: 0.0611 Average relative error: 0.0448\n",
            "Train Epoch: 207-0 batch_loss=2.09e-03\n",
            "Train Epoch: 207-12 batch_loss=1.56e-03\n",
            "Train Epoch: 207-24 batch_loss=1.62e-03\n",
            "Train Epoch: 207-36 batch_loss=1.75e-03\n",
            "Test set: Average loss: 0.0613 Average relative error: 0.0448\n",
            "Train Epoch: 208-0 batch_loss=2.06e-03\n",
            "Train Epoch: 208-12 batch_loss=1.93e-03\n",
            "Train Epoch: 208-24 batch_loss=1.90e-03\n",
            "Train Epoch: 208-36 batch_loss=1.66e-03\n",
            "Test set: Average loss: 0.0605 Average relative error: 0.0445\n",
            "Train Epoch: 209-0 batch_loss=1.55e-03\n",
            "Train Epoch: 209-12 batch_loss=2.16e-03\n",
            "Train Epoch: 209-24 batch_loss=1.95e-03\n",
            "Train Epoch: 209-36 batch_loss=1.52e-03\n",
            "Test set: Average loss: 0.0599 Average relative error: 0.0443\n",
            "Train Epoch: 210-0 batch_loss=2.04e-03\n",
            "Train Epoch: 210-12 batch_loss=2.22e-03\n",
            "Train Epoch: 210-24 batch_loss=1.77e-03\n",
            "Train Epoch: 210-36 batch_loss=1.78e-03\n",
            "Test set: Average loss: 0.0596 Average relative error: 0.0442\n",
            "Train Epoch: 211-0 batch_loss=1.70e-03\n",
            "Train Epoch: 211-12 batch_loss=1.83e-03\n",
            "Train Epoch: 211-24 batch_loss=2.03e-03\n",
            "Train Epoch: 211-36 batch_loss=1.55e-03\n",
            "Test set: Average loss: 0.0596 Average relative error: 0.0443\n",
            "Train Epoch: 212-0 batch_loss=1.54e-03\n",
            "Train Epoch: 212-12 batch_loss=1.95e-03\n",
            "Train Epoch: 212-24 batch_loss=2.29e-03\n",
            "Train Epoch: 212-36 batch_loss=1.49e-03\n",
            "Test set: Average loss: 0.0590 Average relative error: 0.0439\n",
            "Train Epoch: 213-0 batch_loss=1.69e-03\n",
            "Train Epoch: 213-12 batch_loss=2.01e-03\n",
            "Train Epoch: 213-24 batch_loss=1.75e-03\n",
            "Train Epoch: 213-36 batch_loss=2.16e-03\n",
            "Test set: Average loss: 0.0591 Average relative error: 0.0440\n",
            "Train Epoch: 214-0 batch_loss=1.69e-03\n",
            "Train Epoch: 214-12 batch_loss=1.89e-03\n",
            "Train Epoch: 214-24 batch_loss=2.11e-03\n",
            "Train Epoch: 214-36 batch_loss=2.03e-03\n",
            "Test set: Average loss: 0.0584 Average relative error: 0.0439\n",
            "Train Epoch: 215-0 batch_loss=1.53e-03\n",
            "Train Epoch: 215-12 batch_loss=1.91e-03\n",
            "Train Epoch: 215-24 batch_loss=1.62e-03\n",
            "Train Epoch: 215-36 batch_loss=2.03e-03\n",
            "Test set: Average loss: 0.0584 Average relative error: 0.0438\n",
            "Train Epoch: 216-0 batch_loss=2.51e-03\n",
            "Train Epoch: 216-12 batch_loss=1.52e-03\n",
            "Train Epoch: 216-24 batch_loss=1.58e-03\n",
            "Train Epoch: 216-36 batch_loss=2.25e-03\n",
            "Test set: Average loss: 0.0581 Average relative error: 0.0436\n",
            "Train Epoch: 217-0 batch_loss=1.96e-03\n",
            "Train Epoch: 217-12 batch_loss=1.52e-03\n",
            "Train Epoch: 217-24 batch_loss=1.80e-03\n",
            "Train Epoch: 217-36 batch_loss=2.34e-03\n",
            "Test set: Average loss: 0.0579 Average relative error: 0.0436\n",
            "Train Epoch: 218-0 batch_loss=2.11e-03\n",
            "Train Epoch: 218-12 batch_loss=1.65e-03\n",
            "Train Epoch: 218-24 batch_loss=1.44e-03\n",
            "Train Epoch: 218-36 batch_loss=1.92e-03\n",
            "Test set: Average loss: 0.0575 Average relative error: 0.0434\n",
            "Train Epoch: 219-0 batch_loss=1.75e-03\n",
            "Train Epoch: 219-12 batch_loss=1.76e-03\n",
            "Train Epoch: 219-24 batch_loss=1.79e-03\n",
            "Train Epoch: 219-36 batch_loss=1.51e-03\n",
            "Test set: Average loss: 0.0575 Average relative error: 0.0435\n",
            "Train Epoch: 220-0 batch_loss=2.16e-03\n",
            "Train Epoch: 220-12 batch_loss=2.75e-03\n",
            "Train Epoch: 220-24 batch_loss=1.58e-03\n",
            "Train Epoch: 220-36 batch_loss=1.70e-03\n",
            "Test set: Average loss: 0.0566 Average relative error: 0.0431\n",
            "Train Epoch: 221-0 batch_loss=1.30e-03\n",
            "Train Epoch: 221-12 batch_loss=2.05e-03\n",
            "Train Epoch: 221-24 batch_loss=1.64e-03\n",
            "Train Epoch: 221-36 batch_loss=1.37e-03\n",
            "Test set: Average loss: 0.0568 Average relative error: 0.0431\n",
            "Train Epoch: 222-0 batch_loss=1.99e-03\n",
            "Train Epoch: 222-12 batch_loss=2.14e-03\n",
            "Train Epoch: 222-24 batch_loss=1.78e-03\n",
            "Train Epoch: 222-36 batch_loss=2.11e-03\n",
            "Test set: Average loss: 0.0565 Average relative error: 0.0430\n",
            "Train Epoch: 223-0 batch_loss=1.75e-03\n",
            "Train Epoch: 223-12 batch_loss=1.66e-03\n",
            "Train Epoch: 223-24 batch_loss=2.53e-03\n",
            "Train Epoch: 223-36 batch_loss=1.31e-03\n",
            "Test set: Average loss: 0.0561 Average relative error: 0.0429\n",
            "Train Epoch: 224-0 batch_loss=1.86e-03\n",
            "Train Epoch: 224-12 batch_loss=1.99e-03\n",
            "Train Epoch: 224-24 batch_loss=1.43e-03\n",
            "Train Epoch: 224-36 batch_loss=1.30e-03\n",
            "Test set: Average loss: 0.0562 Average relative error: 0.0431\n",
            "Train Epoch: 225-0 batch_loss=1.50e-03\n",
            "Train Epoch: 225-12 batch_loss=1.29e-03\n",
            "Train Epoch: 225-24 batch_loss=1.46e-03\n",
            "Train Epoch: 225-36 batch_loss=2.27e-03\n",
            "Test set: Average loss: 0.0563 Average relative error: 0.0430\n",
            "Train Epoch: 226-0 batch_loss=1.44e-03\n",
            "Train Epoch: 226-12 batch_loss=1.78e-03\n",
            "Train Epoch: 226-24 batch_loss=1.38e-03\n",
            "Train Epoch: 226-36 batch_loss=1.68e-03\n",
            "Test set: Average loss: 0.0556 Average relative error: 0.0428\n",
            "Train Epoch: 227-0 batch_loss=1.82e-03\n",
            "Train Epoch: 227-12 batch_loss=2.07e-03\n",
            "Train Epoch: 227-24 batch_loss=1.73e-03\n",
            "Train Epoch: 227-36 batch_loss=1.56e-03\n",
            "Test set: Average loss: 0.0552 Average relative error: 0.0427\n",
            "Train Epoch: 228-0 batch_loss=1.68e-03\n",
            "Train Epoch: 228-12 batch_loss=1.73e-03\n",
            "Train Epoch: 228-24 batch_loss=2.17e-03\n",
            "Train Epoch: 228-36 batch_loss=1.80e-03\n",
            "Test set: Average loss: 0.0551 Average relative error: 0.0426\n",
            "Train Epoch: 229-0 batch_loss=2.05e-03\n",
            "Train Epoch: 229-12 batch_loss=1.34e-03\n",
            "Train Epoch: 229-24 batch_loss=1.90e-03\n",
            "Train Epoch: 229-36 batch_loss=2.13e-03\n",
            "Test set: Average loss: 0.0548 Average relative error: 0.0425\n",
            "Train Epoch: 230-0 batch_loss=1.83e-03\n",
            "Train Epoch: 230-12 batch_loss=1.32e-03\n",
            "Train Epoch: 230-24 batch_loss=1.39e-03\n",
            "Train Epoch: 230-36 batch_loss=1.68e-03\n",
            "Test set: Average loss: 0.0549 Average relative error: 0.0426\n",
            "Train Epoch: 231-0 batch_loss=2.04e-03\n",
            "Train Epoch: 231-12 batch_loss=1.80e-03\n",
            "Train Epoch: 231-24 batch_loss=1.46e-03\n",
            "Train Epoch: 231-36 batch_loss=1.48e-03\n",
            "Test set: Average loss: 0.0548 Average relative error: 0.0425\n",
            "Train Epoch: 232-0 batch_loss=1.25e-03\n",
            "Train Epoch: 232-12 batch_loss=1.57e-03\n",
            "Train Epoch: 232-24 batch_loss=1.54e-03\n",
            "Train Epoch: 232-36 batch_loss=1.68e-03\n",
            "Test set: Average loss: 0.0541 Average relative error: 0.0422\n",
            "Train Epoch: 233-0 batch_loss=1.74e-03\n",
            "Train Epoch: 233-12 batch_loss=2.24e-03\n",
            "Train Epoch: 233-24 batch_loss=1.95e-03\n",
            "Train Epoch: 233-36 batch_loss=1.61e-03\n",
            "Test set: Average loss: 0.0541 Average relative error: 0.0422\n",
            "Train Epoch: 234-0 batch_loss=1.39e-03\n",
            "Train Epoch: 234-12 batch_loss=1.57e-03\n",
            "Train Epoch: 234-24 batch_loss=1.47e-03\n",
            "Train Epoch: 234-36 batch_loss=1.57e-03\n",
            "Test set: Average loss: 0.0538 Average relative error: 0.0421\n",
            "Train Epoch: 235-0 batch_loss=2.27e-03\n",
            "Train Epoch: 235-12 batch_loss=1.52e-03\n",
            "Train Epoch: 235-24 batch_loss=1.17e-03\n",
            "Train Epoch: 235-36 batch_loss=1.65e-03\n",
            "Test set: Average loss: 0.0538 Average relative error: 0.0421\n",
            "Train Epoch: 236-0 batch_loss=1.60e-03\n",
            "Train Epoch: 236-12 batch_loss=1.43e-03\n",
            "Train Epoch: 236-24 batch_loss=2.36e-03\n",
            "Train Epoch: 236-36 batch_loss=1.50e-03\n",
            "Test set: Average loss: 0.0535 Average relative error: 0.0420\n",
            "Train Epoch: 237-0 batch_loss=1.68e-03\n",
            "Train Epoch: 237-12 batch_loss=1.74e-03\n",
            "Train Epoch: 237-24 batch_loss=1.39e-03\n",
            "Train Epoch: 237-36 batch_loss=1.94e-03\n",
            "Test set: Average loss: 0.0536 Average relative error: 0.0420\n",
            "Train Epoch: 238-0 batch_loss=1.72e-03\n",
            "Train Epoch: 238-12 batch_loss=1.40e-03\n",
            "Train Epoch: 238-24 batch_loss=2.39e-03\n",
            "Train Epoch: 238-36 batch_loss=1.51e-03\n",
            "Test set: Average loss: 0.0533 Average relative error: 0.0419\n",
            "Train Epoch: 239-0 batch_loss=1.56e-03\n",
            "Train Epoch: 239-12 batch_loss=1.56e-03\n",
            "Train Epoch: 239-24 batch_loss=1.45e-03\n",
            "Train Epoch: 239-36 batch_loss=1.97e-03\n",
            "Test set: Average loss: 0.0535 Average relative error: 0.0420\n",
            "Train Epoch: 240-0 batch_loss=2.11e-03\n",
            "Train Epoch: 240-12 batch_loss=1.73e-03\n",
            "Train Epoch: 240-24 batch_loss=1.63e-03\n",
            "Train Epoch: 240-36 batch_loss=1.59e-03\n",
            "Test set: Average loss: 0.0528 Average relative error: 0.0418\n",
            "Train Epoch: 241-0 batch_loss=1.54e-03\n",
            "Train Epoch: 241-12 batch_loss=1.30e-03\n",
            "Train Epoch: 241-24 batch_loss=1.34e-03\n",
            "Train Epoch: 241-36 batch_loss=1.53e-03\n",
            "Test set: Average loss: 0.0531 Average relative error: 0.0419\n",
            "Train Epoch: 242-0 batch_loss=2.04e-03\n",
            "Train Epoch: 242-12 batch_loss=2.10e-03\n",
            "Train Epoch: 242-24 batch_loss=1.57e-03\n",
            "Train Epoch: 242-36 batch_loss=1.33e-03\n",
            "Test set: Average loss: 0.0527 Average relative error: 0.0417\n",
            "Train Epoch: 243-0 batch_loss=1.94e-03\n",
            "Train Epoch: 243-12 batch_loss=1.63e-03\n",
            "Train Epoch: 243-24 batch_loss=1.67e-03\n",
            "Train Epoch: 243-36 batch_loss=2.25e-03\n",
            "Test set: Average loss: 0.0525 Average relative error: 0.0416\n",
            "Train Epoch: 244-0 batch_loss=1.49e-03\n",
            "Train Epoch: 244-12 batch_loss=1.55e-03\n",
            "Train Epoch: 244-24 batch_loss=1.42e-03\n",
            "Train Epoch: 244-36 batch_loss=2.30e-03\n",
            "Test set: Average loss: 0.0523 Average relative error: 0.0416\n",
            "Train Epoch: 245-0 batch_loss=2.00e-03\n",
            "Train Epoch: 245-12 batch_loss=1.63e-03\n",
            "Train Epoch: 245-24 batch_loss=1.48e-03\n",
            "Train Epoch: 245-36 batch_loss=1.38e-03\n",
            "Test set: Average loss: 0.0522 Average relative error: 0.0414\n",
            "Train Epoch: 246-0 batch_loss=1.93e-03\n",
            "Train Epoch: 246-12 batch_loss=1.39e-03\n",
            "Train Epoch: 246-24 batch_loss=1.20e-03\n",
            "Train Epoch: 246-36 batch_loss=1.42e-03\n",
            "Test set: Average loss: 0.0525 Average relative error: 0.0417\n",
            "Train Epoch: 247-0 batch_loss=1.34e-03\n",
            "Train Epoch: 247-12 batch_loss=1.46e-03\n",
            "Train Epoch: 247-24 batch_loss=1.57e-03\n",
            "Train Epoch: 247-36 batch_loss=1.45e-03\n",
            "Test set: Average loss: 0.0519 Average relative error: 0.0414\n",
            "Train Epoch: 248-0 batch_loss=1.59e-03\n",
            "Train Epoch: 248-12 batch_loss=1.26e-03\n",
            "Train Epoch: 248-24 batch_loss=1.49e-03\n",
            "Train Epoch: 248-36 batch_loss=1.87e-03\n",
            "Test set: Average loss: 0.0520 Average relative error: 0.0415\n",
            "Train Epoch: 249-0 batch_loss=1.67e-03\n",
            "Train Epoch: 249-12 batch_loss=1.44e-03\n",
            "Train Epoch: 249-24 batch_loss=1.88e-03\n",
            "Train Epoch: 249-36 batch_loss=1.35e-03\n",
            "Test set: Average loss: 0.0516 Average relative error: 0.0412\n",
            "Train Epoch: 250-0 batch_loss=1.70e-03\n",
            "Train Epoch: 250-12 batch_loss=1.88e-03\n",
            "Train Epoch: 250-24 batch_loss=1.73e-03\n",
            "Train Epoch: 250-36 batch_loss=2.31e-03\n",
            "Test set: Average loss: 0.0517 Average relative error: 0.0413\n",
            "Train Epoch: 251-0 batch_loss=1.83e-03\n",
            "Train Epoch: 251-12 batch_loss=1.23e-03\n",
            "Train Epoch: 251-24 batch_loss=1.56e-03\n",
            "Train Epoch: 251-36 batch_loss=1.22e-03\n",
            "Test set: Average loss: 0.0513 Average relative error: 0.0412\n",
            "Train Epoch: 252-0 batch_loss=1.75e-03\n",
            "Train Epoch: 252-12 batch_loss=1.33e-03\n",
            "Train Epoch: 252-24 batch_loss=1.40e-03\n",
            "Train Epoch: 252-36 batch_loss=1.36e-03\n",
            "Test set: Average loss: 0.0510 Average relative error: 0.0410\n",
            "Train Epoch: 253-0 batch_loss=1.50e-03\n",
            "Train Epoch: 253-12 batch_loss=1.26e-03\n",
            "Train Epoch: 253-24 batch_loss=1.46e-03\n",
            "Train Epoch: 253-36 batch_loss=1.30e-03\n",
            "Test set: Average loss: 0.0511 Average relative error: 0.0411\n",
            "Train Epoch: 254-0 batch_loss=1.46e-03\n",
            "Train Epoch: 254-12 batch_loss=1.46e-03\n",
            "Train Epoch: 254-24 batch_loss=1.77e-03\n",
            "Train Epoch: 254-36 batch_loss=1.45e-03\n",
            "Test set: Average loss: 0.0510 Average relative error: 0.0410\n",
            "Train Epoch: 255-0 batch_loss=1.38e-03\n",
            "Train Epoch: 255-12 batch_loss=1.32e-03\n",
            "Train Epoch: 255-24 batch_loss=1.18e-03\n",
            "Train Epoch: 255-36 batch_loss=1.37e-03\n",
            "Test set: Average loss: 0.0511 Average relative error: 0.0411\n",
            "Train Epoch: 256-0 batch_loss=1.81e-03\n",
            "Train Epoch: 256-12 batch_loss=1.29e-03\n",
            "Train Epoch: 256-24 batch_loss=1.33e-03\n",
            "Train Epoch: 256-36 batch_loss=1.71e-03\n",
            "Test set: Average loss: 0.0506 Average relative error: 0.0409\n",
            "Train Epoch: 257-0 batch_loss=1.88e-03\n",
            "Train Epoch: 257-12 batch_loss=1.63e-03\n",
            "Train Epoch: 257-24 batch_loss=1.56e-03\n",
            "Train Epoch: 257-36 batch_loss=1.54e-03\n",
            "Test set: Average loss: 0.0507 Average relative error: 0.0409\n",
            "Train Epoch: 258-0 batch_loss=1.28e-03\n",
            "Train Epoch: 258-12 batch_loss=1.87e-03\n",
            "Train Epoch: 258-24 batch_loss=1.53e-03\n",
            "Train Epoch: 258-36 batch_loss=1.56e-03\n",
            "Test set: Average loss: 0.0506 Average relative error: 0.0408\n",
            "Train Epoch: 259-0 batch_loss=1.58e-03\n",
            "Train Epoch: 259-12 batch_loss=1.29e-03\n",
            "Train Epoch: 259-24 batch_loss=1.34e-03\n",
            "Train Epoch: 259-36 batch_loss=1.91e-03\n",
            "Test set: Average loss: 0.0503 Average relative error: 0.0408\n",
            "Train Epoch: 260-0 batch_loss=2.15e-03\n",
            "Train Epoch: 260-12 batch_loss=1.89e-03\n",
            "Train Epoch: 260-24 batch_loss=1.55e-03\n",
            "Train Epoch: 260-36 batch_loss=1.51e-03\n",
            "Test set: Average loss: 0.0502 Average relative error: 0.0407\n",
            "Train Epoch: 261-0 batch_loss=1.43e-03\n",
            "Train Epoch: 261-12 batch_loss=1.63e-03\n",
            "Train Epoch: 261-24 batch_loss=1.16e-03\n",
            "Train Epoch: 261-36 batch_loss=1.75e-03\n",
            "Test set: Average loss: 0.0500 Average relative error: 0.0407\n",
            "Train Epoch: 262-0 batch_loss=1.55e-03\n",
            "Train Epoch: 262-12 batch_loss=1.50e-03\n",
            "Train Epoch: 262-24 batch_loss=1.44e-03\n",
            "Train Epoch: 262-36 batch_loss=1.81e-03\n",
            "Test set: Average loss: 0.0501 Average relative error: 0.0407\n",
            "Train Epoch: 263-0 batch_loss=1.90e-03\n",
            "Train Epoch: 263-12 batch_loss=1.68e-03\n",
            "Train Epoch: 263-24 batch_loss=1.56e-03\n",
            "Train Epoch: 263-36 batch_loss=1.66e-03\n",
            "Test set: Average loss: 0.0500 Average relative error: 0.0407\n",
            "Train Epoch: 264-0 batch_loss=1.89e-03\n",
            "Train Epoch: 264-12 batch_loss=1.85e-03\n",
            "Train Epoch: 264-24 batch_loss=1.25e-03\n",
            "Train Epoch: 264-36 batch_loss=1.55e-03\n",
            "Test set: Average loss: 0.0497 Average relative error: 0.0406\n",
            "Train Epoch: 265-0 batch_loss=1.33e-03\n",
            "Train Epoch: 265-12 batch_loss=1.35e-03\n",
            "Train Epoch: 265-24 batch_loss=1.20e-03\n",
            "Train Epoch: 265-36 batch_loss=1.11e-03\n",
            "Test set: Average loss: 0.0498 Average relative error: 0.0406\n",
            "Train Epoch: 266-0 batch_loss=1.55e-03\n",
            "Train Epoch: 266-12 batch_loss=1.43e-03\n",
            "Train Epoch: 266-24 batch_loss=1.46e-03\n",
            "Train Epoch: 266-36 batch_loss=1.64e-03\n",
            "Test set: Average loss: 0.0496 Average relative error: 0.0405\n",
            "Train Epoch: 267-0 batch_loss=1.41e-03\n",
            "Train Epoch: 267-12 batch_loss=1.81e-03\n",
            "Train Epoch: 267-24 batch_loss=1.59e-03\n",
            "Train Epoch: 267-36 batch_loss=1.56e-03\n",
            "Test set: Average loss: 0.0494 Average relative error: 0.0404\n",
            "Train Epoch: 268-0 batch_loss=1.80e-03\n",
            "Train Epoch: 268-12 batch_loss=1.09e-03\n",
            "Train Epoch: 268-24 batch_loss=1.55e-03\n",
            "Train Epoch: 268-36 batch_loss=1.48e-03\n",
            "Test set: Average loss: 0.0490 Average relative error: 0.0403\n",
            "Train Epoch: 269-0 batch_loss=1.27e-03\n",
            "Train Epoch: 269-12 batch_loss=1.40e-03\n",
            "Train Epoch: 269-24 batch_loss=1.66e-03\n",
            "Train Epoch: 269-36 batch_loss=1.24e-03\n",
            "Test set: Average loss: 0.0495 Average relative error: 0.0405\n",
            "Train Epoch: 270-0 batch_loss=1.42e-03\n",
            "Train Epoch: 270-12 batch_loss=2.42e-03\n",
            "Train Epoch: 270-24 batch_loss=1.38e-03\n",
            "Train Epoch: 270-36 batch_loss=2.52e-03\n",
            "Test set: Average loss: 0.0492 Average relative error: 0.0403\n",
            "Train Epoch: 271-0 batch_loss=1.71e-03\n",
            "Train Epoch: 271-12 batch_loss=1.66e-03\n",
            "Train Epoch: 271-24 batch_loss=1.40e-03\n",
            "Train Epoch: 271-36 batch_loss=1.41e-03\n",
            "Test set: Average loss: 0.0489 Average relative error: 0.0403\n",
            "Train Epoch: 272-0 batch_loss=1.31e-03\n",
            "Train Epoch: 272-12 batch_loss=1.50e-03\n",
            "Train Epoch: 272-24 batch_loss=1.52e-03\n",
            "Train Epoch: 272-36 batch_loss=1.26e-03\n",
            "Test set: Average loss: 0.0488 Average relative error: 0.0402\n",
            "Train Epoch: 273-0 batch_loss=1.30e-03\n",
            "Train Epoch: 273-12 batch_loss=1.71e-03\n",
            "Train Epoch: 273-24 batch_loss=1.40e-03\n",
            "Train Epoch: 273-36 batch_loss=1.26e-03\n",
            "Test set: Average loss: 0.0485 Average relative error: 0.0401\n",
            "Train Epoch: 274-0 batch_loss=1.52e-03\n",
            "Train Epoch: 274-12 batch_loss=1.65e-03\n",
            "Train Epoch: 274-24 batch_loss=1.40e-03\n",
            "Train Epoch: 274-36 batch_loss=1.68e-03\n",
            "Test set: Average loss: 0.0487 Average relative error: 0.0401\n",
            "Train Epoch: 275-0 batch_loss=1.32e-03\n",
            "Train Epoch: 275-12 batch_loss=1.30e-03\n",
            "Train Epoch: 275-24 batch_loss=2.03e-03\n",
            "Train Epoch: 275-36 batch_loss=1.24e-03\n",
            "Test set: Average loss: 0.0487 Average relative error: 0.0401\n",
            "Train Epoch: 276-0 batch_loss=1.65e-03\n",
            "Train Epoch: 276-12 batch_loss=1.46e-03\n",
            "Train Epoch: 276-24 batch_loss=1.20e-03\n",
            "Train Epoch: 276-36 batch_loss=1.41e-03\n",
            "Test set: Average loss: 0.0485 Average relative error: 0.0401\n",
            "Train Epoch: 277-0 batch_loss=1.41e-03\n",
            "Train Epoch: 277-12 batch_loss=1.31e-03\n",
            "Train Epoch: 277-24 batch_loss=1.31e-03\n",
            "Train Epoch: 277-36 batch_loss=1.14e-03\n",
            "Test set: Average loss: 0.0483 Average relative error: 0.0400\n",
            "Train Epoch: 278-0 batch_loss=1.60e-03\n",
            "Train Epoch: 278-12 batch_loss=1.40e-03\n",
            "Train Epoch: 278-24 batch_loss=1.90e-03\n",
            "Train Epoch: 278-36 batch_loss=1.94e-03\n",
            "Test set: Average loss: 0.0482 Average relative error: 0.0399\n",
            "Train Epoch: 279-0 batch_loss=1.41e-03\n",
            "Train Epoch: 279-12 batch_loss=1.23e-03\n",
            "Train Epoch: 279-24 batch_loss=1.24e-03\n",
            "Train Epoch: 279-36 batch_loss=1.16e-03\n",
            "Test set: Average loss: 0.0480 Average relative error: 0.0399\n",
            "Train Epoch: 280-0 batch_loss=1.49e-03\n",
            "Train Epoch: 280-12 batch_loss=1.55e-03\n",
            "Train Epoch: 280-24 batch_loss=1.24e-03\n",
            "Train Epoch: 280-36 batch_loss=1.35e-03\n",
            "Test set: Average loss: 0.0481 Average relative error: 0.0399\n",
            "Train Epoch: 281-0 batch_loss=1.35e-03\n",
            "Train Epoch: 281-12 batch_loss=1.57e-03\n",
            "Train Epoch: 281-24 batch_loss=1.24e-03\n",
            "Train Epoch: 281-36 batch_loss=1.47e-03\n",
            "Test set: Average loss: 0.0480 Average relative error: 0.0399\n",
            "Train Epoch: 282-0 batch_loss=1.73e-03\n",
            "Train Epoch: 282-12 batch_loss=1.22e-03\n",
            "Train Epoch: 282-24 batch_loss=1.79e-03\n",
            "Train Epoch: 282-36 batch_loss=1.35e-03\n",
            "Test set: Average loss: 0.0479 Average relative error: 0.0398\n",
            "Train Epoch: 283-0 batch_loss=1.19e-03\n",
            "Train Epoch: 283-12 batch_loss=1.15e-03\n",
            "Train Epoch: 283-24 batch_loss=1.47e-03\n",
            "Train Epoch: 283-36 batch_loss=1.37e-03\n",
            "Test set: Average loss: 0.0478 Average relative error: 0.0398\n",
            "Train Epoch: 284-0 batch_loss=1.31e-03\n",
            "Train Epoch: 284-12 batch_loss=1.16e-03\n",
            "Train Epoch: 284-24 batch_loss=1.50e-03\n",
            "Train Epoch: 284-36 batch_loss=1.58e-03\n",
            "Test set: Average loss: 0.0479 Average relative error: 0.0399\n",
            "Train Epoch: 285-0 batch_loss=1.60e-03\n",
            "Train Epoch: 285-12 batch_loss=1.50e-03\n",
            "Train Epoch: 285-24 batch_loss=1.50e-03\n",
            "Train Epoch: 285-36 batch_loss=1.43e-03\n",
            "Test set: Average loss: 0.0477 Average relative error: 0.0398\n",
            "Train Epoch: 286-0 batch_loss=1.11e-03\n",
            "Train Epoch: 286-12 batch_loss=1.45e-03\n",
            "Train Epoch: 286-24 batch_loss=1.38e-03\n",
            "Train Epoch: 286-36 batch_loss=1.34e-03\n",
            "Test set: Average loss: 0.0477 Average relative error: 0.0398\n",
            "Train Epoch: 287-0 batch_loss=1.22e-03\n",
            "Train Epoch: 287-12 batch_loss=1.40e-03\n",
            "Train Epoch: 287-24 batch_loss=1.58e-03\n",
            "Train Epoch: 287-36 batch_loss=1.32e-03\n",
            "Test set: Average loss: 0.0475 Average relative error: 0.0398\n",
            "Train Epoch: 288-0 batch_loss=1.85e-03\n",
            "Train Epoch: 288-12 batch_loss=1.44e-03\n",
            "Train Epoch: 288-24 batch_loss=1.79e-03\n",
            "Train Epoch: 288-36 batch_loss=1.36e-03\n",
            "Test set: Average loss: 0.0475 Average relative error: 0.0397\n",
            "Train Epoch: 289-0 batch_loss=9.86e-04\n",
            "Train Epoch: 289-12 batch_loss=1.23e-03\n",
            "Train Epoch: 289-24 batch_loss=1.43e-03\n",
            "Train Epoch: 289-36 batch_loss=1.46e-03\n",
            "Test set: Average loss: 0.0472 Average relative error: 0.0395\n",
            "Train Epoch: 290-0 batch_loss=1.40e-03\n",
            "Train Epoch: 290-12 batch_loss=9.65e-04\n",
            "Train Epoch: 290-24 batch_loss=1.72e-03\n",
            "Train Epoch: 290-36 batch_loss=1.22e-03\n",
            "Test set: Average loss: 0.0473 Average relative error: 0.0396\n",
            "Train Epoch: 291-0 batch_loss=1.45e-03\n",
            "Train Epoch: 291-12 batch_loss=1.49e-03\n",
            "Train Epoch: 291-24 batch_loss=1.80e-03\n",
            "Train Epoch: 291-36 batch_loss=1.59e-03\n",
            "Test set: Average loss: 0.0475 Average relative error: 0.0397\n",
            "Train Epoch: 292-0 batch_loss=1.48e-03\n",
            "Train Epoch: 292-12 batch_loss=1.27e-03\n",
            "Train Epoch: 292-24 batch_loss=1.32e-03\n",
            "Train Epoch: 292-36 batch_loss=1.63e-03\n",
            "Test set: Average loss: 0.0475 Average relative error: 0.0397\n",
            "Train Epoch: 293-0 batch_loss=1.48e-03\n",
            "Train Epoch: 293-12 batch_loss=1.25e-03\n",
            "Train Epoch: 293-24 batch_loss=1.19e-03\n",
            "Train Epoch: 293-36 batch_loss=1.65e-03\n",
            "Test set: Average loss: 0.0469 Average relative error: 0.0394\n",
            "Train Epoch: 294-0 batch_loss=1.14e-03\n",
            "Train Epoch: 294-12 batch_loss=1.34e-03\n",
            "Train Epoch: 294-24 batch_loss=1.68e-03\n",
            "Train Epoch: 294-36 batch_loss=1.24e-03\n",
            "Test set: Average loss: 0.0471 Average relative error: 0.0396\n",
            "Train Epoch: 295-0 batch_loss=1.49e-03\n",
            "Train Epoch: 295-12 batch_loss=1.48e-03\n",
            "Train Epoch: 295-24 batch_loss=1.73e-03\n",
            "Train Epoch: 295-36 batch_loss=1.45e-03\n",
            "Test set: Average loss: 0.0469 Average relative error: 0.0394\n",
            "Train Epoch: 296-0 batch_loss=2.05e-03\n",
            "Train Epoch: 296-12 batch_loss=1.23e-03\n",
            "Train Epoch: 296-24 batch_loss=1.21e-03\n",
            "Train Epoch: 296-36 batch_loss=1.26e-03\n",
            "Test set: Average loss: 0.0467 Average relative error: 0.0394\n",
            "Train Epoch: 297-0 batch_loss=1.40e-03\n",
            "Train Epoch: 297-12 batch_loss=1.45e-03\n",
            "Train Epoch: 297-24 batch_loss=1.30e-03\n",
            "Train Epoch: 297-36 batch_loss=1.44e-03\n",
            "Test set: Average loss: 0.0469 Average relative error: 0.0394\n",
            "Train Epoch: 298-0 batch_loss=1.18e-03\n",
            "Train Epoch: 298-12 batch_loss=1.31e-03\n",
            "Train Epoch: 298-24 batch_loss=1.47e-03\n",
            "Train Epoch: 298-36 batch_loss=1.55e-03\n",
            "Test set: Average loss: 0.0468 Average relative error: 0.0394\n",
            "Train Epoch: 299-0 batch_loss=1.25e-03\n",
            "Train Epoch: 299-12 batch_loss=1.26e-03\n",
            "Train Epoch: 299-24 batch_loss=1.71e-03\n",
            "Train Epoch: 299-36 batch_loss=1.12e-03\n",
            "Test set: Average loss: 0.0468 Average relative error: 0.0394\n",
            "Train Epoch: 300-0 batch_loss=1.19e-03\n",
            "Train Epoch: 300-12 batch_loss=1.46e-03\n",
            "Train Epoch: 300-24 batch_loss=1.23e-03\n",
            "Train Epoch: 300-36 batch_loss=1.27e-03\n",
            "Test set: Average loss: 0.0465 Average relative error: 0.0393\n",
            "Train Epoch: 301-0 batch_loss=1.43e-03\n",
            "Train Epoch: 301-12 batch_loss=1.57e-03\n",
            "Train Epoch: 301-24 batch_loss=1.22e-03\n",
            "Train Epoch: 301-36 batch_loss=1.42e-03\n",
            "Test set: Average loss: 0.0466 Average relative error: 0.0394\n",
            "Train Epoch: 302-0 batch_loss=1.45e-03\n",
            "Train Epoch: 302-12 batch_loss=1.64e-03\n",
            "Train Epoch: 302-24 batch_loss=1.27e-03\n",
            "Train Epoch: 302-36 batch_loss=1.52e-03\n",
            "Test set: Average loss: 0.0467 Average relative error: 0.0394\n",
            "Train Epoch: 303-0 batch_loss=1.70e-03\n",
            "Train Epoch: 303-12 batch_loss=1.32e-03\n",
            "Train Epoch: 303-24 batch_loss=1.58e-03\n",
            "Train Epoch: 303-36 batch_loss=1.37e-03\n",
            "Test set: Average loss: 0.0464 Average relative error: 0.0392\n",
            "Train Epoch: 304-0 batch_loss=1.36e-03\n",
            "Train Epoch: 304-12 batch_loss=1.97e-03\n",
            "Train Epoch: 304-24 batch_loss=1.26e-03\n",
            "Train Epoch: 304-36 batch_loss=1.22e-03\n",
            "Test set: Average loss: 0.0464 Average relative error: 0.0392\n",
            "Train Epoch: 305-0 batch_loss=1.07e-03\n",
            "Train Epoch: 305-12 batch_loss=1.33e-03\n",
            "Train Epoch: 305-24 batch_loss=1.32e-03\n",
            "Train Epoch: 305-36 batch_loss=1.46e-03\n",
            "Test set: Average loss: 0.0463 Average relative error: 0.0392\n",
            "Train Epoch: 306-0 batch_loss=1.40e-03\n",
            "Train Epoch: 306-12 batch_loss=1.12e-03\n",
            "Train Epoch: 306-24 batch_loss=1.43e-03\n",
            "Train Epoch: 306-36 batch_loss=1.72e-03\n",
            "Test set: Average loss: 0.0463 Average relative error: 0.0392\n",
            "Train Epoch: 307-0 batch_loss=1.27e-03\n",
            "Train Epoch: 307-12 batch_loss=1.38e-03\n",
            "Train Epoch: 307-24 batch_loss=1.27e-03\n",
            "Train Epoch: 307-36 batch_loss=1.18e-03\n",
            "Test set: Average loss: 0.0460 Average relative error: 0.0392\n",
            "Train Epoch: 308-0 batch_loss=1.36e-03\n",
            "Train Epoch: 308-12 batch_loss=1.46e-03\n",
            "Train Epoch: 308-24 batch_loss=1.46e-03\n",
            "Train Epoch: 308-36 batch_loss=1.35e-03\n",
            "Test set: Average loss: 0.0462 Average relative error: 0.0391\n",
            "Train Epoch: 309-0 batch_loss=1.82e-03\n",
            "Train Epoch: 309-12 batch_loss=1.20e-03\n",
            "Train Epoch: 309-24 batch_loss=1.62e-03\n",
            "Train Epoch: 309-36 batch_loss=1.11e-03\n",
            "Test set: Average loss: 0.0460 Average relative error: 0.0390\n",
            "Train Epoch: 310-0 batch_loss=1.52e-03\n",
            "Train Epoch: 310-12 batch_loss=1.61e-03\n",
            "Train Epoch: 310-24 batch_loss=1.95e-03\n",
            "Train Epoch: 310-36 batch_loss=1.42e-03\n",
            "Test set: Average loss: 0.0461 Average relative error: 0.0392\n",
            "Train Epoch: 311-0 batch_loss=1.16e-03\n",
            "Train Epoch: 311-12 batch_loss=1.41e-03\n",
            "Train Epoch: 311-24 batch_loss=1.37e-03\n",
            "Train Epoch: 311-36 batch_loss=1.32e-03\n",
            "Test set: Average loss: 0.0459 Average relative error: 0.0390\n",
            "Train Epoch: 312-0 batch_loss=1.73e-03\n",
            "Train Epoch: 312-12 batch_loss=1.32e-03\n",
            "Train Epoch: 312-24 batch_loss=1.38e-03\n",
            "Train Epoch: 312-36 batch_loss=1.74e-03\n",
            "Test set: Average loss: 0.0462 Average relative error: 0.0392\n",
            "Train Epoch: 313-0 batch_loss=1.63e-03\n",
            "Train Epoch: 313-12 batch_loss=1.47e-03\n",
            "Train Epoch: 313-24 batch_loss=1.46e-03\n",
            "Train Epoch: 313-36 batch_loss=1.32e-03\n",
            "Test set: Average loss: 0.0457 Average relative error: 0.0390\n",
            "Train Epoch: 314-0 batch_loss=1.23e-03\n",
            "Train Epoch: 314-12 batch_loss=1.18e-03\n",
            "Train Epoch: 314-24 batch_loss=1.53e-03\n",
            "Train Epoch: 314-36 batch_loss=1.54e-03\n",
            "Test set: Average loss: 0.0458 Average relative error: 0.0390\n",
            "Train Epoch: 315-0 batch_loss=1.35e-03\n",
            "Train Epoch: 315-12 batch_loss=1.52e-03\n",
            "Train Epoch: 315-24 batch_loss=1.36e-03\n",
            "Train Epoch: 315-36 batch_loss=1.43e-03\n",
            "Test set: Average loss: 0.0458 Average relative error: 0.0391\n",
            "Train Epoch: 316-0 batch_loss=1.29e-03\n",
            "Train Epoch: 316-12 batch_loss=1.32e-03\n",
            "Train Epoch: 316-24 batch_loss=1.20e-03\n",
            "Train Epoch: 316-36 batch_loss=1.21e-03\n",
            "Test set: Average loss: 0.0457 Average relative error: 0.0389\n",
            "Train Epoch: 317-0 batch_loss=1.15e-03\n",
            "Train Epoch: 317-12 batch_loss=1.68e-03\n",
            "Train Epoch: 317-24 batch_loss=1.51e-03\n",
            "Train Epoch: 317-36 batch_loss=1.30e-03\n",
            "Test set: Average loss: 0.0456 Average relative error: 0.0389\n",
            "Train Epoch: 318-0 batch_loss=1.17e-03\n",
            "Train Epoch: 318-12 batch_loss=1.23e-03\n",
            "Train Epoch: 318-24 batch_loss=1.25e-03\n",
            "Train Epoch: 318-36 batch_loss=1.48e-03\n",
            "Test set: Average loss: 0.0456 Average relative error: 0.0389\n",
            "Train Epoch: 319-0 batch_loss=1.29e-03\n",
            "Train Epoch: 319-12 batch_loss=1.23e-03\n",
            "Train Epoch: 319-24 batch_loss=1.52e-03\n",
            "Train Epoch: 319-36 batch_loss=1.32e-03\n",
            "Test set: Average loss: 0.0456 Average relative error: 0.0389\n",
            "Train Epoch: 320-0 batch_loss=1.15e-03\n",
            "Train Epoch: 320-12 batch_loss=1.57e-03\n",
            "Train Epoch: 320-24 batch_loss=1.61e-03\n",
            "Train Epoch: 320-36 batch_loss=1.09e-03\n",
            "Test set: Average loss: 0.0457 Average relative error: 0.0389\n",
            "Train Epoch: 321-0 batch_loss=1.17e-03\n",
            "Train Epoch: 321-12 batch_loss=1.16e-03\n",
            "Train Epoch: 321-24 batch_loss=1.46e-03\n",
            "Train Epoch: 321-36 batch_loss=1.07e-03\n",
            "Test set: Average loss: 0.0454 Average relative error: 0.0388\n",
            "Train Epoch: 322-0 batch_loss=1.12e-03\n",
            "Train Epoch: 322-12 batch_loss=1.96e-03\n",
            "Train Epoch: 322-24 batch_loss=1.41e-03\n",
            "Train Epoch: 322-36 batch_loss=1.23e-03\n",
            "Test set: Average loss: 0.0454 Average relative error: 0.0388\n",
            "Train Epoch: 323-0 batch_loss=1.00e-03\n",
            "Train Epoch: 323-12 batch_loss=1.34e-03\n",
            "Train Epoch: 323-24 batch_loss=1.46e-03\n",
            "Train Epoch: 323-36 batch_loss=1.48e-03\n",
            "Test set: Average loss: 0.0454 Average relative error: 0.0388\n",
            "Train Epoch: 324-0 batch_loss=1.16e-03\n",
            "Train Epoch: 324-12 batch_loss=1.20e-03\n",
            "Train Epoch: 324-24 batch_loss=1.63e-03\n",
            "Train Epoch: 324-36 batch_loss=1.07e-03\n",
            "Test set: Average loss: 0.0453 Average relative error: 0.0387\n",
            "Train Epoch: 325-0 batch_loss=1.80e-03\n",
            "Train Epoch: 325-12 batch_loss=1.28e-03\n",
            "Train Epoch: 325-24 batch_loss=1.09e-03\n",
            "Train Epoch: 325-36 batch_loss=1.41e-03\n",
            "Test set: Average loss: 0.0454 Average relative error: 0.0389\n",
            "Train Epoch: 326-0 batch_loss=1.43e-03\n",
            "Train Epoch: 326-12 batch_loss=1.32e-03\n",
            "Train Epoch: 326-24 batch_loss=1.72e-03\n",
            "Train Epoch: 326-36 batch_loss=1.22e-03\n",
            "Test set: Average loss: 0.0451 Average relative error: 0.0388\n",
            "Train Epoch: 327-0 batch_loss=1.07e-03\n",
            "Train Epoch: 327-12 batch_loss=1.69e-03\n",
            "Train Epoch: 327-24 batch_loss=1.32e-03\n",
            "Train Epoch: 327-36 batch_loss=1.48e-03\n",
            "Test set: Average loss: 0.0451 Average relative error: 0.0387\n",
            "Train Epoch: 328-0 batch_loss=1.61e-03\n",
            "Train Epoch: 328-12 batch_loss=1.03e-03\n",
            "Train Epoch: 328-24 batch_loss=1.64e-03\n",
            "Train Epoch: 328-36 batch_loss=1.04e-03\n",
            "Test set: Average loss: 0.0452 Average relative error: 0.0388\n",
            "Train Epoch: 329-0 batch_loss=1.27e-03\n",
            "Train Epoch: 329-12 batch_loss=1.47e-03\n",
            "Train Epoch: 329-24 batch_loss=1.69e-03\n",
            "Train Epoch: 329-36 batch_loss=1.16e-03\n",
            "Test set: Average loss: 0.0451 Average relative error: 0.0387\n",
            "Train Epoch: 330-0 batch_loss=1.30e-03\n",
            "Train Epoch: 330-12 batch_loss=1.52e-03\n",
            "Train Epoch: 330-24 batch_loss=1.39e-03\n",
            "Train Epoch: 330-36 batch_loss=1.48e-03\n",
            "Test set: Average loss: 0.0450 Average relative error: 0.0387\n",
            "Train Epoch: 331-0 batch_loss=1.65e-03\n",
            "Train Epoch: 331-12 batch_loss=1.31e-03\n",
            "Train Epoch: 331-24 batch_loss=1.19e-03\n",
            "Train Epoch: 331-36 batch_loss=1.67e-03\n",
            "Test set: Average loss: 0.0449 Average relative error: 0.0386\n",
            "Train Epoch: 332-0 batch_loss=1.23e-03\n",
            "Train Epoch: 332-12 batch_loss=1.53e-03\n",
            "Train Epoch: 332-24 batch_loss=1.30e-03\n",
            "Train Epoch: 332-36 batch_loss=1.38e-03\n",
            "Test set: Average loss: 0.0451 Average relative error: 0.0388\n",
            "Train Epoch: 333-0 batch_loss=1.37e-03\n",
            "Train Epoch: 333-12 batch_loss=1.58e-03\n",
            "Train Epoch: 333-24 batch_loss=1.18e-03\n",
            "Train Epoch: 333-36 batch_loss=1.53e-03\n",
            "Test set: Average loss: 0.0449 Average relative error: 0.0386\n",
            "Train Epoch: 334-0 batch_loss=1.65e-03\n",
            "Train Epoch: 334-12 batch_loss=1.20e-03\n",
            "Train Epoch: 334-24 batch_loss=1.38e-03\n",
            "Train Epoch: 334-36 batch_loss=1.47e-03\n",
            "Test set: Average loss: 0.0449 Average relative error: 0.0386\n",
            "Train Epoch: 335-0 batch_loss=1.06e-03\n",
            "Train Epoch: 335-12 batch_loss=1.44e-03\n",
            "Train Epoch: 335-24 batch_loss=1.72e-03\n",
            "Train Epoch: 335-36 batch_loss=1.56e-03\n",
            "Test set: Average loss: 0.0449 Average relative error: 0.0386\n",
            "Train Epoch: 336-0 batch_loss=1.61e-03\n",
            "Train Epoch: 336-12 batch_loss=1.31e-03\n",
            "Train Epoch: 336-24 batch_loss=1.82e-03\n",
            "Train Epoch: 336-36 batch_loss=1.05e-03\n",
            "Test set: Average loss: 0.0449 Average relative error: 0.0386\n",
            "Train Epoch: 337-0 batch_loss=1.39e-03\n",
            "Train Epoch: 337-12 batch_loss=1.16e-03\n",
            "Train Epoch: 337-24 batch_loss=1.21e-03\n",
            "Train Epoch: 337-36 batch_loss=1.39e-03\n",
            "Test set: Average loss: 0.0446 Average relative error: 0.0385\n",
            "Train Epoch: 338-0 batch_loss=1.69e-03\n",
            "Train Epoch: 338-12 batch_loss=1.59e-03\n",
            "Train Epoch: 338-24 batch_loss=1.27e-03\n",
            "Train Epoch: 338-36 batch_loss=1.31e-03\n",
            "Test set: Average loss: 0.0447 Average relative error: 0.0385\n",
            "Train Epoch: 339-0 batch_loss=1.32e-03\n",
            "Train Epoch: 339-12 batch_loss=1.75e-03\n",
            "Train Epoch: 339-24 batch_loss=1.42e-03\n",
            "Train Epoch: 339-36 batch_loss=1.36e-03\n",
            "Test set: Average loss: 0.0448 Average relative error: 0.0386\n",
            "Train Epoch: 340-0 batch_loss=1.40e-03\n",
            "Train Epoch: 340-12 batch_loss=1.41e-03\n",
            "Train Epoch: 340-24 batch_loss=1.33e-03\n",
            "Train Epoch: 340-36 batch_loss=1.40e-03\n",
            "Test set: Average loss: 0.0447 Average relative error: 0.0385\n",
            "Train Epoch: 341-0 batch_loss=1.28e-03\n",
            "Train Epoch: 341-12 batch_loss=1.23e-03\n",
            "Train Epoch: 341-24 batch_loss=1.43e-03\n",
            "Train Epoch: 341-36 batch_loss=1.53e-03\n",
            "Test set: Average loss: 0.0447 Average relative error: 0.0386\n",
            "Train Epoch: 342-0 batch_loss=1.27e-03\n",
            "Train Epoch: 342-12 batch_loss=1.38e-03\n",
            "Train Epoch: 342-24 batch_loss=1.42e-03\n",
            "Train Epoch: 342-36 batch_loss=1.07e-03\n",
            "Test set: Average loss: 0.0445 Average relative error: 0.0385\n",
            "Train Epoch: 343-0 batch_loss=1.18e-03\n",
            "Train Epoch: 343-12 batch_loss=1.31e-03\n",
            "Train Epoch: 343-24 batch_loss=1.14e-03\n",
            "Train Epoch: 343-36 batch_loss=1.34e-03\n",
            "Test set: Average loss: 0.0445 Average relative error: 0.0384\n",
            "Train Epoch: 344-0 batch_loss=1.81e-03\n",
            "Train Epoch: 344-12 batch_loss=1.46e-03\n",
            "Train Epoch: 344-24 batch_loss=1.35e-03\n",
            "Train Epoch: 344-36 batch_loss=1.16e-03\n",
            "Test set: Average loss: 0.0446 Average relative error: 0.0385\n",
            "Train Epoch: 345-0 batch_loss=1.12e-03\n",
            "Train Epoch: 345-12 batch_loss=1.77e-03\n",
            "Train Epoch: 345-24 batch_loss=1.28e-03\n",
            "Train Epoch: 345-36 batch_loss=1.32e-03\n",
            "Test set: Average loss: 0.0443 Average relative error: 0.0384\n",
            "Train Epoch: 346-0 batch_loss=1.58e-03\n",
            "Train Epoch: 346-12 batch_loss=1.60e-03\n",
            "Train Epoch: 346-24 batch_loss=1.43e-03\n",
            "Train Epoch: 346-36 batch_loss=1.59e-03\n",
            "Test set: Average loss: 0.0445 Average relative error: 0.0384\n",
            "Train Epoch: 347-0 batch_loss=1.29e-03\n",
            "Train Epoch: 347-12 batch_loss=1.37e-03\n",
            "Train Epoch: 347-24 batch_loss=1.58e-03\n",
            "Train Epoch: 347-36 batch_loss=9.99e-04\n",
            "Test set: Average loss: 0.0443 Average relative error: 0.0384\n",
            "Train Epoch: 348-0 batch_loss=1.03e-03\n",
            "Train Epoch: 348-12 batch_loss=1.29e-03\n",
            "Train Epoch: 348-24 batch_loss=1.17e-03\n",
            "Train Epoch: 348-36 batch_loss=1.67e-03\n",
            "Test set: Average loss: 0.0443 Average relative error: 0.0384\n",
            "Train Epoch: 349-0 batch_loss=1.10e-03\n",
            "Train Epoch: 349-12 batch_loss=1.53e-03\n",
            "Train Epoch: 349-24 batch_loss=1.70e-03\n",
            "Train Epoch: 349-36 batch_loss=1.39e-03\n",
            "Test set: Average loss: 0.0443 Average relative error: 0.0384\n",
            "Train Epoch: 350-0 batch_loss=1.29e-03\n",
            "Train Epoch: 350-12 batch_loss=1.27e-03\n",
            "Train Epoch: 350-24 batch_loss=1.46e-03\n",
            "Train Epoch: 350-36 batch_loss=1.39e-03\n",
            "Test set: Average loss: 0.0443 Average relative error: 0.0384\n",
            "Train Epoch: 351-0 batch_loss=1.58e-03\n",
            "Train Epoch: 351-12 batch_loss=1.27e-03\n",
            "Train Epoch: 351-24 batch_loss=1.23e-03\n",
            "Train Epoch: 351-36 batch_loss=1.14e-03\n",
            "Test set: Average loss: 0.0442 Average relative error: 0.0383\n",
            "Train Epoch: 352-0 batch_loss=1.26e-03\n",
            "Train Epoch: 352-12 batch_loss=1.56e-03\n",
            "Train Epoch: 352-24 batch_loss=1.95e-03\n",
            "Train Epoch: 352-36 batch_loss=1.52e-03\n",
            "Test set: Average loss: 0.0444 Average relative error: 0.0384\n",
            "Train Epoch: 353-0 batch_loss=1.26e-03\n",
            "Train Epoch: 353-12 batch_loss=1.51e-03\n",
            "Train Epoch: 353-24 batch_loss=9.77e-04\n",
            "Train Epoch: 353-36 batch_loss=1.37e-03\n",
            "Test set: Average loss: 0.0443 Average relative error: 0.0384\n",
            "Train Epoch: 354-0 batch_loss=1.30e-03\n",
            "Train Epoch: 354-12 batch_loss=1.39e-03\n",
            "Train Epoch: 354-24 batch_loss=1.52e-03\n",
            "Train Epoch: 354-36 batch_loss=1.48e-03\n",
            "Test set: Average loss: 0.0443 Average relative error: 0.0384\n",
            "Train Epoch: 355-0 batch_loss=1.44e-03\n",
            "Train Epoch: 355-12 batch_loss=1.37e-03\n",
            "Train Epoch: 355-24 batch_loss=1.23e-03\n",
            "Train Epoch: 355-36 batch_loss=1.24e-03\n",
            "Test set: Average loss: 0.0441 Average relative error: 0.0383\n",
            "Train Epoch: 356-0 batch_loss=1.13e-03\n",
            "Train Epoch: 356-12 batch_loss=1.52e-03\n",
            "Train Epoch: 356-24 batch_loss=1.20e-03\n",
            "Train Epoch: 356-36 batch_loss=1.42e-03\n",
            "Test set: Average loss: 0.0442 Average relative error: 0.0384\n",
            "Train Epoch: 357-0 batch_loss=1.53e-03\n",
            "Train Epoch: 357-12 batch_loss=1.24e-03\n",
            "Train Epoch: 357-24 batch_loss=1.33e-03\n",
            "Train Epoch: 357-36 batch_loss=1.40e-03\n",
            "Test set: Average loss: 0.0440 Average relative error: 0.0382\n",
            "Train Epoch: 358-0 batch_loss=1.31e-03\n",
            "Train Epoch: 358-12 batch_loss=1.52e-03\n",
            "Train Epoch: 358-24 batch_loss=1.13e-03\n",
            "Train Epoch: 358-36 batch_loss=1.47e-03\n",
            "Test set: Average loss: 0.0442 Average relative error: 0.0383\n",
            "Train Epoch: 359-0 batch_loss=1.38e-03\n",
            "Train Epoch: 359-12 batch_loss=1.06e-03\n",
            "Train Epoch: 359-24 batch_loss=1.16e-03\n",
            "Train Epoch: 359-36 batch_loss=1.28e-03\n",
            "Test set: Average loss: 0.0440 Average relative error: 0.0383\n",
            "Train Epoch: 360-0 batch_loss=1.38e-03\n",
            "Train Epoch: 360-12 batch_loss=1.65e-03\n",
            "Train Epoch: 360-24 batch_loss=1.23e-03\n",
            "Train Epoch: 360-36 batch_loss=1.27e-03\n",
            "Test set: Average loss: 0.0439 Average relative error: 0.0382\n",
            "Train Epoch: 361-0 batch_loss=1.25e-03\n",
            "Train Epoch: 361-12 batch_loss=1.25e-03\n",
            "Train Epoch: 361-24 batch_loss=1.36e-03\n",
            "Train Epoch: 361-36 batch_loss=1.35e-03\n",
            "Test set: Average loss: 0.0439 Average relative error: 0.0382\n",
            "Train Epoch: 362-0 batch_loss=1.59e-03\n",
            "Train Epoch: 362-12 batch_loss=1.25e-03\n",
            "Train Epoch: 362-24 batch_loss=1.40e-03\n",
            "Train Epoch: 362-36 batch_loss=1.13e-03\n",
            "Test set: Average loss: 0.0439 Average relative error: 0.0383\n",
            "Train Epoch: 363-0 batch_loss=1.40e-03\n",
            "Train Epoch: 363-12 batch_loss=1.43e-03\n",
            "Train Epoch: 363-24 batch_loss=1.47e-03\n",
            "Train Epoch: 363-36 batch_loss=1.40e-03\n",
            "Test set: Average loss: 0.0438 Average relative error: 0.0382\n",
            "Train Epoch: 364-0 batch_loss=1.10e-03\n",
            "Train Epoch: 364-12 batch_loss=1.37e-03\n",
            "Train Epoch: 364-24 batch_loss=1.50e-03\n",
            "Train Epoch: 364-36 batch_loss=1.15e-03\n",
            "Test set: Average loss: 0.0439 Average relative error: 0.0382\n",
            "Train Epoch: 365-0 batch_loss=1.40e-03\n",
            "Train Epoch: 365-12 batch_loss=1.19e-03\n",
            "Train Epoch: 365-24 batch_loss=1.34e-03\n",
            "Train Epoch: 365-36 batch_loss=1.22e-03\n",
            "Test set: Average loss: 0.0438 Average relative error: 0.0382\n",
            "Train Epoch: 366-0 batch_loss=1.15e-03\n",
            "Train Epoch: 366-12 batch_loss=1.12e-03\n",
            "Train Epoch: 366-24 batch_loss=1.37e-03\n",
            "Train Epoch: 366-36 batch_loss=1.06e-03\n",
            "Test set: Average loss: 0.0437 Average relative error: 0.0381\n",
            "Train Epoch: 367-0 batch_loss=1.36e-03\n",
            "Train Epoch: 367-12 batch_loss=1.82e-03\n",
            "Train Epoch: 367-24 batch_loss=1.15e-03\n",
            "Train Epoch: 367-36 batch_loss=1.34e-03\n",
            "Test set: Average loss: 0.0438 Average relative error: 0.0382\n",
            "Train Epoch: 368-0 batch_loss=1.37e-03\n",
            "Train Epoch: 368-12 batch_loss=1.28e-03\n",
            "Train Epoch: 368-24 batch_loss=1.23e-03\n",
            "Train Epoch: 368-36 batch_loss=1.38e-03\n",
            "Test set: Average loss: 0.0437 Average relative error: 0.0382\n",
            "Train Epoch: 369-0 batch_loss=1.52e-03\n",
            "Train Epoch: 369-12 batch_loss=1.45e-03\n",
            "Train Epoch: 369-24 batch_loss=1.06e-03\n",
            "Train Epoch: 369-36 batch_loss=1.03e-03\n",
            "Test set: Average loss: 0.0437 Average relative error: 0.0382\n",
            "Train Epoch: 370-0 batch_loss=1.43e-03\n",
            "Train Epoch: 370-12 batch_loss=1.35e-03\n",
            "Train Epoch: 370-24 batch_loss=1.31e-03\n",
            "Train Epoch: 370-36 batch_loss=1.38e-03\n",
            "Test set: Average loss: 0.0436 Average relative error: 0.0381\n",
            "Train Epoch: 371-0 batch_loss=1.26e-03\n",
            "Train Epoch: 371-12 batch_loss=1.22e-03\n",
            "Train Epoch: 371-24 batch_loss=1.53e-03\n",
            "Train Epoch: 371-36 batch_loss=1.23e-03\n",
            "Test set: Average loss: 0.0437 Average relative error: 0.0381\n",
            "Train Epoch: 372-0 batch_loss=1.33e-03\n",
            "Train Epoch: 372-12 batch_loss=1.24e-03\n",
            "Train Epoch: 372-24 batch_loss=1.29e-03\n",
            "Train Epoch: 372-36 batch_loss=1.34e-03\n",
            "Test set: Average loss: 0.0437 Average relative error: 0.0382\n",
            "Train Epoch: 373-0 batch_loss=1.32e-03\n",
            "Train Epoch: 373-12 batch_loss=1.63e-03\n",
            "Train Epoch: 373-24 batch_loss=1.45e-03\n",
            "Train Epoch: 373-36 batch_loss=1.29e-03\n",
            "Test set: Average loss: 0.0436 Average relative error: 0.0381\n",
            "Train Epoch: 374-0 batch_loss=1.29e-03\n",
            "Train Epoch: 374-12 batch_loss=1.55e-03\n",
            "Train Epoch: 374-24 batch_loss=1.23e-03\n",
            "Train Epoch: 374-36 batch_loss=1.11e-03\n",
            "Test set: Average loss: 0.0435 Average relative error: 0.0380\n",
            "Train Epoch: 375-0 batch_loss=1.34e-03\n",
            "Train Epoch: 375-12 batch_loss=1.21e-03\n",
            "Train Epoch: 375-24 batch_loss=9.95e-04\n",
            "Train Epoch: 375-36 batch_loss=1.04e-03\n",
            "Test set: Average loss: 0.0436 Average relative error: 0.0381\n",
            "Train Epoch: 376-0 batch_loss=1.22e-03\n",
            "Train Epoch: 376-12 batch_loss=1.39e-03\n",
            "Train Epoch: 376-24 batch_loss=1.61e-03\n",
            "Train Epoch: 376-36 batch_loss=1.77e-03\n",
            "Test set: Average loss: 0.0435 Average relative error: 0.0381\n",
            "Train Epoch: 377-0 batch_loss=1.27e-03\n",
            "Train Epoch: 377-12 batch_loss=1.06e-03\n",
            "Train Epoch: 377-24 batch_loss=1.33e-03\n",
            "Train Epoch: 377-36 batch_loss=1.44e-03\n",
            "Test set: Average loss: 0.0435 Average relative error: 0.0381\n",
            "Train Epoch: 378-0 batch_loss=1.14e-03\n",
            "Train Epoch: 378-12 batch_loss=1.41e-03\n",
            "Train Epoch: 378-24 batch_loss=1.47e-03\n",
            "Train Epoch: 378-36 batch_loss=1.37e-03\n",
            "Test set: Average loss: 0.0435 Average relative error: 0.0381\n",
            "Train Epoch: 379-0 batch_loss=1.12e-03\n",
            "Train Epoch: 379-12 batch_loss=1.11e-03\n",
            "Train Epoch: 379-24 batch_loss=1.23e-03\n",
            "Train Epoch: 379-36 batch_loss=1.05e-03\n",
            "Test set: Average loss: 0.0434 Average relative error: 0.0380\n",
            "Train Epoch: 380-0 batch_loss=1.16e-03\n",
            "Train Epoch: 380-12 batch_loss=1.03e-03\n",
            "Train Epoch: 380-24 batch_loss=1.36e-03\n",
            "Train Epoch: 380-36 batch_loss=1.46e-03\n",
            "Test set: Average loss: 0.0435 Average relative error: 0.0381\n",
            "Train Epoch: 381-0 batch_loss=1.30e-03\n",
            "Train Epoch: 381-12 batch_loss=1.28e-03\n",
            "Train Epoch: 381-24 batch_loss=1.28e-03\n",
            "Train Epoch: 381-36 batch_loss=1.65e-03\n",
            "Test set: Average loss: 0.0434 Average relative error: 0.0380\n",
            "Train Epoch: 382-0 batch_loss=1.22e-03\n",
            "Train Epoch: 382-12 batch_loss=1.61e-03\n",
            "Train Epoch: 382-24 batch_loss=1.38e-03\n",
            "Train Epoch: 382-36 batch_loss=1.45e-03\n",
            "Test set: Average loss: 0.0434 Average relative error: 0.0380\n",
            "Train Epoch: 383-0 batch_loss=1.09e-03\n",
            "Train Epoch: 383-12 batch_loss=1.26e-03\n",
            "Train Epoch: 383-24 batch_loss=1.22e-03\n",
            "Train Epoch: 383-36 batch_loss=1.49e-03\n",
            "Test set: Average loss: 0.0433 Average relative error: 0.0380\n",
            "Train Epoch: 384-0 batch_loss=1.55e-03\n",
            "Train Epoch: 384-12 batch_loss=1.19e-03\n",
            "Train Epoch: 384-24 batch_loss=1.25e-03\n",
            "Train Epoch: 384-36 batch_loss=1.38e-03\n",
            "Test set: Average loss: 0.0434 Average relative error: 0.0380\n",
            "Train Epoch: 385-0 batch_loss=1.10e-03\n",
            "Train Epoch: 385-12 batch_loss=1.15e-03\n",
            "Train Epoch: 385-24 batch_loss=1.31e-03\n",
            "Train Epoch: 385-36 batch_loss=1.31e-03\n",
            "Test set: Average loss: 0.0432 Average relative error: 0.0380\n",
            "Train Epoch: 386-0 batch_loss=1.61e-03\n",
            "Train Epoch: 386-12 batch_loss=1.32e-03\n",
            "Train Epoch: 386-24 batch_loss=1.18e-03\n",
            "Train Epoch: 386-36 batch_loss=1.46e-03\n",
            "Test set: Average loss: 0.0433 Average relative error: 0.0380\n",
            "Train Epoch: 387-0 batch_loss=1.35e-03\n",
            "Train Epoch: 387-12 batch_loss=1.46e-03\n",
            "Train Epoch: 387-24 batch_loss=1.24e-03\n",
            "Train Epoch: 387-36 batch_loss=1.38e-03\n",
            "Test set: Average loss: 0.0433 Average relative error: 0.0380\n",
            "Train Epoch: 388-0 batch_loss=1.26e-03\n",
            "Train Epoch: 388-12 batch_loss=1.31e-03\n",
            "Train Epoch: 388-24 batch_loss=1.36e-03\n",
            "Train Epoch: 388-36 batch_loss=1.43e-03\n",
            "Test set: Average loss: 0.0432 Average relative error: 0.0379\n",
            "Train Epoch: 389-0 batch_loss=1.09e-03\n",
            "Train Epoch: 389-12 batch_loss=1.37e-03\n",
            "Train Epoch: 389-24 batch_loss=1.37e-03\n",
            "Train Epoch: 389-36 batch_loss=1.10e-03\n",
            "Test set: Average loss: 0.0432 Average relative error: 0.0379\n",
            "Train Epoch: 390-0 batch_loss=1.34e-03\n",
            "Train Epoch: 390-12 batch_loss=1.43e-03\n",
            "Train Epoch: 390-24 batch_loss=1.51e-03\n",
            "Train Epoch: 390-36 batch_loss=1.21e-03\n",
            "Test set: Average loss: 0.0433 Average relative error: 0.0380\n",
            "Train Epoch: 391-0 batch_loss=1.77e-03\n",
            "Train Epoch: 391-12 batch_loss=1.43e-03\n",
            "Train Epoch: 391-24 batch_loss=1.11e-03\n",
            "Train Epoch: 391-36 batch_loss=1.44e-03\n",
            "Test set: Average loss: 0.0432 Average relative error: 0.0379\n",
            "Train Epoch: 392-0 batch_loss=1.39e-03\n",
            "Train Epoch: 392-12 batch_loss=1.14e-03\n",
            "Train Epoch: 392-24 batch_loss=1.31e-03\n",
            "Train Epoch: 392-36 batch_loss=1.18e-03\n",
            "Test set: Average loss: 0.0432 Average relative error: 0.0379\n",
            "Train Epoch: 393-0 batch_loss=1.97e-03\n",
            "Train Epoch: 393-12 batch_loss=1.78e-03\n",
            "Train Epoch: 393-24 batch_loss=1.33e-03\n",
            "Train Epoch: 393-36 batch_loss=1.16e-03\n",
            "Test set: Average loss: 0.0431 Average relative error: 0.0379\n",
            "Train Epoch: 394-0 batch_loss=1.02e-03\n",
            "Train Epoch: 394-12 batch_loss=1.26e-03\n",
            "Train Epoch: 394-24 batch_loss=1.47e-03\n",
            "Train Epoch: 394-36 batch_loss=1.10e-03\n",
            "Test set: Average loss: 0.0431 Average relative error: 0.0379\n",
            "Train Epoch: 395-0 batch_loss=1.54e-03\n",
            "Train Epoch: 395-12 batch_loss=1.82e-03\n",
            "Train Epoch: 395-24 batch_loss=1.18e-03\n",
            "Train Epoch: 395-36 batch_loss=1.32e-03\n",
            "Test set: Average loss: 0.0432 Average relative error: 0.0379\n",
            "Train Epoch: 396-0 batch_loss=1.10e-03\n",
            "Train Epoch: 396-12 batch_loss=1.62e-03\n",
            "Train Epoch: 396-24 batch_loss=1.58e-03\n",
            "Train Epoch: 396-36 batch_loss=1.12e-03\n",
            "Test set: Average loss: 0.0430 Average relative error: 0.0379\n",
            "Train Epoch: 397-0 batch_loss=1.17e-03\n",
            "Train Epoch: 397-12 batch_loss=1.66e-03\n",
            "Train Epoch: 397-24 batch_loss=1.12e-03\n",
            "Train Epoch: 397-36 batch_loss=1.46e-03\n",
            "Test set: Average loss: 0.0431 Average relative error: 0.0379\n",
            "Train Epoch: 398-0 batch_loss=1.32e-03\n",
            "Train Epoch: 398-12 batch_loss=1.48e-03\n",
            "Train Epoch: 398-24 batch_loss=1.30e-03\n",
            "Train Epoch: 398-36 batch_loss=1.48e-03\n",
            "Test set: Average loss: 0.0431 Average relative error: 0.0379\n",
            "Train Epoch: 399-0 batch_loss=1.36e-03\n",
            "Train Epoch: 399-12 batch_loss=1.32e-03\n",
            "Train Epoch: 399-24 batch_loss=1.06e-03\n",
            "Train Epoch: 399-36 batch_loss=1.49e-03\n",
            "Test set: Average loss: 0.0429 Average relative error: 0.0378\n",
            "Train Epoch: 400-0 batch_loss=1.31e-03\n",
            "Train Epoch: 400-12 batch_loss=1.47e-03\n",
            "Train Epoch: 400-24 batch_loss=9.84e-04\n",
            "Train Epoch: 400-36 batch_loss=1.29e-03\n",
            "Test set: Average loss: 0.0430 Average relative error: 0.0379\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_vtk(filename):\n",
        "    \"\"\"Read .vtk file and return the polydata\"\"\"\n",
        "\n",
        "    fn_dir, fn_ext = os.path.splitext(filename)\n",
        "\n",
        "    if fn_ext == '.vtk':\n",
        "        reader = vtk.vtkPolyDataReader()\n",
        "    elif fn_ext == '.vtp':\n",
        "        reader = vtk.vtkXMLPolyDataReader()\n",
        "    elif fn_ext == '.stl':\n",
        "        reader = vtk.vtkSTLReader()\n",
        "    elif fn_ext == '.obj':\n",
        "        reader = vtk.vtkOBJReader()\n",
        "    elif fn_ext == '.vtu':\n",
        "        reader = vtk.vtkXMLUnstructuredGridReader()\n",
        "    elif fn_ext == '.pvtu':\n",
        "        reader = vtk.vtkXMLPUnstructuredGridReader()\n",
        "    else:\n",
        "        raise ValueError(F\"File extension {fn_ext} not supported\")\n",
        "\n",
        "    reader.SetFileName(filename)\n",
        "    reader.Update(0)\n",
        "    mesh = reader.GetOutput()\n",
        "\n",
        "    return mesh\n",
        "\n",
        "def write_vtk(mesh, fn):\n",
        "    \"\"\" Write a mesh (vtk polydata or unstructured grid) to disk \"\"\"\n",
        "\n",
        "    _, extension = os.path.splitext(fn)\n",
        "\n",
        "    if extension == '.vtk':\n",
        "        writer = vtk.vtkPolyDataWriter()\n",
        "    elif extension == '.stl':\n",
        "        writer = vtk.vtkSTLWriter()\n",
        "    elif extension == '.vtp':\n",
        "        writer = vtk.vtkXMLPolyDataWriter()\n",
        "    elif extension == '.vtu':\n",
        "        writer = vtk.vtkXMLUnstructuredGridWriter()\n",
        "    elif extension == '.obj':\n",
        "        writer = vtk.vtkOBJWriter()\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized extension {extension}\")\n",
        "\n",
        "    writer.SetInputData(mesh)\n",
        "    writer.SetFileName(fn)\n",
        "    writer.Update(0)\n",
        "    writer.Write()\n",
        "\n",
        "    return\n",
        "\n",
        "def add_array(mesh, array, name):\n",
        "    \"\"\"Add numpy array as new field to a vtk file\"\"\"\n",
        "\n",
        "    new_array = numpy_to_vtk(array)\n",
        "    new_array.SetName(name)\n",
        "    mesh.GetPointData().AddArray(new_array)\n",
        "\n",
        "    return mesh\n",
        "\n",
        "def compute_matching_idxs():\n",
        "    \"\"\"Compute correspondences bewteen indices on the .vtu and on the .mesh file for plotting\"\"\"\n",
        "\n",
        "    mesh = read_vtk(os.path.join('/content/drive/MyDrive/data_ML4Science', 'geometries', 'bif_sym_alpha50_h0.10_ref.vtu'))\n",
        "    points = vtk_to_numpy(mesh.GetPoints().GetData())\n",
        "\n",
        "    mesh_2 = meshio.read(os.path.join('/content/drive/MyDrive/data_ML4Science', 'geometries','bif_sym_alpha50_h0.10.mesh'))\n",
        "    points_2 = mesh_2.points\n",
        "\n",
        "    dist = cdist(mesh_2.points, points, metric='euclidean')\n",
        "\n",
        "    idxs = np.argmin(dist, axis=0)\n",
        "\n",
        "    return idxs\n",
        "\n",
        "\n",
        "def visualize_solution(fields_array, fields=None, step_t=10):\n",
        "    \"\"\" Export the solution corresponding to the n-th snapshot (every step_t steps) to a .vtu file.\"\"\"\n",
        "\n",
        "    if fields is None:\n",
        "        fields = {'velocity': 3, 'pressure': 1}  # fields and corresponding dimensions\n",
        "\n",
        "    os.makedirs('solutions', exist_ok=True)\n",
        "\n",
        "    idxs = compute_matching_idxs()\n",
        "\n",
        "    mesh = read_vtk(os.path.join('/content/drive/MyDrive/data_ML4Science', 'geometries', 'bif_sym_alpha50_h0.10.vtu'))\n",
        "\n",
        "    fom_solution = dict()\n",
        "    for field in fields:\n",
        "        # print(f\"Processing field {field} - Dimension: {fields[field]}\")\n",
        "        cur_idxs = np.hstack([idxs + k * (Nh_space[field]//fields[field]) for k in range(fields[field])])\n",
        "        fom_solution[field] = expand(fields_array[field], basis_space[field], basis_time[field])[cur_idxs]\n",
        "        print(fom_solution[field].shape)\n",
        "\n",
        "    for cnt_t in range(0, Nh_time['velocity'], step_t):\n",
        "        # print(f\"\\nProcessing timestep {cnt_t} of {Nh_time['velocity']}\")\n",
        "        for field in fields:\n",
        "            cur_fom_solution = np.reshape(fom_solution[field][:, cnt_t], (fields[field], -1)).T\n",
        "            mesh = add_array(mesh, cur_fom_solution, field)\n",
        "\n",
        "        # write_vtk(mesh, os.path.join('solutions', f\"solution_{n}_{cnt_t}\" + '.vtu'))\n",
        "        write_vtk(mesh, os.path.join('solutions', f\"solution_{cnt_t}\" + '.vtu'))\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "WxKh2cvIOjf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_vel_trained.eval()\n",
        "# model_press_trained.eval()\n",
        "model_vel_trained_autoencoder.eval()\n",
        "model_press_trained_autoencoder.eval()\n",
        "\n",
        "input_tensor = torch.tensor(test_params[0,:], dtype=torch.float32)  # Trasforma in tensore\n",
        "input_tensor = input_tensor.unsqueeze(dim=0)\n",
        "input_tensor = input_tensor.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # output_vel_visual = model_vel_trained(input_tensor)\n",
        "    # output_vel_visual=output_vel_visual[0]\n",
        "    # print(output_vel_visual.shape)\n",
        "    # output_press_visual = model_press_trained(input_tensor)\n",
        "    # output_press_visual=output_press_visual[0]\n",
        "    # print(output_press_visual.shape)\n",
        "    output_vel_visual = model_vel_trained_autoencoder.predict(input_tensor)\n",
        "    output_vel_visual=output_vel_visual[0]\n",
        "    print(output_vel_visual.shape)\n",
        "    output_press_visual = model_press_trained_autoencoder.predict(input_tensor)\n",
        "    output_press_visual=output_press_visual[0]\n",
        "    print(output_press_visual.shape)\n",
        "\n",
        "output_visual=dict()\n",
        "output_visual['velocity']=output_vel_visual.cpu().numpy()\n",
        "output_visual['pressure']=output_press_visual.cpu().numpy()\n",
        "visualize_solution(output_visual,step_t=5)"
      ],
      "metadata": {
        "id": "Ezn9VDSNOwKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f290dd-3b10-44e3-9df7-28661a907324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([39, 16])\n",
            "torch.Size([9, 19])\n",
            "(10656, 1000)\n",
            "(3552, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r solutions.zip solutions\n",
        "from google.colab import files\n",
        "files.download('solutions.zip')"
      ],
      "metadata": {
        "id": "rWGvn5V8cY_I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5b2ada2-0c8e-418c-f2c3-d8a27973bef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: solutions/ (stored 0%)\n",
            "  adding: solutions/solution_285.vtu (deflated 29%)\n",
            "  adding: solutions/solution_565.vtu (deflated 29%)\n",
            "  adding: solutions/solution_535.vtu (deflated 29%)\n",
            "  adding: solutions/solution_295.vtu (deflated 29%)\n",
            "  adding: solutions/solution_410.vtu (deflated 29%)\n",
            "  adding: solutions/solution_855.vtu (deflated 29%)\n",
            "  adding: solutions/solution_945.vtu (deflated 29%)\n",
            "  adding: solutions/solution_590.vtu (deflated 29%)\n",
            "  adding: solutions/solution_805.vtu (deflated 29%)\n",
            "  adding: solutions/solution_820.vtu (deflated 29%)\n",
            "  adding: solutions/solution_650.vtu (deflated 29%)\n",
            "  adding: solutions/solution_940.vtu (deflated 29%)\n",
            "  adding: solutions/solution_110.vtu (deflated 29%)\n",
            "  adding: solutions/solution_595.vtu (deflated 29%)\n",
            "  adding: solutions/solution_635.vtu (deflated 29%)\n",
            "  adding: solutions/solution_340.vtu (deflated 29%)\n",
            "  adding: solutions/solution_985.vtu (deflated 29%)\n",
            "  adding: solutions/solution_55.vtu (deflated 29%)\n",
            "  adding: solutions/solution_365.vtu (deflated 29%)\n",
            "  adding: solutions/solution_800.vtu (deflated 29%)\n",
            "  adding: solutions/solution_355.vtu (deflated 29%)\n",
            "  adding: solutions/solution_160.vtu (deflated 29%)\n",
            "  adding: solutions/solution_860.vtu (deflated 29%)\n",
            "  adding: solutions/solution_670.vtu (deflated 29%)\n",
            "  adding: solutions/solution_735.vtu (deflated 29%)\n",
            "  adding: solutions/solution_790.vtu (deflated 29%)\n",
            "  adding: solutions/solution_930.vtu (deflated 29%)\n",
            "  adding: solutions/solution_995.vtu (deflated 29%)\n",
            "  adding: solutions/solution_965.vtu (deflated 29%)\n",
            "  adding: solutions/solution_350.vtu (deflated 29%)\n",
            "  adding: solutions/solution_170.vtu (deflated 29%)\n",
            "  adding: solutions/solution_400.vtu (deflated 29%)\n",
            "  adding: solutions/solution_30.vtu (deflated 29%)\n",
            "  adding: solutions/solution_835.vtu (deflated 29%)\n",
            "  adding: solutions/solution_515.vtu (deflated 29%)\n",
            "  adding: solutions/solution_510.vtu (deflated 29%)\n",
            "  adding: solutions/solution_85.vtu (deflated 29%)\n",
            "  adding: solutions/solution_230.vtu (deflated 29%)\n",
            "  adding: solutions/solution_330.vtu (deflated 29%)\n",
            "  adding: solutions/solution_580.vtu (deflated 29%)\n",
            "  adding: solutions/solution_395.vtu (deflated 29%)\n",
            "  adding: solutions/solution_830.vtu (deflated 29%)\n",
            "  adding: solutions/solution_40.vtu (deflated 29%)\n",
            "  adding: solutions/solution_165.vtu (deflated 29%)\n",
            "  adding: solutions/solution_815.vtu (deflated 29%)\n",
            "  adding: solutions/solution_960.vtu (deflated 29%)\n",
            "  adding: solutions/solution_200.vtu (deflated 29%)\n",
            "  adding: solutions/solution_505.vtu (deflated 29%)\n",
            "  adding: solutions/solution_75.vtu (deflated 29%)\n",
            "  adding: solutions/solution_955.vtu (deflated 29%)\n",
            "  adding: solutions/solution_120.vtu (deflated 29%)\n",
            "  adding: solutions/solution_600.vtu (deflated 29%)\n",
            "  adding: solutions/solution_500.vtu (deflated 29%)\n",
            "  adding: solutions/solution_390.vtu (deflated 29%)\n",
            "  adding: solutions/solution_905.vtu (deflated 29%)\n",
            "  adding: solutions/solution_730.vtu (deflated 29%)\n",
            "  adding: solutions/solution_865.vtu (deflated 29%)\n",
            "  adding: solutions/solution_20.vtu (deflated 29%)\n",
            "  adding: solutions/solution_460.vtu (deflated 29%)\n",
            "  adding: solutions/solution_475.vtu (deflated 29%)\n",
            "  adding: solutions/solution_260.vtu (deflated 29%)\n",
            "  adding: solutions/solution_890.vtu (deflated 29%)\n",
            "  adding: solutions/solution_425.vtu (deflated 29%)\n",
            "  adding: solutions/solution_255.vtu (deflated 29%)\n",
            "  adding: solutions/solution_615.vtu (deflated 29%)\n",
            "  adding: solutions/solution_95.vtu (deflated 29%)\n",
            "  adding: solutions/solution_15.vtu (deflated 29%)\n",
            "  adding: solutions/solution_480.vtu (deflated 29%)\n",
            "  adding: solutions/solution_585.vtu (deflated 29%)\n",
            "  adding: solutions/solution_10.vtu (deflated 29%)\n",
            "  adding: solutions/solution_525.vtu (deflated 29%)\n",
            "  adding: solutions/solution_555.vtu (deflated 29%)\n",
            "  adding: solutions/solution_315.vtu (deflated 29%)\n",
            "  adding: solutions/solution_5.vtu (deflated 29%)\n",
            "  adding: solutions/solution_240.vtu (deflated 29%)\n",
            "  adding: solutions/solution_420.vtu (deflated 29%)\n",
            "  adding: solutions/solution_495.vtu (deflated 29%)\n",
            "  adding: solutions/solution_620.vtu (deflated 29%)\n",
            "  adding: solutions/solution_810.vtu (deflated 29%)\n",
            "  adding: solutions/solution_125.vtu (deflated 29%)\n",
            "  adding: solutions/solution_90.vtu (deflated 29%)\n",
            "  adding: solutions/solution_575.vtu (deflated 29%)\n",
            "  adding: solutions/solution_455.vtu (deflated 29%)\n",
            "  adding: solutions/solution_740.vtu (deflated 29%)\n",
            "  adding: solutions/solution_190.vtu (deflated 29%)\n",
            "  adding: solutions/solution_570.vtu (deflated 29%)\n",
            "  adding: solutions/solution_375.vtu (deflated 29%)\n",
            "  adding: solutions/solution_545.vtu (deflated 29%)\n",
            "  adding: solutions/solution_990.vtu (deflated 29%)\n",
            "  adding: solutions/solution_270.vtu (deflated 29%)\n",
            "  adding: solutions/solution_900.vtu (deflated 29%)\n",
            "  adding: solutions/solution_470.vtu (deflated 29%)\n",
            "  adding: solutions/solution_135.vtu (deflated 29%)\n",
            "  adding: solutions/solution_35.vtu (deflated 29%)\n",
            "  adding: solutions/solution_300.vtu (deflated 29%)\n",
            "  adding: solutions/solution_80.vtu (deflated 29%)\n",
            "  adding: solutions/solution_435.vtu (deflated 29%)\n",
            "  adding: solutions/solution_210.vtu (deflated 29%)\n",
            "  adding: solutions/solution_345.vtu (deflated 29%)\n",
            "  adding: solutions/solution_725.vtu (deflated 29%)\n",
            "  adding: solutions/solution_310.vtu (deflated 29%)\n",
            "  adding: solutions/solution_775.vtu (deflated 29%)\n",
            "  adding: solutions/solution_605.vtu (deflated 29%)\n",
            "  adding: solutions/solution_760.vtu (deflated 29%)\n",
            "  adding: solutions/solution_540.vtu (deflated 29%)\n",
            "  adding: solutions/solution_60.vtu (deflated 29%)\n",
            "  adding: solutions/solution_625.vtu (deflated 29%)\n",
            "  adding: solutions/solution_265.vtu (deflated 29%)\n",
            "  adding: solutions/solution_450.vtu (deflated 29%)\n",
            "  adding: solutions/solution_825.vtu (deflated 29%)\n",
            "  adding: solutions/solution_710.vtu (deflated 29%)\n",
            "  adding: solutions/solution_290.vtu (deflated 29%)\n",
            "  adding: solutions/solution_65.vtu (deflated 29%)\n",
            "  adding: solutions/solution_755.vtu (deflated 29%)\n",
            "  adding: solutions/solution_215.vtu (deflated 29%)\n",
            "  adding: solutions/solution_640.vtu (deflated 29%)\n",
            "  adding: solutions/solution_220.vtu (deflated 29%)\n",
            "  adding: solutions/solution_660.vtu (deflated 29%)\n",
            "  adding: solutions/solution_25.vtu (deflated 29%)\n",
            "  adding: solutions/solution_690.vtu (deflated 29%)\n",
            "  adding: solutions/solution_245.vtu (deflated 29%)\n",
            "  adding: solutions/solution_185.vtu (deflated 29%)\n",
            "  adding: solutions/solution_205.vtu (deflated 29%)\n",
            "  adding: solutions/solution_720.vtu (deflated 29%)\n",
            "  adding: solutions/solution_50.vtu (deflated 29%)\n",
            "  adding: solutions/solution_885.vtu (deflated 29%)\n",
            "  adding: solutions/solution_465.vtu (deflated 29%)\n",
            "  adding: solutions/solution_275.vtu (deflated 29%)\n",
            "  adding: solutions/solution_925.vtu (deflated 29%)\n",
            "  adding: solutions/solution_550.vtu (deflated 29%)\n",
            "  adding: solutions/solution_105.vtu (deflated 29%)\n",
            "  adding: solutions/solution_665.vtu (deflated 29%)\n",
            "  adding: solutions/solution_920.vtu (deflated 29%)\n",
            "  adding: solutions/solution_655.vtu (deflated 29%)\n",
            "  adding: solutions/solution_850.vtu (deflated 29%)\n",
            "  adding: solutions/solution_195.vtu (deflated 29%)\n",
            "  adding: solutions/solution_415.vtu (deflated 29%)\n",
            "  adding: solutions/solution_305.vtu (deflated 29%)\n",
            "  adding: solutions/solution_840.vtu (deflated 29%)\n",
            "  adding: solutions/solution_145.vtu (deflated 29%)\n",
            "  adding: solutions/solution_45.vtu (deflated 29%)\n",
            "  adding: solutions/solution_130.vtu (deflated 29%)\n",
            "  adding: solutions/solution_385.vtu (deflated 29%)\n",
            "  adding: solutions/solution_705.vtu (deflated 29%)\n",
            "  adding: solutions/solution_530.vtu (deflated 29%)\n",
            "  adding: solutions/solution_320.vtu (deflated 29%)\n",
            "  adding: solutions/solution_695.vtu (deflated 29%)\n",
            "  adding: solutions/solution_0.vtu (deflated 29%)\n",
            "  adding: solutions/solution_645.vtu (deflated 29%)\n",
            "  adding: solutions/solution_360.vtu (deflated 29%)\n",
            "  adding: solutions/solution_745.vtu (deflated 29%)\n",
            "  adding: solutions/solution_715.vtu (deflated 29%)\n",
            "  adding: solutions/solution_325.vtu (deflated 29%)\n",
            "  adding: solutions/solution_140.vtu (deflated 29%)\n",
            "  adding: solutions/solution_780.vtu (deflated 29%)\n",
            "  adding: solutions/solution_785.vtu (deflated 29%)\n",
            "  adding: solutions/solution_100.vtu (deflated 29%)\n",
            "  adding: solutions/solution_880.vtu (deflated 29%)\n",
            "  adding: solutions/solution_485.vtu (deflated 29%)\n",
            "  adding: solutions/solution_380.vtu (deflated 29%)\n",
            "  adding: solutions/solution_895.vtu (deflated 29%)\n",
            "  adding: solutions/solution_370.vtu (deflated 29%)\n",
            "  adding: solutions/solution_430.vtu (deflated 29%)\n",
            "  adding: solutions/solution_910.vtu (deflated 29%)\n",
            "  adding: solutions/solution_685.vtu (deflated 29%)\n",
            "  adding: solutions/solution_445.vtu (deflated 29%)\n",
            "  adding: solutions/solution_680.vtu (deflated 29%)\n",
            "  adding: solutions/solution_950.vtu (deflated 29%)\n",
            "  adding: solutions/solution_975.vtu (deflated 29%)\n",
            "  adding: solutions/solution_490.vtu (deflated 29%)\n",
            "  adding: solutions/solution_980.vtu (deflated 29%)\n",
            "  adding: solutions/solution_765.vtu (deflated 29%)\n",
            "  adding: solutions/solution_70.vtu (deflated 29%)\n",
            "  adding: solutions/solution_335.vtu (deflated 29%)\n",
            "  adding: solutions/solution_970.vtu (deflated 29%)\n",
            "  adding: solutions/solution_175.vtu (deflated 29%)\n",
            "  adding: solutions/solution_610.vtu (deflated 29%)\n",
            "  adding: solutions/solution_875.vtu (deflated 29%)\n",
            "  adding: solutions/solution_845.vtu (deflated 29%)\n",
            "  adding: solutions/solution_630.vtu (deflated 29%)\n",
            "  adding: solutions/solution_675.vtu (deflated 29%)\n",
            "  adding: solutions/solution_870.vtu (deflated 29%)\n",
            "  adding: solutions/solution_115.vtu (deflated 29%)\n",
            "  adding: solutions/solution_560.vtu (deflated 29%)\n",
            "  adding: solutions/solution_520.vtu (deflated 29%)\n",
            "  adding: solutions/solution_155.vtu (deflated 29%)\n",
            "  adding: solutions/solution_150.vtu (deflated 29%)\n",
            "  adding: solutions/solution_700.vtu (deflated 29%)\n",
            "  adding: solutions/solution_750.vtu (deflated 29%)\n",
            "  adding: solutions/solution_915.vtu (deflated 29%)\n",
            "  adding: solutions/solution_250.vtu (deflated 29%)\n",
            "  adding: solutions/solution_440.vtu (deflated 29%)\n",
            "  adding: solutions/solution_225.vtu (deflated 29%)\n",
            "  adding: solutions/solution_770.vtu (deflated 29%)\n",
            "  adding: solutions/solution_280.vtu (deflated 29%)\n",
            "  adding: solutions/solution_405.vtu (deflated 29%)\n",
            "  adding: solutions/solution_795.vtu (deflated 29%)\n",
            "  adding: solutions/solution_180.vtu (deflated 29%)\n",
            "  adding: solutions/solution_235.vtu (deflated 29%)\n",
            "  adding: solutions/solution_935.vtu (deflated 29%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_beb0ab12-b178-43d0-8d1d-45a8aba7bd9c\", \"solutions.zip\", 57611833)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}