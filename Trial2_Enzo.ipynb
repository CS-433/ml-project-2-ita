{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Invi4SwWUGt0",
        "outputId": "611b2d28-586f-46d1-d203-5784147ed861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vtk in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from vtk) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk) (1.16.0)\n",
            "Requirement already satisfied: meshio in /usr/local/lib/python3.10/dist-packages (5.3.5)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from meshio) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from meshio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->meshio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->meshio) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->meshio) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->meshio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install vtk\n",
        "!pip install meshio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcjMZnnRwpCN"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import vtkmodules.all as vtk\n",
        "from vtkmodules.util.numpy_support import vtk_to_numpy, numpy_to_vtk\n",
        "import meshio\n",
        "from scipy.spatial.distance import cdist\n",
        "from torchvision import datasets, transforms\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "R9olb7sJ2u0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ3-Jiio0MMr",
        "outputId": "58e71606-8868-4063-b7b1-4b406727ed10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#device=torch.device('cpu')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdOhmH83cwz2"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6Cg8T5wmrPq"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = '/content/drive/MyDrive/data_ML4Science'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Bqc_7Kl3RmC"
      },
      "outputs": [],
      "source": [
        "fields = {'velocity', 'pressure'}\n",
        "\n",
        "basis_space, sv_space, Nh_space, nmodes_space = dict(), dict(), dict(), dict()\n",
        "basis_time, sv_time, Nh_time, nmodes_time = dict(), dict(), dict(), dict()\n",
        "nmodes = dict()\n",
        "for field in fields:\n",
        "    basis_space[field] = np.load(os.path.join(DATASET_PATH, 'basis', field, 'space_basis.npy'))  # spatial basis\n",
        "    sv_space[field] = np.load(os.path.join(DATASET_PATH, 'basis', field, 'space_sv.npy'))  # singular values in space\n",
        "    Nh_space[field], nmodes_space[field] = basis_space[field].shape  # number of FOM and ROM unknowns in space\n",
        "    basis_time[field] = np.load(os.path.join(DATASET_PATH, 'basis', field, 'time_basis.npy'))  # temporal basis\n",
        "    sv_time[field] = np.load(os.path.join(DATASET_PATH, 'basis', field, 'time_sv.npy'))  # singular values in time\n",
        "    Nh_time[field], nmodes_time[field] = basis_time[field].shape  # number of FOM and ROM unknowns in time\n",
        "    nmodes[field] = nmodes_space[field] * nmodes_time[field]  # total dimension of the reduced basis\n",
        "\n",
        "# UPDATE VELOCITY BASES TO ACCOUNT FOR SUPREMIZERS AND STABILIZERS\n",
        "N_supr_space = basis_space['pressure'].shape[1] + 66  # number of extra bases in space for the velocity\n",
        "N_supr_time = 5  # number of extra bases in time for the velocity\n",
        "\n",
        "# STORE ORIGINAL NUMBER OF VELOCITY MODES IN THE DICTIONARY\n",
        "nmodes_space['velocity_full'] = nmodes_space['velocity']\n",
        "nmodes_time['velocity_full'] = nmodes_time['velocity']\n",
        "nmodes['velocity_full'] = nmodes['velocity']\n",
        "\n",
        "# UPDATE THE NUMBER OF VELOCITY MODES TO ACCOUNT FOR SUPREMIZERS AND STABILIZERS\n",
        "nmodes_space['velocity'] -= N_supr_space\n",
        "nmodes_time['velocity'] -= N_supr_time\n",
        "nmodes['velocity'] = nmodes_space['velocity'] * nmodes_time['velocity']\n",
        "\n",
        "# UPDATE VELOCITY BASES TO ACCOUNT FOR SUPREMIZERS AND STABILIZERS\n",
        "basis_space['velocity'] = basis_space['velocity'][:, :nmodes_space['velocity']]\n",
        "basis_time['velocity'] = basis_time['velocity'][:, :nmodes_time['velocity']]\n",
        "\n",
        "# LOAD NORMED BASIS MATRICES IN SPACE (needed for projections)\n",
        "basis_space_normed = dict()\n",
        "#norm = dict()\n",
        "for field in fields:\n",
        "    #norm[field] = load_npz(os.path.join('dataset', 'norms', f'norm_{field}.npz'))\n",
        "    #basis_space_normed[field] = norm[field].dot(basis_space[field])\n",
        "    #np.save(os.path.join('dataset', 'basis', field, 'basis_space_normed.npy'), basis_space_normed[field])\n",
        "    basis_space_normed[field] = np.load(os.path.join(DATASET_PATH, 'basis', field, 'basis_space_normed.npy'))\n",
        "\n",
        "##################################################################\n",
        "def project(sol, normed_basis_space, basis_time):\n",
        "    \"\"\" Project a full-order solution in space-time.\"\"\"\n",
        "    return (normed_basis_space.T.dot(sol)).dot(basis_time) # !! REMARK: here we need the normed basis in space !!\n",
        "\n",
        "def expand(sol, basis_space, basis_time):\n",
        "    \"\"\" Expand a reduced-order solution in space-time.\"\"\"\n",
        "    return (basis_space.dot(sol)).dot(basis_time.T)\n",
        "\n",
        "##################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA3wRZEOoVLB"
      },
      "outputs": [],
      "source": [
        "params = np.load(os.path.join(DATASET_PATH, 'RB_data', 'parameters.npy'))\n",
        "params = np.delete(params, 2, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0EhSv14og6T"
      },
      "outputs": [],
      "source": [
        "n_snaps = None  # change to a number if you want to load only a subset of snapshots\n",
        "_sol = np.load(os.path.join(DATASET_PATH, 'RB_data', 'solutions.npy'))[:n_snaps]\n",
        "\n",
        "solutions = dict()\n",
        "\n",
        "# velocity reduced solutions (with and without supremizers and stabilizers)\n",
        "solutions['velocity_full'] = np.reshape(_sol[:, :nmodes['velocity_full']],\n",
        "                                        (-1, nmodes_space['velocity_full'], nmodes_time['velocity_full']))\n",
        "solutions['velocity'] = solutions['velocity_full'][:, :nmodes_space['velocity'], :nmodes_time['velocity']]\n",
        "\n",
        "# pressure reduced solutions\n",
        "solutions['pressure'] = np.reshape(_sol[:, :nmodes['pressure']],\n",
        "                                   (-1, nmodes_space['pressure'], nmodes_time['pressure']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhZYXNL9n_ju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df78f1c-468c-4e85-8869-b24e545d5f15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76974, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "basis_space['velocity'].shape #Vs = Ns *ns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_IJ_VUYoCEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e77f15c-a76e-4c6d-d68e-f551c3c477c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "basis_time['velocity'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdrwegyJc-wT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqQ58u-UoEeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc469d7-a106-41dd-d53f-e9509bf49361"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3552, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "basis_space['pressure'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMO1E5SjoGvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0acd185-388f-4a4b-f446-5a79f400d998"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "basis_time['pressure'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sstQrU6Ds11j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d641d779-dc7f-4d60-8a4e-e006af059975"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1950, 9, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "solutions['pressure'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O_IrlxOxbRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9632f25-d3a6-4e1b-90f7-a34cf4b90c5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1950, 39, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "solutions['velocity'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57AtIrbHogWJ"
      },
      "outputs": [],
      "source": [
        "solutions['pressure']= torch.tensor(solutions['pressure'], dtype=torch.float32)\n",
        "solutions['velocity']= torch.tensor(solutions['velocity'], dtype=torch.float32)\n",
        "params = torch.tensor(params, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMIFcsExttZc"
      },
      "outputs": [],
      "source": [
        "class Fluid_Dataset(Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets =  targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.inputs.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        input = self.inputs[idx]\n",
        "        output = self.targets[idx]\n",
        "        return input, output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zePSfOcbvLOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8a58b5-97ae-40bb-b2e3-fdddc8dda701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([151.1840,  47.9287,  -4.8919, -13.6345,  15.4792,  -4.2125,  -0.3348,\n",
            "          5.1385,  -0.6269,  -3.8354,  -0.5111,   4.1919,  -3.5017,  -0.8359,\n",
            "         -0.5537,  -0.7395])\n"
          ]
        }
      ],
      "source": [
        "N_data=params.shape[0]\n",
        "indices = torch.randperm(N_data)\n",
        "ratio_data=0.8\n",
        "train_size = int(ratio_data * N_data)\n",
        "train_indices = indices[:train_size]\n",
        "test_indices=indices[train_size:]\n",
        "\n",
        "train_params=params[train_indices]\n",
        "test_params=params[test_indices]\n",
        "\n",
        "mean_params=torch.mean(train_params,dim=0)\n",
        "std_params=torch.std(train_params,dim=0)\n",
        "train_params=(train_params-mean_params)/std_params\n",
        "test_params=(test_params-mean_params)/std_params\n",
        "\n",
        "\n",
        "train_vel=solutions['velocity'][train_indices]\n",
        "\n",
        "test_vel=solutions['velocity'][test_indices]\n",
        "\n",
        "train_press=solutions['pressure'][train_indices]\n",
        "test_press=solutions['pressure'][test_indices]\n",
        "print(train_vel[0,0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLHSePTbcFq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a088b3-bb44-4708-8099-0b73a74e7f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.7319,  0.2168, -0.5090, -0.7062,  0.7336,  2.1690,  0.4455, -2.7250,\n",
            "        -1.2003, -0.4249,  1.8618, -1.7595, -0.5973, -0.1114,  0.1245,  0.8888])\n"
          ]
        }
      ],
      "source": [
        "#STANDARDITZAION ALTERNATIVE ZERO\n",
        "vel_space_mean = torch.mean(train_vel, dim= 0)\n",
        "vel_space_std = torch.std(train_vel, dim=0)\n",
        "train_vel = (train_vel - vel_space_mean) / vel_space_std\n",
        "test_vel =(test_vel - vel_space_mean) / vel_space_std\n",
        "\n",
        "\n",
        "print(train_vel[0,0,:])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_vel.mean())\n",
        "print(test_vel.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8TI9AnOoEkj",
        "outputId": "2529f791-eff8-4002-b703-52b36ab24f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.3876e-10)\n",
            "tensor(0.0003)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foxgkv9l0ikm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b00a281-9936-4e16-e5a1-e1aeb3f08f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5125, 0.4972, 0.3822, 0.1550, 0.7809, 0.2477, 0.4258, 0.5963, 0.3093,\n",
            "        0.2861, 0.3506, 0.6018, 0.7280, 0.6898, 0.3659, 0.5932])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#STANDARDITZAION ALTERNATIVE ONE\n",
        "vel_space_max = torch.max(train_vel, dim= 0).values\n",
        "vel_space_min = torch.min(train_vel, dim=0).values\n",
        "train_vel = (train_vel - vel_space_min*0.95) / (1.05*vel_space_max - 0.95*vel_space_min)\n",
        "test_vel =(test_vel - vel_space_min*0.95) / (1.05*vel_space_max - 0.95*vel_space_min)\n",
        "\n",
        "\n",
        "\n",
        "print(train_vel[0,0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnyE0gXK6WLS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jyi6yYWK2MEF"
      },
      "outputs": [],
      "source": [
        "train_params.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJyxsOfu2PL1"
      },
      "outputs": [],
      "source": [
        "test_params.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2ePjgZznYjm"
      },
      "outputs": [],
      "source": [
        "train_vel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzd6zZONneMB"
      },
      "outputs": [],
      "source": [
        "test_vel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl0I7JiFuMXM"
      },
      "outputs": [],
      "source": [
        "#IGNORE THIS FOR THE MOMENT\n",
        "class MLP_press_ConvAutoencoder(torch.nn.Module):\n",
        "    def __init__(self, parameters=3, dim_1=39, dim_2=16, dim_1_reduced=18, dim_2_reduced=8, L=4, K=256):\n",
        "        super(MLP_press_ConvAutoencoder, self).__init__()\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            *[layer for i in range(L) for layer in [\n",
        "                torch.nn.Linear(parameters if i == 0 else K, K),\n",
        "                torch.nn.LayerNorm(K),\n",
        "                torch.nn.GELU(),\n",
        "            ]],\n",
        "            torch.nn.Linear(K, dim_1_reduced * dim_2_reduced),\n",
        "            torch.nn.Unflatten(1, (dim_1_reduced, dim_2_reduced))  # Reshaping to (-1, dim_1_reduced, dim_2_reduced)\n",
        "        )\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),  # (batch_size, 1, dim_1, dim_2) -> (batch_size, 16, 20, 8)\n",
        "            torch.nn.BatchNorm2d(num_features=16),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # (batch_size, 16, 20, 8) -> (batch_size, 32, 10, 4)\n",
        "            torch.nn.BatchNorm2d(num_features=32),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Flatten(),  # (batch_size, 32, 10, 4) -> (batch_size, 1280)\n",
        "            torch.nn.Linear(32*10*4, dim_1_reduced * dim_2_reduced),  # (batch_size, 1280) -> (batch_size, dim_1_reduced * dim_2_reduced)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Unflatten(1, (dim_1_reduced , dim_2_reduced))  # Reshape to (batch_size, dim_1_reduced, dim_2_reduced)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "      torch.nn.Flatten(1),\n",
        "      torch.nn.Linear(18 * 8, 32 * 10 * 4),  # (batch_size, dim_1_reduced * dim_2_reduced) -> (batch_size, 32*10*4)\n",
        "      torch.nn.BatchNorm1d(32 * 10 * 4),  # Batch normalization before ReLU\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.Unflatten(1, (32, 10, 4)),  # (batch_size, 32*10*4) -> (batch_size, 32, 10, 4)\n",
        "      torch.nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),  # (batch_size, 32, 10, 4) -> (batch_size, 16, 20, 8)\n",
        "      torch.nn.BatchNorm2d(16),  # Batch normalization before ReLU\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=(0, 1)),  # (batch_size, 16, 20, 8) -> (batch_size, 1, 39, 16)\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "    def forward(self, par, out):\n",
        "        Z1 = self.mlp(par)  # (dim_1_reduced * dim_2_reduced)\n",
        "\n",
        "        out_squeezed = out.unsqueeze(1)\n",
        "          # Adding channel dimension to input\n",
        "        Z2 = self.encoder(out_squeezed)  # (dim_1_reduced * dim_2_reduced)\n",
        "\n",
        "        Z3 = self.decoder(Z2) # (batch_siz, 1, dim_1, dim_2)\n",
        "        Z3=Z3.squeeze(1)  # (batch_siz, dim_1, dim_2)\n",
        "\n",
        "        return Z1, Z2, Z3\n",
        "\n",
        "    def predict(self, par):\n",
        "        Z = self.mlp(par)  # (dim_1_reduced * dim_2_reduced)\n",
        "        Z = self.decoder(Z)  # (batch_size, 1, dim_1, dim_2)\n",
        "        Z=Z.squeeze(1)\n",
        "        return Z\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVL4yfwkYva1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = MLP_press_ConvAutoencoder()\n",
        "  # Valori casuali tra 0 e 1\n",
        "z1, z2, z3= model.forward(train_params,train_vel)"
      ],
      "metadata": {
        "id": "VZUhqoGWT8y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_lXkgjfT-Ua",
        "outputId": "bb982e8b-4ead-4860-a2af-0fd7a60e6bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 18, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ2FXxmGT_cB",
        "outputId": "aa7ae255-258c-4431-d2ee-b5a49f9e8fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 18, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA9_cwCcUD7S",
        "outputId": "544103b0-4554-46a4-d164-7bc23bad75e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 39, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I'M USING THIS AT THE MOMENT\n",
        "\n",
        "class MLP_press_ConvAutoencoder_2(torch.nn.Module):\n",
        "    def __init__(self, parameters=3, dim_1=39, dim_2=16, dim_reduced=128, L=4, K=256):\n",
        "        super(MLP_press_ConvAutoencoder_2, self).__init__()\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            *[layer for i in range(L) for layer in [\n",
        "                torch.nn.Linear(parameters if i == 0 else K, K),\n",
        "                torch.nn.LayerNorm(K),\n",
        "                torch.nn.ReLU(),\n",
        "            ]],\n",
        "            torch.nn.Linear(K, dim_reduced), #(batch_size, K) -> (batch_size, dim_reduced)\n",
        "\n",
        "        )\n",
        "\n",
        "        # Encoder\n",
        "\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=1),  # (batch_size, 1, dim_1, dim_2) -> (batch_size, 64, 19, 7)\n",
        "            #torch.nn.BatchNorm2d(64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # (batch_size, 64, 19, 7) -> (batch_size, 128, 10, 4)\n",
        "            #torch.nn.BatchNorm2d(128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Flatten(),      #(batch_size, 128, 10, 4) -> (batch_size, 128 x 10 x 4)\n",
        "            torch.nn.Linear(128*10*4, 256),    #(batch_size, 128 x 10 x 4) ->  batch_size, 256)\n",
        "            #torch.nn.Dropout(p=0.3)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, dim_reduced)  #(batch_size, 256) ->  (batch_size, dim_reduced)\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(dim_reduced, 256),    # (batch_size, dim_reduced)-> #(batch_size, 256)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128*10*4), # (batch_size, 256)-> #(batch_size, 128*10*4)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Unflatten(1, (128, 10, 4)),      #(batch_size, 128*10*4) -> (batch_size, 128, 10, 4)\n",
        "            torch.nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=(0, 0)), # (batch_size, 128, 10, 4) -> # (batch_size, 64, 19, 7)\n",
        "            #torch.nn.BatchNorm2d(64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.ConvTranspose2d(64, 1, kernel_size=5, stride=2, padding=1, output_padding=(0, 1)),   # -> (batch_size, 64, 19, 7) --> (batch_size, 1, dim_1, dim_2)\n",
        "            torch.nn.Sigmoid() #LEVAREEEEEEEE SE NON MIN MAX\n",
        "            #-------->LEVAREEEEEEEE SE NON MIN MAX\n",
        "            #-------->LEVAREEEEEEEE SE NON MIN MAX\n",
        "            #-------->LEVAREEEEEEEE SE NON MIN MAX\n",
        "            #-------->LEVAREEEEEEEE SE NON MIN MAX\n",
        "            #-------->LEVAREEEEEEEE SE NON MIN MAX\n",
        "            #-------->LEVAREEEEEEEE SE NON MIN MAX\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, par, out):\n",
        "        Z1 = self.mlp(par)  # (batch_size, dim_reduced)\n",
        "\n",
        "        out_squeezed = out.unsqueeze(1) #(batch_size x 39 x 16) -> #(batch_size x 1 x 39 x 16)\n",
        "        Z2 = self.encoder(out_squeezed)  # (batch_size, dim_reduced)\n",
        "\n",
        "        Z3 = self.decoder(Z2) # (batch_siz, 1, dim_1, dim_2)\n",
        "        Z3=Z3.squeeze(1)  # (batch_siz, dim_1, dim_2)\n",
        "\n",
        "        return Z1, Z2, Z3\n",
        "\n",
        "    def predict(self, par):\n",
        "        Z = self.mlp(par)  # (dim_1_reduced * dim_2_reduced)\n",
        "        Z = self.decoder(Z)  # (batch_size, 1, dim_1, dim_2)\n",
        "        Z=Z.squeeze(1)\n",
        "        return Z"
      ],
      "metadata": {
        "id": "HAX-EZRXUBll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yIMUR21Cfoez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = MLP_press_ConvAutoencoder_2()\n",
        "  # Valori casuali tra 0 e 1\n",
        "z1, z2, z3= model.forward(train_params,train_vel)"
      ],
      "metadata": {
        "id": "TMi1vXFzY8xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NhSZdWwZFKA",
        "outputId": "88af2bcd-0897-4f26-b40d-00dcdf25c174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggE3gpJhZGsL",
        "outputId": "4466d6fa-64fd-4fd1-df90-fde17acd45a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_YzJP87ZJbM",
        "outputId": "8b8471f0-d791-48e5-ef65-ce042177307a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 39, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I141B3VFW7DW"
      },
      "outputs": [],
      "source": [
        "# vel_space_mean=vel_space_mean.to('cuda')\n",
        "# vel_space_std=vel_space_std.to('cuda')\n",
        "vel_space_min=vel_space_min.to('cuda')\n",
        "vel_space_max=vel_space_max.to('cuda')\n",
        "\n",
        "#TODO: normalize input of encoder\n",
        "\n",
        "def train_encoder_decoder_epoch(model, device, train_loader, optimizer, epoch, criterion):\n",
        "    model.train()  # Important set model to train mode (affects dropout, batch norm etc)\n",
        "\n",
        "    loss_history = []\n",
        "    accuracy_history = []\n",
        "    loss_history_enc_dec = []\n",
        "    loss_history_mlp_encoder = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "\n",
        "        data=data.to(device)\n",
        "        target=target.to(device)\n",
        "\n",
        "        Z1, Z2, Z3 = model.forward(data, target)\n",
        "\n",
        "        assert Z3.shape == target.shape\n",
        "        assert Z1.shape == Z2.shape\n",
        "\n",
        "        # ###########################\n",
        "        # target=target*vel_space_std+vel_space_mean\n",
        "        # Z3=Z3*vel_space_std+vel_space_mean\n",
        "        # ###########################\n",
        "        target=target*(1.1*vel_space_max - 0.9*vel_space_min)+0.9*vel_space_min\n",
        "        Z3=Z3*(1.1*vel_space_max - 0.9*vel_space_min)+0.9*vel_space_min\n",
        "        ##############################\n",
        "\n",
        "        Z3_flattened = Z3.flatten(1)\n",
        "        target_fattened = target.flatten(1)\n",
        "\n",
        "        loss_enc_dec =  criterion(target_fattened, Z3_flattened)\n",
        "        loss_mlp_encoder = criterion(Z1, Z2)\n",
        "\n",
        "\n",
        "        loss =  loss_enc_dec + loss_mlp_encoder\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        loss.backward()        # Backpropagation\n",
        "        optimizer.step()       # Update the weights\n",
        "\n",
        "        loss_history_enc_dec.append(loss_enc_dec.item())\n",
        "        loss_history_mlp_encoder.append(loss_mlp_encoder.item())\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    return loss_history, loss_history_enc_dec, loss_history_mlp_encoder\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, device, val_loader, criterion):\n",
        "    model.eval()  # Important set model to eval mode (affects dropout, batch norm etc)\n",
        "    test_loss = 0\n",
        "    test_rel_loss = 0\n",
        "    for data, target in val_loader:\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model.predict(data)\n",
        "        assert output.shape == target.shape\n",
        "\n",
        "        # #####################\n",
        "        # output=output*vel_space_std+vel_space_mean\n",
        "        # target=target*vel_space_std+vel_space_mean\n",
        "        # #####################\n",
        "        output=output*(1.1*vel_space_max - 0.9*vel_space_min)+0.9*vel_space_min\n",
        "        target=target*(1.1*vel_space_max - 0.9*vel_space_min)+0.9*vel_space_min\n",
        "        ##############################\n",
        "\n",
        "        output_flattened = output.flatten(1)\n",
        "        target_flattened = target.flatten(1)\n",
        "        test_loss += criterion(output_flattened, target_flattened).item() * len(data)\n",
        "\n",
        "        test_rel_loss += ((torch.norm((output-target).view(output.shape[0], -1), dim=1, p=2)/torch.norm((target).view(output.shape[0], -1), dim=1, p=2)).sum()).item()\n",
        "    test_loss /= len(val_loader.dataset)\n",
        "    test_rel_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(\n",
        "         \"Test set: Average loss: {:.4f} Average relative error: {:.4f}\".format(\n",
        "           test_loss, test_rel_loss\n",
        "        )\n",
        "    )\n",
        "    return test_loss,test_rel_loss\n",
        "\n",
        "\n",
        "def run_vel_training_encoder_decoder(num_epochs, lr, batch_size, device=\"cuda\"):\n",
        "\n",
        "    train_vel_DataSet = Fluid_Dataset(train_params, train_vel)\n",
        "    test_vel_DataSet = Fluid_Dataset(test_params, test_vel)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_vel_DataSet,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,  # Can be important for training\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "        drop_last=True,\n",
        "        num_workers=2,\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        test_vel_DataSet,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    # ===== Model, Optimizer and Criterion =====\n",
        "    model_encoder_decoder= MLP_press_ConvAutoencoder_2()\n",
        "    model_encoder_decoder = model_encoder_decoder.to(device=device)\n",
        "    optimizer_encoder_decoder  = torch.optim.Adam(\n",
        "        model_encoder_decoder.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=1e-3\n",
        "    )\n",
        "    criterion_mlp = torch.nn.functional.mse_loss\n",
        "\n",
        "    # ===== Train Model =====\n",
        "    train_loss_history = []\n",
        "    train_loss_enc_dec_history = []\n",
        "    train_loss_mlp_enc_history = []\n",
        "    val_loss_history = []\n",
        "    val_rel_loss_history = []\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        train_loss, trai_loss_enc_dec, train_loss_mlp_enc = train_encoder_decoder_epoch(\n",
        "            model_encoder_decoder, device, train_loader, optimizer_encoder_decoder, epoch, criterion_mlp\n",
        "        )\n",
        "        train_loss_history.extend(train_loss)\n",
        "        train_loss_enc_dec_history.extend(trai_loss_enc_dec)\n",
        "        train_loss_mlp_enc_history.extend(train_loss_mlp_enc)\n",
        "\n",
        "        val_loss,val_rel_loss= validate(model_encoder_decoder, device, val_loader, criterion_mlp)\n",
        "        val_loss_history.append(val_loss)\n",
        "        val_rel_loss_history.append(val_rel_loss)\n",
        "\n",
        "\n",
        "    # ===== Plot training curves =====\n",
        "    n_train = len(train_loss_history)\n",
        "    t_train = num_epochs * np.arange(n_train) / n_train\n",
        "    t_val = np.arange(1, num_epochs + 1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(t_train, train_loss_history, label=\"Train\")\n",
        "    plt.plot(t_val, val_loss_history, label=\"Val\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(t_train, train_loss_enc_dec_history, label=\"Train enc dec\")\n",
        "    plt.plot(t_train, train_loss_mlp_enc_history, label=\"Train mlp enc\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(t_val, val_rel_loss_history, label=\"Val rel err\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"rel err\")\n",
        "\n",
        "    return model_encoder_decoder, val_loss_history[-1], val_rel_loss_history[-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "num_epochs=200\n",
        "lr=0.0001\n",
        "#device=torch.device('cpu')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_trained,  val_loss, val_rel_loss = run_vel_training_encoder_decoder(num_epochs, lr, batch_size, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Ijy1f4reSHp",
        "outputId": "9523f296-b681-4bff-8144-5a60fa5cffc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 4.7101 Average relative error: 0.2827\n",
            "Test set: Average loss: 2.2227 Average relative error: 0.1969\n",
            "Test set: Average loss: 1.9149 Average relative error: 0.1832\n",
            "Test set: Average loss: 1.8613 Average relative error: 0.1805\n",
            "Test set: Average loss: 1.8234 Average relative error: 0.1786\n",
            "Test set: Average loss: 1.7939 Average relative error: 0.1770\n",
            "Test set: Average loss: 1.7735 Average relative error: 0.1759\n",
            "Test set: Average loss: 1.7614 Average relative error: 0.1753\n",
            "Test set: Average loss: 1.7577 Average relative error: 0.1748\n",
            "Test set: Average loss: 1.7284 Average relative error: 0.1737\n",
            "Test set: Average loss: 1.5907 Average relative error: 0.1658\n",
            "Test set: Average loss: 1.4266 Average relative error: 0.1569\n",
            "Test set: Average loss: 1.2389 Average relative error: 0.1460\n",
            "Test set: Average loss: 0.9621 Average relative error: 0.1283\n",
            "Test set: Average loss: 0.7245 Average relative error: 0.1107\n",
            "Test set: Average loss: 0.5409 Average relative error: 0.0943\n",
            "Test set: Average loss: 0.4268 Average relative error: 0.0830\n",
            "Test set: Average loss: 0.3612 Average relative error: 0.0760\n",
            "Test set: Average loss: 0.3216 Average relative error: 0.0717\n",
            "Test set: Average loss: 0.2800 Average relative error: 0.0666\n",
            "Test set: Average loss: 0.2459 Average relative error: 0.0622\n",
            "Test set: Average loss: 0.2202 Average relative error: 0.0592\n",
            "Test set: Average loss: 0.1998 Average relative error: 0.0566\n",
            "Test set: Average loss: 0.1866 Average relative error: 0.0547\n",
            "Test set: Average loss: 0.1722 Average relative error: 0.0527\n",
            "Test set: Average loss: 0.1660 Average relative error: 0.0517\n",
            "Test set: Average loss: 0.1598 Average relative error: 0.0509\n",
            "Test set: Average loss: 0.1531 Average relative error: 0.0503\n",
            "Test set: Average loss: 0.1416 Average relative error: 0.0481\n",
            "Test set: Average loss: 0.1438 Average relative error: 0.0483\n",
            "Test set: Average loss: 0.1418 Average relative error: 0.0483\n",
            "Test set: Average loss: 0.1274 Average relative error: 0.0457\n",
            "Test set: Average loss: 0.1232 Average relative error: 0.0450\n",
            "Test set: Average loss: 0.1232 Average relative error: 0.0449\n",
            "Test set: Average loss: 0.1224 Average relative error: 0.0451\n",
            "Test set: Average loss: 0.1208 Average relative error: 0.0443\n",
            "Test set: Average loss: 0.1158 Average relative error: 0.0439\n",
            "Test set: Average loss: 0.1160 Average relative error: 0.0439\n",
            "Test set: Average loss: 0.1076 Average relative error: 0.0423\n",
            "Test set: Average loss: 0.1101 Average relative error: 0.0430\n",
            "Test set: Average loss: 0.1078 Average relative error: 0.0426\n",
            "Test set: Average loss: 0.1027 Average relative error: 0.0412\n",
            "Test set: Average loss: 0.1044 Average relative error: 0.0415\n",
            "Test set: Average loss: 0.1005 Average relative error: 0.0410\n",
            "Test set: Average loss: 0.0997 Average relative error: 0.0409\n",
            "Test set: Average loss: 0.0998 Average relative error: 0.0409\n",
            "Test set: Average loss: 0.0962 Average relative error: 0.0399\n",
            "Test set: Average loss: 0.1037 Average relative error: 0.0418\n",
            "Test set: Average loss: 0.0981 Average relative error: 0.0405\n",
            "Test set: Average loss: 0.0942 Average relative error: 0.0396\n",
            "Test set: Average loss: 0.0931 Average relative error: 0.0395\n",
            "Test set: Average loss: 0.0899 Average relative error: 0.0388\n",
            "Test set: Average loss: 0.0914 Average relative error: 0.0389\n",
            "Test set: Average loss: 0.0920 Average relative error: 0.0392\n",
            "Test set: Average loss: 0.0911 Average relative error: 0.0390\n",
            "Test set: Average loss: 0.0959 Average relative error: 0.0402\n",
            "Test set: Average loss: 0.0888 Average relative error: 0.0386\n",
            "Test set: Average loss: 0.0894 Average relative error: 0.0387\n",
            "Test set: Average loss: 0.0935 Average relative error: 0.0397\n",
            "Test set: Average loss: 0.0937 Average relative error: 0.0397\n",
            "Test set: Average loss: 0.0872 Average relative error: 0.0382\n",
            "Test set: Average loss: 0.0809 Average relative error: 0.0366\n",
            "Test set: Average loss: 0.0842 Average relative error: 0.0375\n",
            "Test set: Average loss: 0.0854 Average relative error: 0.0376\n",
            "Test set: Average loss: 0.0837 Average relative error: 0.0372\n",
            "Test set: Average loss: 0.0830 Average relative error: 0.0372\n",
            "Test set: Average loss: 0.0874 Average relative error: 0.0384\n",
            "Test set: Average loss: 0.0888 Average relative error: 0.0384\n",
            "Test set: Average loss: 0.0830 Average relative error: 0.0371\n",
            "Test set: Average loss: 0.0848 Average relative error: 0.0377\n",
            "Test set: Average loss: 0.0821 Average relative error: 0.0370\n",
            "Test set: Average loss: 0.0914 Average relative error: 0.0390\n",
            "Test set: Average loss: 0.0841 Average relative error: 0.0374\n",
            "Test set: Average loss: 0.0813 Average relative error: 0.0367\n",
            "Test set: Average loss: 0.0838 Average relative error: 0.0373\n",
            "Test set: Average loss: 0.0838 Average relative error: 0.0374\n",
            "Test set: Average loss: 0.0786 Average relative error: 0.0361\n",
            "Test set: Average loss: 0.0843 Average relative error: 0.0376\n",
            "Test set: Average loss: 0.0872 Average relative error: 0.0381\n",
            "Test set: Average loss: 0.0807 Average relative error: 0.0367\n",
            "Test set: Average loss: 0.0813 Average relative error: 0.0369\n",
            "Test set: Average loss: 0.0814 Average relative error: 0.0368\n",
            "Test set: Average loss: 0.0802 Average relative error: 0.0365\n",
            "Test set: Average loss: 0.0777 Average relative error: 0.0359\n",
            "Test set: Average loss: 0.0791 Average relative error: 0.0362\n",
            "Test set: Average loss: 0.0787 Average relative error: 0.0361\n",
            "Test set: Average loss: 0.0835 Average relative error: 0.0375\n",
            "Test set: Average loss: 0.0799 Average relative error: 0.0363\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-32c343f88682>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#device=torch.device('cpu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_trained\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_vel_training_encoder_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-e148473553e1>\u001b[0m in \u001b[0;36mrun_vel_training_encoder_decoder\u001b[0;34m(num_epochs, lr, batch_size, device)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         train_loss, trai_loss_enc_dec, train_loss_mlp_enc = train_encoder_decoder_epoch(\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mmodel_encoder_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_encoder_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-15-e148473553e1>\u001b[0m in \u001b[0;36mtrain_encoder_decoder_epoch\u001b[0;34m(model, device, train_loader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mZ3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-caa738c5a96e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, par, out)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mout_squeezed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(batch_size x 39 x 16) -> #(batch_size x 1 x 39 x 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_squeezed\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, dim_reduced)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mZ3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_siz, 1, dim_1, dim_2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR7Fp6yKFBkA"
      },
      "outputs": [],
      "source": [
        "#find best num_epoch and learning rate\n",
        "\n",
        "batch_size=32\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "val_losses=[]\n",
        "val_rel_losses=[]\n",
        "for lr in list(np.linspace(0.0001, 0.001, 50)):\n",
        "  for num_epochs in list(np.linspace(50 , 200, 20).astype(int)):\n",
        "\n",
        "        model_trained,  val_loss, val_rel_loss = run_vel_training_encoder_decoder(num_epochs, lr, batch_size, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_rel_losses.append(val_rel_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBBQ2fU6vsPY"
      },
      "outputs": [],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NINq0KIOvn_I"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Simple_Model()\n",
        "  # Valori casuali tra 0 e 1\n",
        "z1, z2, z3= model.forward(train_params,train_vel)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjMB1zFmuSDm",
        "outputId": "6366a8d3-bcda-4c02-c001-71e83b7d8d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 18, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI43oebU3e95",
        "outputId": "d318417b-c453-4410-e48b-f23dbd07d7d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 18, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "z2.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD3WsrA0vHcx",
        "outputId": "71fc5297-1b8b-463f-de2c-9dc1dee41bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=model.predict(train_params)"
      ],
      "metadata": {
        "id": "tsxauj7LvOly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlI85MUnvRAf",
        "outputId": "55d4f37e-1c91-4c0c-a58e-f5db4fe15b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1560, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.randn((5,3,2))\n",
        "c.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2exQdUyryr-U",
        "outputId": "bb58ae7a-d705-45d2-ee73-61d6954b49d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_shaped=c.view(c.shape[0], -1)"
      ],
      "metadata": {
        "id": "M4gLIJpMzPPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_shaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csiBaQe9zZv8",
        "outputId": "bb359c84-7a14-4c52-8dd6-329649293892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_shaped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcBNc2kKzsRD",
        "outputId": "ea09b0fa-7a03-471d-c6c6-3af1b07da260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0247,  0.5999,  1.3813, -0.8010,  1.7893, -1.3100],\n",
              "        [-0.0918,  1.5952, -0.1132, -1.1700,  0.2491,  2.2126],\n",
              "        [-0.3063,  1.1698,  0.2230,  0.6958,  0.5637, -1.1418],\n",
              "        [ 0.4004,  0.7669,  0.3747,  1.3313,  0.7806,  0.3532],\n",
              "        [-0.2890,  0.9966,  1.9221,  0.0194, -1.7310,  1.0572]])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(c_shaped, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crBccyUtznzZ",
        "outputId": "94ccb136-af9e-4252-9a12-3f4b30505c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.7979, 2.9821, 1.9020, 1.8426, 2.9809])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGia49f52YVb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxKh2cvIOjf_"
      },
      "outputs": [],
      "source": [
        "def read_vtk(filename):\n",
        "    \"\"\"Read .vtk file and return the polydata\"\"\"\n",
        "\n",
        "    fn_dir, fn_ext = os.path.splitext(filename)\n",
        "\n",
        "    if fn_ext == '.vtk':\n",
        "        reader = vtk.vtkPolyDataReader()\n",
        "    elif fn_ext == '.vtp':\n",
        "        reader = vtk.vtkXMLPolyDataReader()\n",
        "    elif fn_ext == '.stl':\n",
        "        reader = vtk.vtkSTLReader()\n",
        "    elif fn_ext == '.obj':\n",
        "        reader = vtk.vtkOBJReader()\n",
        "    elif fn_ext == '.vtu':\n",
        "        reader = vtk.vtkXMLUnstructuredGridReader()\n",
        "    elif fn_ext == '.pvtu':\n",
        "        reader = vtk.vtkXMLPUnstructuredGridReader()\n",
        "    else:\n",
        "        raise ValueError(F\"File extension {fn_ext} not supported\")\n",
        "\n",
        "    reader.SetFileName(filename)\n",
        "    reader.Update(0)\n",
        "    mesh = reader.GetOutput()\n",
        "\n",
        "    return mesh\n",
        "\n",
        "def write_vtk(mesh, fn):\n",
        "    \"\"\" Write a mesh (vtk polydata or unstructured grid) to disk \"\"\"\n",
        "\n",
        "    _, extension = os.path.splitext(fn)\n",
        "\n",
        "    if extension == '.vtk':\n",
        "        writer = vtk.vtkPolyDataWriter()\n",
        "    elif extension == '.stl':\n",
        "        writer = vtk.vtkSTLWriter()\n",
        "    elif extension == '.vtp':\n",
        "        writer = vtk.vtkXMLPolyDataWriter()\n",
        "    elif extension == '.vtu':\n",
        "        writer = vtk.vtkXMLUnstructuredGridWriter()\n",
        "    elif extension == '.obj':\n",
        "        writer = vtk.vtkOBJWriter()\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized extension {extension}\")\n",
        "\n",
        "    writer.SetInputData(mesh)\n",
        "    writer.SetFileName(fn)\n",
        "    writer.Update(0)\n",
        "    writer.Write()\n",
        "\n",
        "    return\n",
        "\n",
        "def add_array(mesh, array, name):\n",
        "    \"\"\"Add numpy array as new field to a vtk file\"\"\"\n",
        "\n",
        "    new_array = numpy_to_vtk(array)\n",
        "    new_array.SetName(name)\n",
        "    mesh.GetPointData().AddArray(new_array)\n",
        "\n",
        "    return mesh\n",
        "\n",
        "def compute_matching_idxs():\n",
        "    \"\"\"Compute correspondences bewteen indices on the .vtu and on the .mesh file for plotting\"\"\"\n",
        "\n",
        "    mesh = read_vtk(os.path.join('/content/drive/MyDrive/data_ML4Science', 'geometries', 'bif_sym_alpha50_h0.10_ref.vtu'))\n",
        "    points = vtk_to_numpy(mesh.GetPoints().GetData())\n",
        "\n",
        "    mesh_2 = meshio.read(os.path.join('/content/drive/MyDrive/data_ML4Science', 'geometries','bif_sym_alpha50_h0.10.mesh'))\n",
        "    points_2 = mesh_2.points\n",
        "\n",
        "    dist = cdist(mesh_2.points, points, metric='euclidean')\n",
        "\n",
        "    idxs = np.argmin(dist, axis=0)\n",
        "\n",
        "    return idxs\n",
        "\n",
        "\n",
        "def visualize_solution(field_array, fields=None, step_t=10):\n",
        "    \"\"\" Export the solution corresponding to the n-th snapshot (every step_t steps) to a .vtu file.\"\"\"\n",
        "\n",
        "    if fields is None:\n",
        "        fields = {'velocity': 3, 'pressure': 1}  # fields and corresponding dimensions\n",
        "\n",
        "    os.makedirs('solutions', exist_ok=True)\n",
        "\n",
        "    idxs = compute_matching_idxs()\n",
        "\n",
        "    mesh = read_vtk(os.path.join('/content/drive/MyDrive/data_ML4Science', 'geometries', 'bif_sym_alpha50_h0.10.vtu'))\n",
        "\n",
        "    fom_solution = dict()\n",
        "    for field in fields:\n",
        "        # print(f\"Processing field {field} - Dimension: {fields[field]}\")\n",
        "        cur_idxs = np.hstack([idxs + k * (Nh_space[field]//fields[field]) for k in range(fields[field])])\n",
        "        fom_solution[field] = expand(field_array, basis_space[field], basis_time[field])[cur_idxs]\n",
        "        print(fom_solution[field].shape)\n",
        "\n",
        "    for cnt_t in range(0, Nh_time['velocity'], step_t):\n",
        "        # print(f\"\\nProcessing timestep {cnt_t} of {Nh_time['velocity']}\")\n",
        "        for field in fields:\n",
        "            cur_fom_solution = np.reshape(fom_solution[field][:, cnt_t], (fields[field], -1)).T\n",
        "            mesh = add_array(mesh, cur_fom_solution, field)\n",
        "\n",
        "        # write_vtk(mesh, os.path.join('solutions', f\"solution_{n}_{cnt_t}\" + '.vtu'))\n",
        "        write_vtk(mesh, os.path.join('solutions', f\"solution_{cnt_t}\" + '.vtu'))\n",
        "\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezn9VDSNOwKP"
      },
      "outputs": [],
      "source": [
        "model_trained.eval()\n",
        "\n",
        "input_tensor = torch.tensor(test_params[0,:], dtype=torch.float32)  # Trasforma in tensore\n",
        "input_tensor = input_tensor.unsqueeze(dim=0)\n",
        "input_tensor = input_tensor.to(device)  # Se usi la GPU\n",
        "\n",
        "with torch.no_grad():\n",
        "    output_visual = model_trained(input_tensor)\n",
        "    output_visual=output_visual[0]\n",
        "    print(output_visual.shape)\n",
        "\n",
        "visualize_solution(output_visual.cpu().numpy() ,fields={'velocity': 3},step_t=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWGvn5V8cY_I"
      },
      "outputs": [],
      "source": [
        "!zip -r solutions.zip solutions\n",
        "from google.colab import files\n",
        "files.download('solutions.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}